# 29 - æ•°æ®å¢å¹¿

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰[![Bilibil](https://i2.hdslb.com/bfs/archive/31677fa89093f30b98e516884b110b8d983643ca.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV17y4y1g76q)
## æ•°æ®å¢å¼º(Data Augmentation)

**Problem**
æ¯”å¦‚ä¸€ä¸ªè¯­éŸ³ã€å›¾ç‰‡è¯†åˆ«ç³»ç»Ÿï¼Œåœ¨è®­ç»ƒåœºæ™¯ä¸‹æˆåŠŸï¼Œæ‹¿å‡ºæ¥åˆ°å®é™…ç¯å¢ƒï¼Œä¼šå‡ºç°ä¸é€‚åº”çš„å™ªéŸ³ã€‚

å¢åŠ ä¸€ä¸ªå·²æœ‰æ•°æ®é›†ï¼Œé€šè¿‡æ•°æ®å˜æ¢ï¼Œä½¿å¾—æœ‰æ›´å¤šçš„å¤šæ ·æ€§
- åœ¨è¯­è¨€é‡ŒåŠ å…¥å„ç§ä¸åŒçš„èƒŒæ™¯å™ªéŸ³
- æ”¹å˜å›¾ç‰‡çš„é¢œè‰²å’Œå½¢çŠ¶

![](\Images/0_Utma-dS47hSoQ6Zt.png)

**ä½¿ç”¨å¢å¼ºæ•°æ®è®­ç»ƒ**

åœ¨è®­ç»ƒä¸­éšæœºåœ¨çº¿ç”Ÿæˆ

- ç¿»è½¬(Flip)
  - å·¦å³
  - ä¸Šä¸‹
- åˆ‡å‰²ï¼Œä»å›¾ç‰‡ä¸­åˆ‡å‰²ä¸€å—ï¼Œå˜æˆå›ºå®šå½¢çŠ¶ï¼Œæ‰€ä»¥è¿˜å­˜åœ¨æ‹‰ä¼¸ç­‰(Crop)
  - éšæœºé«˜å®½æ¯”
  - éšæœºå¤§å°
  - éšæœºä½ç½®
- é¢œè‰²(Color)
  - è‰²è°ƒ
  - é¥±å’Œåº¦
  - æ˜äº®åº¦

![](\Images/arc.png)

ç±»ä¼¼äºå¯¹å›¾ç‰‡åšPSçš„å˜æ¢

**æ€»ç»“**

- æ•°æ®å¢å¹¿é€šè¿‡å˜å½¢æ•°æ®æ¥è·å–å¤šæ ·æ€§ä»è€Œä½¿æ¨¡å‹æ³›åŒ–æ€§èƒ½æ›´å¥½
- å¸¸è§æ–¹æ³•åè½¬ã€åˆ‡å‰²ã€å˜è‰²

### ä»£ç å®ç°

```
%matplotlib inline
import torch
import torchvision
from torch import nn
from d2l import torch as d2l

d2l.set_figsize()
img = d2l.Image.open('./Image/Lions.png')
d2l.plt.imshow(img)
#éƒ½æ¥è‡ªäºfrom PIL import Image

def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):
    Y = [aug(img) for _ in range(num_rows * num_cols)]
    d2l.show_images(Y, num_rows, num_cols, scale=scale)
#å®šä¹‰è¾…åŠ©å‡½æ•°ï¼Œå‚æ•°ä¸ºå›¾ç‰‡img,å’Œå¢å¹¿æ–¹æ³•aug
#é»˜è®¤(2, 4)=8å¼ å˜æ¢

```
**Flip**

> torchvision.transforms.RandomHorizontalFlip()
> torchvision.transforms.RandomVerticalFlip()
```
#æ°´å¹³éšæœºç¿»è½¬ï¼Œ50%
apply(img, torchvision.transforms.RandomHorizontalFlip())

#éšæœºä¸Šä¸‹ç¿»è½¬ï¼Œ50%
apply(img, torchvision.transforms.RandomVerticalFlip())
```
**Crop**

>torchvision.transforms.RandomResizedCrop(size, scale, ratio)
```
#éšæœºå‰ªè£
shape_aug = torchvision.transforms.RandomResizedCrop((200, 200), scale=(0.1, 1), ratio=(0.5, 2))
#size = (200, 200)ï¼Œè£å‡ºæ¥çš„å›¾ç‰‡å¤§å°
#scale=(0.1, 1)ï¼Œè£å¤„åŒºåŸŸé¢ç§¯å åŸå§‹å›¾ç‰‡ç™¾åˆ†æ¯”ï¼Œä»10%åˆ°100%
#ratio=(0.5, 2)ï¼Œé«˜å®½æ¯”ï¼Œ1:2 or 2:1
apply(img, shape_aug)
```
**Color**

> torchvision.transforms.ColorJitter(
    brightness, contrast, saturation, hue)
```
apply(img, torchvision.transforms.ColorJitter(
    brightness=0.5, contrast=0, saturation=0, hue=0))
#brightnessäº®åº¦ï¼›contrastå¯¹æ¯”åº¦ï¼›saturationé¥±å’Œåº¦ï¼›hueè‰²è°ƒ

apply(img, torchvision.transforms.ColorJitter(
    brightness=0, contrast=0, saturation=0, hue=0.5))
```
**å¯ç»“åˆå¤šç§å¢å¹¿æ–¹æ³•**

>torchvision.transforms.Compose([aug1, aug2, aug3, aug4])
```
augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomHorizontalFlip(),
    color_aug, shape_aug])
apply(img, augs)
```
**å®ä¾‹**

```
train_augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor()
])

test_augs = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor()
])
#ToTensorå°†(H,W,C)çš„ndarray, imgè½¬åŒ–ä¸º(C,H,W)çš„Tensor
```
```
def load_cifar10(is_train, augs, batch_size):
    dataset = torchvision.datasets.CIFAR10(
        root='../data', train=is_train,
        transform=augs, download=True)
    #å¯¹äºdatasetså‡½æ•°
    #transform:ä¸€ä¸ªå‡½æ•°ï¼ŒåŸå§‹å›¾ç‰‡ä½œä¸ºè¾“å…¥ï¼Œè¿”å›ä¸€ä¸ªè½¬æ¢åçš„å›¾ç‰‡ã€‚
    #download:ä»äº’è”ç½‘ä¸Šä¸‹è½½æ•°æ®é›†å¹¶æ”¾åˆ°æ ¹ç›®å½•ä¸‹
    #train:è®­ç»ƒé›†oræµ‹è¯•é›†
    #å…ˆæ”¹å˜æ•°æ®é›†å½¢å¼ï¼Œå³transforms+totensor
    dataloader = torch.utils.data.DataLoader(
        dataset, batch_size=batch_size, shuffle=is_train,
        num_workers=4)
    #å†æå–æ•°æ®ä¸ºitearble
    #untils.data.DataLoader()
    #Combines a dataset and a sampler,
    #and provides an iterable over the given dataset.
    #dataset:åŠ è½½çš„æ•°æ®é›†
    #batch_size:æ‰¹é‡å¤§å°
    #shuffleï¼šæ‰“ä¹±
    #num_workers:ç”¨å¤šå°‘ä¸ªå­è¿›ç¨‹åŠ è½½æ•°æ®,å¯¹äºå›¾ç‰‡è¿˜æ˜¯åšå¤§ä¸€ç‚¹
    #augéœ€è¦å¾ˆå¤§çš„è®¡ç®—é‡
    return dataloader

```

```
def train_batch_ch13(net, X, y, loss, trainer, devices):
    if isinstance(X, list):
        X = [x.to(devices[0]) for x in X]
    else:
        X = X.to(devices[0])
    y = y.to(devices[0])
    net.train()
    trainer.zero_grad()
    pred = net(X)
    l = loss(pred, y)
    l.sum().backward()
    trainer.step()
    train_loss_sum = l.sum()
    train_acc_sum = d2l.accuracy(pred, y)
    return train_loss_sum, train_acc_sum

def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,
               devices=d2l.try_all_gpus()):
    timer, num_batches = d2l.Timer(), len(train_iter)
    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                            legend=['train loss', 'train acc', 'test acc'])
    net = nn.DataParallel(net, device_ids=devices).to(devices[0])
    #åœ¨æ¨¡å—çº§åˆ«ä¸Šå®ç°æ•°æ®å¹¶è¡Œã€‚
    for epoch in range(num_epochs):
        metric = d2l.Accumulator(4)
        for i, (features, labels) in enumerate(train_iter):
            timer.start()
            l, acc = train_batch
æœªå®Œå¾…ç»­â€¦â€¦
```