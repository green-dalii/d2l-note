## 数据增强(Data Augmentation)

**Problem**
比如一个语音、图片识别系统，在训练场景下成功，拿出来到实际环境，会出现不适应的噪音。

增加一个已有数据集，通过数据变换，使得有更多的多样性
- 在语言里加入各种不同的背景噪音
- 改变图片的颜色和形状

![](\Images/0_Utma-dS47hSoQ6Zt.png)

**使用增强数据训练**

在训练中随机在线生成

- 翻转(Flip)
  - 左右
  - 上下
- 切割，从图片中切割一块，变成固定形状，所以还存在拉伸等(Crop)
  - 随机高宽比
  - 随机大小
  - 随机位置
- 颜色(Color)
  - 色调
  - 饱和度
  - 明亮度

![](\Images/arc.png)

类似于对图片做PS的变换

**总结**

- 数据增广通过变形数据来获取多样性从而使模型泛化性能更好
- 常见方法反转、切割、变色

### 代码实现

```
%matplotlib inline
import torch
import torchvision
from torch import nn
from d2l import torch as d2l

d2l.set_figsize()
img = d2l.Image.open('./Image/Lions.png')
d2l.plt.imshow(img)
#都来自于from PIL import Image

def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):
    Y = [aug(img) for _ in range(num_rows * num_cols)]
    d2l.show_images(Y, num_rows, num_cols, scale=scale)
#定义辅助函数，参数为图片img,和增广方法aug
#默认(2, 4)=8张变换

```
**Flip**

> torchvision.transforms.RandomHorizontalFlip()
> torchvision.transforms.RandomVerticalFlip()
```
#水平随机翻转，50%
apply(img, torchvision.transforms.RandomHorizontalFlip())

#随机上下翻转，50%
apply(img, torchvision.transforms.RandomVerticalFlip())
```
**Crop**

>torchvision.transforms.RandomResizedCrop(size, scale, ratio)
```
#随机剪裁
shape_aug = torchvision.transforms.RandomResizedCrop((200, 200), scale=(0.1, 1), ratio=(0.5, 2))
#size = (200, 200)，裁出来的图片大小
#scale=(0.1, 1)，裁处区域面积占原始图片百分比，从10%到100%
#ratio=(0.5, 2)，高宽比，1:2 or 2:1
apply(img, shape_aug)
```
**Color**

> torchvision.transforms.ColorJitter(
    brightness, contrast, saturation, hue)
```
apply(img, torchvision.transforms.ColorJitter(
    brightness=0.5, contrast=0, saturation=0, hue=0))
#brightness亮度；contrast对比度；saturation饱和度；hue色调

apply(img, torchvision.transforms.ColorJitter(
    brightness=0, contrast=0, saturation=0, hue=0.5))
```
**可结合多种增广方法**

>torchvision.transforms.Compose([aug1, aug2, aug3, aug4])
```
augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomHorizontalFlip(),
    color_aug, shape_aug])
apply(img, augs)
```
**实例**

```
train_augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor()
])

test_augs = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor()
])
#ToTensor将(H,W,C)的ndarray, img转化为(C,H,W)的Tensor
```
```
def load_cifar10(is_train, augs, batch_size):
    dataset = torchvision.datasets.CIFAR10(
        root='../data', train=is_train,
        transform=augs, download=True)
    #对于datasets函数
    #transform:一个函数，原始图片作为输入，返回一个转换后的图片。
    #download:从互联网上下载数据集并放到根目录下
    #train:训练集or测试集
    #先改变数据集形式，即transforms+totensor
    dataloader = torch.utils.data.DataLoader(
        dataset, batch_size=batch_size, shuffle=is_train,
        num_workers=4)
    #再提取数据为itearble
    #untils.data.DataLoader()
    #Combines a dataset and a sampler,
    #and provides an iterable over the given dataset.
    #dataset:加载的数据集
    #batch_size:批量大小
    #shuffle：打乱
    #num_workers:用多少个子进程加载数据,对于图片还是做大一点
    #aug需要很大的计算量
    return dataloader

```

```
def train_batch_ch13(net, X, y, loss, trainer, devices):
    if isinstance(X, list):
        X = [x.to(devices[0]) for x in X]
    else:
        X = X.to(devices[0])
    y = y.to(devices[0])
    net.train()
    trainer.zero_grad()
    pred = net(X)
    l = loss(pred, y)
    l.sum().backward()
    trainer.step()
    train_loss_sum = l.sum()
    train_acc_sum = d2l.accuracy(pred, y)
    return train_loss_sum, train_acc_sum

def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,
               devices=d2l.try_all_gpus()):
    timer, num_batches = d2l.Timer(), len(train_iter)
    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                            legend=['train loss', 'train acc', 'test acc'])
    net = nn.DataParallel(net, device_ids=devices).to(devices[0])
    #在模块级别上实现数据并行。
    for epoch in range(num_epochs):
        metric = d2l.Accumulator(4)
        for i, (features, labels) in enumerate(train_iter):
            timer.start()
            l, acc = train_batch
未完待续……
```