# 05 - 线性代数

---

### 🎦 本节课程视频地址 👇

[![Bilibil](https://i0.hdslb.com/bfs/archive/e9ec11aff2b4a5a12bc08fd2be9bc12357c34f51.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1eK4y1U7Qy)

### 🎦 关于线性代数相关知识，强烈推荐**3Blue1Brown**的超棒教程 👇

[![Bilibili](https://i2.hdslb.com/bfs/archive/c81a8eb032f3eaa1afd604272a410ac6896f281e.jpg@380w_240h_100Q_1c.webp)](https://www.bilibili.com/video/BV1ys411472E)

## 1. 基本运算

- **向量点乘**：按元素相乘结果为标量，当相互正交时为 0
  $$\mathbf{a}^T\mathbf{b}=\sum_{i} a_ib_i$$

- **向量范数**：分为 L1 范数、L2 范数、p-范数、$\infty$-范数。其中定义分别为：

  - $L_1$范数：

  $$||\mathbf{x}||_1=\sum_{i=1}^n|x_i|$$

  - $L_2$范数：

  $$||\mathbf{x}||_2=\sqrt{\sum_{i=1}^nx_i^2}$$

  - p-范数：

  $$||\mathbf{x}||_p=(\sum_{i=1}^n|x_i|^p)^{1\over p},p>1$$

  - $\infty$-范数：

$$||\mathbf{x}||_{\infty}=\max_i|x_i|$$

- **矩阵乘以向量**：需保证矩阵列数与向量行数相等，最终得到向量，(m, n)·(n, 1)=(m,1)。矩阵的作用相当于对向量进行空间的扭曲变换（可参考 3Blue1Brown 视频）
  $$\mathbf{c}=A\mathbf{b},\ where\ c_i=\sum_jA_{ij}b_j$$

- **矩阵乘以矩阵**：相当于矩阵 A 分别与矩阵 B 中的每一列（相当于向量）做矩阵与向量乘法
  $$C=AB\ where\ C_{ik}=\sum_jA_{ij}B{jk}$$

- **Frobenius 范数**：将所有元素做平方和再开根号，因矩阵范数求解较麻烦，Frob 范数多用于替代矩阵范数
  $$||A||_{Frob}=[\sum_{ij}A_{ij}^2]^{1\over2}$$

- **矩阵正定**：如果一个矩阵 A 满足：
  $$xA^Tx^T\ge0$$
  则称其为正定矩阵
- **正交矩阵**：矩阵的所有行为相互正交的单位向量，满足：
  $$UU^T=I$$
- **特征向量和特征值**：做矩阵与向量乘法时，如果向量 $\mathbf{x}$ 经过矩阵 $A$ 扭曲变换后，没有改变原向量 $\mathbf{x}$ 的方向（长度可改变为比例 $\lambda$），则称 $\mathbf{x}$ 为特征向量，$\lambda$ 为特征值，对称矩阵总能找到特征向量
  $$A\mathbf{x}=\lambda\ \mathbf{x}$$

## 2. 线性代数的 Pytorch 写法

- 标量：`torch.tensor([3.0])`
- 向量：`torch.tensor([list])`
- 向量点积：`torch.dot(x,y)`，等价于先按元素乘，再求和：`sum(x * y)`
- 矩阵：`torch.arange(20).reshape(5,4)`
- 矩阵转置：`A.T`
- 两个矩阵按元素乘（哈达玛积，Hadamard product，数学符号为 $\bigodot$ ）[不常用]：`A * B`
- 矩阵求和，得到标量：`A.sum()`
- 矩阵按轴求和，则该轴维度变为 1：`A.sum(axis=n)` | `A.sum(axis=[a,b])`
- 矩阵求和时保留维度信息：`A.sum(axis=1,keepdims=True)`
- 矩阵求均值：`A.mean()`
- 矩阵的累加：`A.cumsum(axis=n)`，必须要指定维度
- 矩阵向量积$Ax$，需保证矩阵列数与向量维数相等：`torch.mv(A,x)`
- 矩阵相乘$AB$，可以看作是执行 m 次矩阵向量积，并拼合结果：`torch.mm(A,B)`
- $L_2$范数：`torch.norm(u)`
- $L_1$范数：`torch.abs(u).sum()`
- 矩阵的 Frob 范数：`torch.norm(A)`

> Markdown 数学公式语法参考 👉[链接 1](https://blog.csdn.net/weixin_42782150/article/details/104878759)、[链接 2](https://blog.csdn.net/dss_dssssd/article/details/82692894)

---

## Q&A🤓

**Q**：怎么改变 Tensor 里元素的数据类型：int/float？

**A**：首先介绍 Pytorch8 种张量类型：

- **torch.FloatTensor**：32bit 精度浮点张量 **[Pytorch 默认类型]** dtype 值为：torch.float32 or torch.float
- **torch.DoubleTensor**：64bit 精度浮点张量，dtype 值为：torch.float64 or torch.double _（深度学习用的较少，因为计算、存储成本太大）_
- **torch.HalfTensor**：半精度（16bit）浮点张量，dtype 值为：torch.float16 or torch.half
- torch.ByteTensor：8bit 无符号整型张量，dtype 值为：torch.uint8（深度学习领域鲜有使用）
- torch.CharTensor：8bit 字符型张量，dtype 值为：torch.int8
- torch.ShortTensor：16bit 短整型张量，dtype 值为：torch.int16 or torch.short（深度学习领域鲜有使用）
- torch.IntTensor：32bit 整型张量，dtype 值为：torch.int32 or torch.int（深度学习领域鲜有使用）
- torch.LongTensor：64bit 长整型张量，dtype 值为：torch.int64 or torch.long（深度学习领域鲜有使用）

要查看已有张量的类型，可通过在张量后使用属性：`.dtype`查看

怎样改变数据类型：

- **第一种方法：** 在构建时直接指定上面提到的 8 种类型：
  - `torch.IntTensor([[1,2],[3,4]])`
- **第二种方法：** 使用`.type()`方法转换已有张量的类型：
  - `tensor1.type(torch.HalfTensor)`
