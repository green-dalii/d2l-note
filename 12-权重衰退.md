### 🎦 本节课程视频地址 👉[Bilibil](https://www.bilibili.com/video/BV1UK4y1o7dy?spm_id_from=333.999.0.0)
——最常见的处理过拟合的方法。
### **使用均方范数作为硬性限制条件**
通过限制参数值的选择范围来控制模型容量。

$$\min l({\bf w},b)\ subject\ to\ ||{\bf w}||^2\le\theta$$

意思就是每一个$w_i$的值都不能太大。

通常不会限制偏移$b$，效果也不显著。

小的$\theta$相当于更强的正则项。

### **使用均方范数作为柔性限制**

对于每个$\theta$，都可以找到$\lambda$使得之前的目标函数等价于下面：

$$\min [l({\bf w},b)+{\lambda\over2}||{\bf w}||^2]$$

最后一项称之为惩罚，可以通过拉格朗日乘子证明。

超参数$\lambda$控制了正则项的重要程度

- $\lambda=0$：无作用；
- $\lambda\to\infty, {\bf w^*\to0}$

**图片解释**
![](\Images/微信截图_20211216174330.png)

### 参数更新法则

**计算梯度**

$${\partial\over\partial{\bf w}}(l({\bf w},b)+{\lambda\over2}||{\bf w}||^2)={\partial{l({\bf w},b)}\over\partial{\bf w}}+\lambda{\bf w}$$

**时间$t$更新参数**

$${\bf w_{t+1}}=(1-\eta\lambda){\bf w_t}-\eta{\partial{l({\bf w_t},b_t)}\over\partial{\bf w_t}}$$

通常$\eta\lambda\lt1$，在深度学习中叫权重衰退。

相当于每一次更新前先放缩当前的权重。

## 权重衰退的代码实现

生成一个人工数据集，依据：

$$y=0.05+\sum_{i=1}^d0.01x_i+\epsilon\ where\ \epsilon\in\aleph N(0,0.01^2)$$

- **创建数据集**

```
%matplotlib inline
import torch
from torch import nn
from d2l import torch as d2l

#人工数据集很容易发现与真实值的区别。
n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5
#训练集越小，越容易过拟合；同理，输入特征越多，模型越复杂
true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05
#true_w=(200*1),value=-0.01, b=0.05
train_data = d2l.synthetic_data(true_w, true_b, n_train)
#synthetic_data()函数返回y=wx+b+noise，n_train表示执行此任务的样本数量，这个函数已经考虑了噪音。
train_iter = d2l.load_array(train_data, batch_size)
test_data = d2l.synthetic_data(true_w, true_b, n_test)
test_iter = d2l.load_array(test_data, batch_size, is_train=False)

```

- **定义参数和惩罚**

```
def init_params():
    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)
    b = torch.zeros(1, requires_grad=True)
    return [w, b]

def l2_penalty(w):
    return torch.sum(w.pow(2)) / 2
# pow()函数代表指数运算符。
```

- **设计神经网络**

```
def train(lambd):
    w, b = init_params()
    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss
    num_epochs, lr = 100, 0.003
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale = 'log',
                           xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            #with torch.enable_grad():
            l = loss(net(X), y) + lambd * l2_penalty(w)
            l.sum().backward()
            #求导已经包括对lambda项的求导
            d2l.sgd([w, b], lr, batch_size)
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),
                                   d2l.evaluate_loss(net, test_iter, loss)))
    print('w的L2范数是：', torch.norm(w).item())
    #Returns the matrix norm or vector norm of a given tensor
    #返回值是一个tensor，所以要用item()调用元素。
    #只有一维张量可以返回一个标量，因为本身就是一个标量，只是改了数据类型。
```

- **训练**
```
train(0) #代表没有dw
```
![损失](\Images/微信截图_20211216204557.png)

```
train(lambd=5)
```
![损失](\Images/微信截图_20211216204706.png)

```
train(lambd=20)
```
![损失](\Images/微信截图_20211216204749.png)

- **简易实现**

```
def train_concise(wd):
    net = nn.Sequential(nn.Linear(num_inputs, 1))
    #在Linear已经设计了w,b的初值
    for param in net.parameters():
        param.data.normal_()
    loss = nn.MSELoss()
    num_epochs, lr = 100, 0.003
    trainer = torch.optim.SGD([{
        'params': net[0].weight, 'weight_decay':wd}, {
        "params": net[0].bias}], lr=lr)
    #对w有wd，b没有，所以要用字典写，分别定义。
    #params=[w,b]
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                           xlim=[5, num_epochs], legend=['test', 'train'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.backward()
            trainer.step()
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),
                                   d2l.evaluate_loss(net, test_iter, loss)))
    print('w的L2范数是：', net[0].weight.norm().item())
    #w是net[0]Sequential的第一个模块Linear的attr，求norm()后再提取成scalar。
```

- **训练**

```
train_concise(5)
```
![损失](\Images/微信截图_20211216210434.png)

Q：有一个现象，就是简洁实现收敛所需要的的epoch明显多于手动实现，而且收敛后也不是完全的平滑，这是什么原因？