# 43 - å¾ªç¯ç¥ç»ç½‘ç»œRNN

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰[![Bilibil](https://i2.hdslb.com/bfs/archive/9f357cf3d856d9497eb3d0c6e86868e7d1b253a6.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1D64y1z7CA)
[![Bilibil](https://i0.hdslb.com/bfs/archive/c5b59337e4e102a48da7bada38ea372b27774009.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1kq4y1H7sw)
## å¾ªç¯ç¥ç»ç½‘ç»œ(RNN, Recurrent Neural Network)

### å¾ªç¯ç¥ç»ç½‘ç»œ

![](\Images/043-addition.gif)

- æ›´æ–°éšè—çŠ¶æ€ï¼š$\bf h_t=\phi(W_{hh}h_{t-1}+W_{hx}x_{t-1}+b_h)$
  - å»æ‰äº† $\bf W_{hh}h_{t-1}$ å°±æ˜¯MLP
  - $\bf W_{hh}$ å°±ç”¨æ¥å­˜å‚¨æ—¶åºä¿¡æ¯
- è¾“å‡ºï¼š$\bf o_t=\phi(W_{ho}h_t+b_o)$
- æ¿€æ´»å‡½æ•°ä¸º $\phi$
![](\Images/043-01.gif)

**å›°æƒ‘åº¦(Perplexity)**

- è¡¡é‡ä¸€ä¸ªè¯­è¨€æ¨¡å‹çš„å¥½åå¯ä»¥ç”¨å¹³å‡äº¤å‰ç†µ
  $\pi = {1\over n}\sum_{i=1}^n-\log p(x_t|x_{t-1},...)$
  - $-\log p(x_t|x_{t-1},...)$  æ˜¯çœŸå®å€¼é¢„æµ‹æ¦‚ç‡çš„softmaxè¾“å‡ºã€‚ $p$ æ˜¯è¯­è¨€æ¨¡å‹çš„é¢„æµ‹æ¦‚ç‡ï¼Œ $x_t$ æ˜¯çœŸå®è¯
  - ä¸€ä¸ªé•¿åº¦ä¸º $n$ çš„åºåˆ—ï¼Œåšåˆ†ç±»ï¼Œå¹³å‡çš„äº¤å‰ç†µ
- å†å²åŸå› NLPä½¿ç”¨å›°æƒ‘åº¦ $exp(\pi)$ æ¥è¡¡é‡ï¼Œæ˜¯å¹³å‡æ¯æ¬¡å¯èƒ½é€‰é¡¹
  - 1è¡¨ç¤ºå®Œç¾ï¼Œæ— ç©·å¤§å¸ˆæœ€å·®æƒ…å†µ
  - åšæŒ‡æ•°ä½¿æ•°å€¼å˜å¤§ï¼ˆåˆ†æ•£ï¼‰

**æ¢¯åº¦å‰ªè£**

- è¿­ä»£ä¸­è®¡ç®—è¿™ $T$ ä¸ªæ—¶é—´æ­¥ä¸Šçš„æ¢¯åº¦ï¼Œåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­äº§ç”Ÿé•¿åº¦ä¸º $O(T)$ çš„çŸ©é˜µä¹˜æ³•é“¾ï¼Œå¯¼è‡´æ•°å€¼ä¸ç¨³å®šã€‚
- æ¢¯åº¦å‰ªè£èƒ½æœ‰æ•ˆé¢„é˜²æ¢¯åº¦çˆ†ç‚¸
  - å¦‚æœæ¢¯åº¦é•¿åº¦è¶…è¿‡ $\theta$ï¼Œé‚£ä¹ˆæ‹–ç§»å›é•¿åº¦ $\theta$ã€‚
  ${\bf g} \leftarrow \min\left(1, {\theta\over||\bf g||}\right)\bf g$
  $||{\bf g}||=len(\bf g)$

**æ›´å¤šçš„åº”ç”¨RNNs**

![](\Images/043-02.png)

- one to many æ–‡æœ¬ç”Ÿæˆ
  - MLPï¼Œæ— æ—¶åºä¿¡æ¯
- many to one æ–‡æœ¬åˆ†ç±»
- many to many1 é—®ç­”ã€æœºå™¨ç¿»è¯‘
- many to many2 Tag ç”Ÿæˆ
  - å¯¹æ¯ä¸€ä¸ªè¯è¿›è¡Œåˆ†ç±»

**æ€»ç»“**

- å¾ªç¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºå–å†³äºå½“ä¸‹çš„è¾“å…¥å’Œå‰ä¸€æ—¶é—´çš„éšå˜é‡
- åº”ç”¨åˆ°è¯­è¨€æ¨¡å‹ä¸­æ—¶ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œæ ¹æ®å½“å‰è¯é¢„æµ‹ä¸‹ä¸€æ¬¡æ—¶åˆ»è¯
- é€šå¸¸ä½¿ç”¨å›°æƒ‘åº¦æ¥è¡¡é‡è¯­è¨€æ¨¡å‹çš„å¥½å

## ä»é›¶å¼€å§‹å®ç°

**å¯¼å…¥åŒ…å’Œé¢„å¤„ç†**

```
%matplotlib inline
import math
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l

batch_size, num_steps = 32, 35
train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)

#ç‹¬çƒ­ç¼–ç 
F.one_hot(torch.tensor([0, 2]), len(vocab))
#ä¸¤ä¸ª1çš„ç´¢å¼•([0, 2])ï¼Œå‘é‡é•¿åº¦len(vocab)

X = torch.arange(10).reshape((2, 5))
# æ‰¹é‡å¤§å°ä¸º2ï¼Œæ—¶é—´æ­¥æ•°æ˜¯5
F.one_hot(X.T, 28).shape
# è½¬ç½®ï¼Œæ—¶åºä¸Šè¿ç»­
```

**åˆå§‹åŒ–å‚æ•°**

```
def get_params(vocab_size, num_hiddens, device):
    num_inputs = num_outputs = vocab_size
    # è¾“å…¥æ˜¯ä¸€è¿ä¸²è¯æ±‡ï¼Œé€šè¿‡one-hotå˜æˆä¸€ä¸ªé•¿ä¸ºvobab_sizeçš„å‘é‡
    # è¾“å‡ºæ˜¯å¤šç±»åˆ†ç±»ï¼Œé¢„æµ‹çš„å¯èƒ½ç»“æœéƒ½æ¥æºäºvocab_size
    
    def normal(shape):
        return torch.randn(size=shape, device=device) * 0.01
        # è¿”å›æœä»æ­£æ€åˆ†å¸ƒçš„éšæœºå˜é‡ N~(0,1)
        # å†æ”¾ç¼©åˆ°0.01

    # éšè—å±‚å‚æ•°
    W_xh = normal((num_inputs, num_hiddens))
    #x(t)é¢„æµ‹h(t)
    W_hh = normal((num_hiddens, num_hiddens))
    #h(t-1)é¢„æµ‹h(t)
    b_h = torch.zeros(num_hiddens, device=device)
    # åç§»ä¸º0
    W_hq = normal((num_hiddens, num_outputs))
    #h(t)é¢„æµ‹o(t)
    b_q = torch.zeros(num_outputs, device=device)
    # åç§»ä¸º0
    params = [W_xh, W_hh, b_h, W_hq, b_q]
    for param in params:
        param.requires_grad_(True)
        #Change if autograd should record operations on parameters
        #This method sets the parameters' requires_grad attributes in-place.
    return params

def init_rnn_state(batch_size, num_hiddens, device):
    #åˆå§‹åŒ–éšè—çŠ¶æ€h(0)
    return (torch.zeros((batch_size, num_hiddens), device=device), )
    #æ”¾åœ¨ä¸€ä¸ªå…ƒç»„é‡Œï¼Œä¸ºä»¥åçš„LSTåšå‡†å¤‡
```

**å®šä¹‰ç½‘ç»œ**

```
def rnn(inputs, state, params):
    #stateåˆå§‹åŒ–çš„éšè—çŠ¶æ€
    W_xh, W_hh, b_h, W_hq, b_q = params
    H, = state
    #è¡¨ç¤ºæ¥å—èµ‹å€¼çš„æ˜¯stateé‡Œçš„å…ƒç´ 
    outputs = []
    # Xçš„å½¢çŠ¶ï¼š(æ‰¹é‡å¤§å°ï¼Œè¯è¡¨å¤§å°)
    for X in inputs:
        #ä¸‰Då¼ é‡ï¼Œæ—¶åº-æ‰¹é‡å¤§å°-æ—¶é—´æ­¥æ•°
        #å¾ªç¯äºæ¯ä¸ªæ—¶é—´ç»´åº¦
        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)
        #H(t)=X(t)W_xh+H(t-1)W_hh
        #(batch_size, vocab_size)*(vacob_size,num_hiddens)
        #(batch_size, num_hiddens)*(num_hiddens,num_hiddens)
        Y = torch.mm(H, W_hq) + b_q
        # (batch_size,num_hiddens)*(num_hiddens, vocab_size)
        outputs.append(Y)
        #(num_steps, batch_size,vocab_size)
    return torch.cat(outputs, dim=0), (H,)
    #æŠŠè¾“å‡ºçš„YæŒ‰ç…§ç¬¬é›¶ç»´åº¦è¿æ¥
    #catæ¥æ”¶ä¸€ä¸ªtupleï¼Œæ‹†å¼€ç¬¬ä¸€ä¸ªç»´åº¦ï¼ˆnum_stepsï¼‰
    #æŠŠå…ƒç´ æŒ‰è¡Œè¿æ¥
    #(num_steps*batch_size,vocab_size)
```
```
# å®šä¹‰ç±»å°è£…å‰æ–¹åŠŸèƒ½
class RNNModelScratch: 
    """ä»é›¶å¼€å§‹å®ç°çš„å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹"""
    def __init__(self, vocab_size, num_hiddens, device,
                 get_params, init_state, forward_fn):
        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens
        self.params = get_params(vocab_size, num_hiddens, device)
        # return params
        self.init_state, self.forward_fn = init_state, forward_fn
        # init_stateåˆå§‹åŒ–çš„Hçš„å‡½æ•°
        # forward_fnæ˜¯RNNç½‘ç»œæœ¬èº«

    def __call__(self, X, state):
        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)
        #æŠŠæ•´å½¢å˜æˆæµ®ç‚¹å‹ï¼Œå¾ˆé‡è¦
        return self.forward_fn(X, state, self.params)

    def begin_state(self, batch_size, device):
        return self.init_state(batch_size, self.num_hiddens, device)

num_hiddens = 512
net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,
                      init_rnn_state, rnn)
state = net.begin_state(X.shape[0], d2l.try_gpu())
#æ²¡è½¬ç½®çš„X[0]æ˜¯batch_size
Y, new_state = net(X.to(d2l.try_gpu()), state)
# X(2,5,28)
# state æ˜¯å…ƒç»„(H,)
Y.shape, len(new_state), new_state[0].shape
```
**å®šä¹‰é¢„æµ‹æ‰¹æ¬¡**

```
#è®­ç»ƒå’Œé¢„æµ‹çš„éƒ½æ˜¯æ–‡æœ¬é‡Œæ¯ä¸€ä¸ªcharçš„ç‹¬çƒ­
def predict_ch8(prefix, num_preds, net, vocab, device): 
    #prefix å¥å­çš„å¼€å¤´
    #num_predsç”Ÿæˆå¤šå°‘ä¸ªè¯ï¼ˆè¿™é‡Œæ˜¯å­—ç¬¦ï¼‰
    state = net.begin_state(batch_size=1, device=device)
    outputs = [vocab[prefix[0]]]
    #ç¬¬ä¸€ä¸ªå­—ç¬¦ä¸²åœ¨vocabé‡Œçš„ä¸‹æ ‡
    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))
    #å®šä¹‰åŒ¿åå‡½æ•°å¯ä»¥ç›´æ¥èµ‹å€¼ç»™å˜é‡
    #outputsæœ€è¿‘é¢„æµ‹çš„è¯å˜æˆtensor
    #æ—¶é—´æ­¥é•¿1ï¼Œæ‰¹é‡å¤§å°1
    for y in prefix[1:]:  
        _, state = net(get_input(), state)
        #è¿”å›çš„æ˜¯state=(H,)ï¼Œ h(t)
        #_æ˜¯catèµ·æ¥çš„é¢„æµ‹ç»“æœ, (num_steps,vocab_size)
        #Y(1-num_steps),Y[0]=X[0]ä¸éœ€è¦é¢„æµ‹
        outputs.append(vocab[y])
        #æ·»åŠ çœŸå®çš„prefix[1]
        #output == prefix
    #éå¸¸å·§å¦™ï¼Œä»prefix[1]å¼€å§‹ä¼ å…¥ï¼Œå´æŠŠprefix[0]ä½œä¸ºè¾“å…¥
    #æ‰€ä»¥æŠŠprefix[1:]å…¨éƒ¨æ”¾å…¥åï¼Œåªè¿è¡Œäº†len(prefix)-1æ¬¡
    #æœ€åé¢„æµ‹æœªçŸ¥å­—ç¬¦çš„Hå’Œé¢„æµ‹å€¼å¹¶æ²¡æœ‰å‚ä¸
    for _ in range(num_preds):  
        #ç´§æ¥ç€å‰é¢
        y, state = net(get_input(), state)
        #ä»_=0å¼€å§‹
        #è¿™é‡Œçš„stateå°±æ˜¯å€’æ•°ç¬¬äºŒæ­¥çš„H
        #get_input()æ‹¿åˆ°äº†prefixé‡Œæœ€åä¸€ä¸ªå­—ç¬¦
        #é¢„æµ‹çš„å°±æ˜¯æœªçŸ¥å¤„çš„ç¬¬ä¸€ä¸ªå­—ç¬¦
        outputs.append(int(y.argmax(dim=1).reshape(1)))
        #è¿”å›é¢„æµ‹æœ€å¤§å€¼å¤„çš„ä¸‹æ ‡
        #ä¹Ÿå°±æ˜¯å…¶åœ¨ç‹¬çƒ­ä¸­çš„ç´¢å¼•
    return ''.join([vocab.idx_to_token[i] for i in outputs])
    #æŠŠindexè½¬æˆtoken,ç”¨''ç›¸è¿
    #char.join([])ç”¨charè¿æ¥[]é‡Œçš„å­—ç¬¦ä¸²

predict_ch8('time traveller ', 10, net, vocab, d2l.try_gpu())
```

**æ¢¯åº¦å‰ªè£**

```
#è¾…åŠ©å‡½æ•°-æ¢¯åº¦å‰ªè£
def grad_clipping(net, theta): 
    """è£å‰ªæ¢¯åº¦"""
    if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
        #ç”¨nn.Moduleçš„æ–¹å¼
    else:
        params = net.params
    #æ‹¿å‡ºæ‰€æœ‰å‚æ•°
    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))
    #W_xh, W_hh, b_h, W_hq, b_q
    #æ‰€æœ‰æ¢¯åº¦å¹³æ–¹å’Œå¼€æ ¹å·
    if norm > theta:
        for param in params:
            param.grad[:] *= theta / norm
            #[:]è¡¨ç¤ºæ‰€æœ‰å…ƒç´ 
```

**å®šä¹‰æ‰¹æ¬¡è®­ç»ƒ**

```

def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):

    state, timer = None, d2l.Timer()
    metric = d2l.Accumulator(2)  
    for X, Y in train_iter:
        #X,Y(batch_size, num_stpes)
        if state is None or use_random_iter:
            # éšæœºæ‰¹é‡
            state = net.begin_state(batch_size=X.shape[0], device=device)
            # å¦‚æœæ˜¯éšæœºæ‰¹é‡ï¼Œæ¯ä¸€æ¬¡å¾ªç¯éƒ½è¦åˆå§‹åŒ–Hå…¨é›¶
            # å› ä¸ºä¸Šä¸€åˆ»çš„ä¿¡æ¯å’Œè¿™ä¸€åˆ»çš„ä¿¡æ¯åœ¨æ—¶åºä¸Šä¸æ˜¯è¿ç»­çš„
        else:
            if isinstance(net, nn.Module) and not isinstance(state, tuple):
                state.detach_()
                # detach_()è¡¨ç¤ºåœ¨æ­¤å¤„è®¡ç®—å›¾åœæ­¢ä¼ æ’­
                # ä¹Ÿå°±æ˜¯è¯´åå‘æ¢¯åº¦åœ¨stateå‰é¢çš„å‚æ•°æ¥æ”¶ä¸åˆ°
                # å› ä¸ºbackward()åªèƒ½åœ¨åŒä¸€ä¸ªiterationé‡Œé¢è¿›è¡Œ
                # æ‰€ä»¥å‰é¢æ—¶åºç®—å‡ºæ¥çš„Hä¸éœ€è¦åœ¨æ­¤è¢«æ›´æ–°æƒé‡
            else:
                # stateå¯¹äºnn.LSTMæˆ–å¯¹äºæˆ‘ä»¬ä»é›¶å¼€å§‹å®ç°çš„æ¨¡å‹æ˜¯ä¸ªå¼ é‡
                for s in state:
                    s.detach_()
        y = Y.T.reshape(-1)
        #æŒ‰æ—¶é—´åºåˆ—æ‹‰æˆä¸€è¡Œ
        X, y = X.to(device), y.to(device)
        y_hat, state = net(X, state)
        l = loss(y_hat, y.long()).mean()
        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.backward()
            grad_clipping(net, 1)
            #æ¢¯åº¦å‰ªè£
            updater.step()
        else:
            l.backward()
            grad_clipping(net, 1)
            # å› ä¸ºå·²ç»è°ƒç”¨äº†meanå‡½æ•°
            updater(batch_size=1)
        metric.add(l * y.numel(), y.numel())
    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()
    #è®¡ç®—å›°æƒ‘åº¦
```
**å®šä¹‰epochè®­ç»ƒ**

```
def train_ch8(net, train_iter, vocab, lr, num_epochs, device,
              use_random_iter=False):
    loss = nn.CrossEntropyLoss()
    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',
                            legend=['train'], xlim=[10, num_epochs])
    if isinstance(net, nn.Module):
        updater = torch.optim.SGD(net.parameters(), lr)
    else:
        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)
    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)
    for epoch in range(num_epochs):
        ppl, speed = train_epoch_ch8(
            net, train_iter, loss, updater, device, use_random_iter)
        if (epoch + 1) % 10 == 0:
            print(predict('time traveller'))
            animator.add(epoch + 1, [ppl])
    print(f'å›°æƒ‘åº¦ {ppl:.1f}, {speed:.1f} è¯å…ƒ/ç§’ {str(device)}')
    print(predict('time traveller'))
    print(predict('traveller'))
```
```
num_epochs, lr = 500, 1
train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())
#ç»“æœè¯æ˜å¯ä»¥é¢„æµ‹å‡ºæ¯”è¾ƒæ­£ç¡®çš„è¯ï¼Œä½†æ˜¯ä¸èƒ½é¢„æµ‹è®²å¾—é€šçš„å¥å­
```
![](\Images/043-03.png)

```
net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,
                      init_rnn_state, rnn)
train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu(),
          use_random_iter=True)
```
![](\Images/043-04.png)

### ç®€æ´å®ç°

**åŠŸèƒ½é‡å¤**

```
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l

batch_size, num_steps = 32, 35
train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)

num_hiddens = 256
#ç›´æ¥è°ƒç”¨RNNç±»ï¼Œè¾“å…¥å¤§å°ï¼Œéšè—å±‚å¤§å°
rnn_layer = nn.RNN(len(vocab), num_hiddens)
# è‡ªåŠ¨åˆå§‹åŒ–H[0]ä¸ºå…¨é›¶

state = torch.zeros((1, batch_size, num_hiddens))
#åŠ äº†ä¸€ä¸ªç»´åº¦
state.shape

X = torch.rand(size=(num_steps, batch_size, len(vocab)))
Y, state_new = rnn_layer(X, state)
Y.shape, state_new.shape
#num_steps, batch_size, num_hiddens
#pyTorch çš„RNN LayeråªåŒ…æ‹¬éšè—å±‚ï¼Œä½†ä¸åŒ…æ‹¬è¾“å‡ºå±‚
```

**ç”¨ç±»å°è£…RNN+Linear**

```
class RNNModel(nn.Module):
    """å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹"""
    def __init__(self, rnn_layer, vocab_size, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        self.rnn = rnn_layer
        self.vocab_size = vocab_size
        self.num_hiddens = self.rnn.hidden_size
        # å¦‚æœRNNæ˜¯åŒå‘çš„ï¼ˆä¹‹åå°†ä»‹ç»ï¼‰ï¼Œnum_directionsåº”è¯¥æ˜¯2ï¼Œå¦åˆ™åº”è¯¥æ˜¯1
        if not self.rnn.bidirectional:
            self.num_directions = 1
            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)
        else:
            self.num_directions = 2
            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)

    def forward(self, inputs, state):
        X = F.one_hot(inputs.T.long(), self.vocab_size)
        X = X.to(torch.float32)
        Y, state = self.rnn(X, state)
        # å…¨è¿æ¥å±‚é¦–å…ˆå°†Yçš„å½¢çŠ¶æ”¹ä¸º(æ—¶é—´æ­¥æ•°*æ‰¹é‡å¤§å°,éšè—å•å…ƒæ•°)
        # å®ƒçš„è¾“å‡ºå½¢çŠ¶æ˜¯(æ—¶é—´æ­¥æ•°*æ‰¹é‡å¤§å°,è¯è¡¨å¤§å°)ã€‚
        output = self.linear(Y.reshape((-1, Y.shape[-1])))
        return output, state

    def begin_state(self, device, batch_size=1):
        if not isinstance(self.rnn, nn.LSTM):
            # nn.GRUä»¥å¼ é‡ä½œä¸ºéšçŠ¶æ€
            return  torch.zeros((self.num_directions * self.rnn.num_layers,
                                 batch_size, self.num_hiddens),
                                device=device)
        else:
            # nn.LSTMä»¥å…ƒç»„ä½œä¸ºéšçŠ¶æ€
            return (torch.zeros((
                self.num_directions * self.rnn.num_layers,
                batch_size, self.num_hiddens), device=device),
                    torch.zeros((
                        self.num_directions * self.rnn.num_layers,
                        batch_size, self.num_hiddens), device=device))
```

**è®­ç»ƒ**

```
device = d2l.try_gpu()
net = RNNModel(rnn_layer, vocab_size=len(vocab))
net = net.to(device)
d2l.predict_ch8('time traveller', 10, net, vocab, device)

num_epochs, lr = 500, 1
d2l.train_ch8(net, train_iter, vocab, lr, num_epochs, device)
#æ¡†æ¶çš„RNNæ›´å¿«ä¸€äº›ï¼Œå› ä¸ºè‡ªå®šä¹‰æ˜¯å¤šæ¬¡å°çŸ©é˜µä¹˜æ³•ï¼Œæ¡†æ¶æ˜¯å¤§çŸ©é˜µè¿ç®—
```

![](\Images/043-05.png)

![](\Images/043-06.gif)