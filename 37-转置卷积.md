# 37 - è½¬ç½®å·ç§¯

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰
[![Bilibil](https://i1.hdslb.com/bfs/archive/ac2781fb68a3e42c48833e453ec0e859ad04a2ae.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV17o4y1X7Jn)
[![Bilibil](https://i1.hdslb.com/bfs/archive/46cc51ad8dcf1541c5a3e106546805d5b6420ac1.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1CM4y1K7r7)
## è½¬ç½®å·ç§¯(Transposed Convolution)
- å·ç§¯ä¸ä¼šå¢å¤§è¾“å…¥çš„é«˜å®½ï¼Œé€šå¸¸è¦ä¹ˆä¸å˜ã€è¦ä¹ˆå‡åŠ
  - è¯­ä¹‰åˆ†å‰²éœ€è¦åœ¨åƒç´ çº§åˆ«è¯„ä¼°
- è½¬ç½®å·ç§¯åˆ™å¯ä»¥ç”¨æ¥å¢å¤§è¾“å…¥é«˜å®½

$$Y[i:i+h,j:j+w]+=X[i,j]\cdot K$$

![](\Images/037-01.png)
![](\Images/037-02.jpg)

**ä¸ºä»€ä¹ˆç§°ä¹‹ä¸ºâ€œè½¬ç½®â€**

- å¯¹äºå·ç§¯ $Y=X\star W$
  - å¯ä»¥å¯¹ $W$ æ„é€ ä¸€ä¸ª $V$ ï¼Œä½¿å¾—å·ç§¯ç­‰ä»·äºçŸ©é˜µä¹˜æ³• $Y\prime=VX\prime$
  - è¿™é‡Œ $Y\prime,\ X\prime$ æ˜¯ $Y,\ X$ å¯¹åº”çš„å‘é‡ç‰ˆæœ¬
  - $m = (m, n) \times n$
  - æ—©æœŸå°±æ˜¯è¿™ä¹ˆåšçš„
- è½¬ç½®å·ç§¯åˆ™ç­‰ä»·äº $Y\prime=V^TX\prime$
- å¦‚æœå·ç§¯å°†è¾“å…¥ä» $(h, w)$ å˜æˆäº† $(h\prime, w\prime)$
  - åŒæ ·è¶…å‚æ•°çš„è½¬ç½®å·ç§¯åˆ™ä» $(h\prime, w\prime)$ å˜å› $(h, w)$ï¼Œé€†å˜æ¢å…³ç³»
  - $n = (n, m) \times m$
  - äº¤æ¢äº†ç»´åº¦ï¼ŒåŸæœ¬çš„å·ç§¯ç»´åº¦å‡å°å˜æˆäº†è½¬ç½®ç»´åº¦å¢åŠ 

## ä»£ç å®ç°
å¯¹äºä¸€ä¸ªå¼ é‡ $X$ï¼Œè½¬ç½®å·ç§¯çš„è¾“å‡º
$$
h_Y=h_k+(h_X-1)\times stride - 2\times padding\\
w_Y=w_k+(w_X-1)\times stride - 2\times padding
$$
```
import torch
from torch import nn
from d2l import torch as d2l

#è‡ªå®šä¹‰å®ç°
def trans_conv(X, K):
    h, w = K.shape
    Y = torch.zeros((X.shape[0] + h - 1, X.shape[1] + w - 1))
    print(Y)
    for i in range(X.shape[0]):
        for j in range(X.shape[1]):
            Y[i: i + h, j: j + w] += X[i, j] * K
            #å¯¹çŸ©é˜µçš„ä¸€ä¸ªæ–¹é˜µé‡æ–°èµ‹å€¼
    return Y


#ç”¨pyTorchå†…ç½®æ¨¡å—
X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2)
tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False)
tconv.weight.data = K
#è®¾ç½®æ ¸çš„å€¼
tconv(X)
```
**å¡«å……å’Œæ­¥å¹…**

```
#å¡«å……
tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, padding=1, bias=False)
tconv.weight.data = K
tconv(X)
#åœ¨è¾“å‡ºä¸Šä½œç”¨ä¸€ä¸ªé€†å‘å¡«å……

#æ­¥å¹…
tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, stride=2, bias=False)
tconv.weight.data = K
tconv(X)
#è¾“å‡ºé«˜å®½ h/w +stride * (shape[0]/[1] - 1)

X = torch.rand(size=(1, 10, 16, 16))
conv = nn.Conv2d(10, 20, kernel_size=5, padding=2, stride=3)
tconv = nn.ConvTranspose2d(20, 10, kernel_size=5, padding=2, stride=3)
tconv(conv(X)).shape == X.shape
#è¾“å‡ºé«˜å®½ h/w +stride * (shape[0]/[1] - 1) - padding * 2

```

**åŸç†éªŒè¯**

```
X = torch.arange(9.0).reshape(3, 3)
K = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
Y = d2l.corr2d(X, K)
Y

def kernel2matrix(K):
    k, W = torch.zeros(5), torch.zeros((4, 9))

    k[:2], k[3:5] = K[0, :], K[1, :]
    # k = [1., 2., 0., 3., 4.]
    W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k

    return W

W = kernel2matrix(K)
W

Y == torch.matmul(W, X.reshape(-1)).reshape(2, 2)

Z = trans_conv(Y, K)
Z == torch.matmul(W.T, Y.reshape(-1)).reshape(3, 3)
```