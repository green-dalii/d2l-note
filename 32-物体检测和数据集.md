# 32 - ç‰©ä½“æ£€æµ‹å’Œæ•°æ®é›†

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰
[![Bilibil](https://i1.hdslb.com/bfs/archive/74c42a4b752084a4f20f3e0ec318b59f009679ae.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1Lh411Y7LX)

<center> å›¾ç‰‡åˆ†ç±» VS ç›®æ ‡æ£€æµ‹ </center>

![](/Images/1_Hz6t-tokG1niaUfmcysusw.jpeg)

**è¾¹ç¼˜æ¡†**

å¯ä»¥ç”¨4ä¸ªæ•°å­—å®šä¹‰
- å·¦ä¸Šxï¼Œå·¦ä¸Šyï¼Œå³ä¸‹xï¼Œå³ä¸‹y
- å·¦ä¸Šxï¼Œå·¦ä¸Šyï¼Œå®½ï¼Œé«˜
- yåæ ‡è½´åå‘

ç›®æ ‡è¯†åˆ«çš„æ•°æ®é›†é€šå¸¸æ¯”å›¾ç‰‡åˆ†ç±»çš„æ•°æ®é›†å°å¾ˆå¤šã€‚

## ç›®æ ‡æ£€æµ‹æ•°æ®é›†

- æ¯è¡Œè¡¨ç¤ºä¸€ä¸ªç‰©ä½“
  - å›¾ç‰‡æ–‡ä»¶åï¼Œç‰©ä½“ç±»åˆ«ï¼Œè¾¹ç¼˜æ¡†
    - 1+1+4=6ä¸ªå€¼
- COCO(cocodataset.org)
  - 80ç±»åˆ«ï¼Œ330Kå›¾ç‰‡ï¼Œ1.5Mç‰©ä½“

**æ€»ç»“**

- ç‰©ä½“æ£€æµ‹è¯†åˆ«å›¾ç‰‡é‡Œçš„å¤šä¸ªç‰©ä½“çš„ç±»åˆ«å’Œä½ç½®
- ä½ç½®é€šå¸¸ç”¨è¾¹ç¼˜æ¡†è¡¨ç¤º

### è¾¹ç¼˜æ¡†å®ç°

```
#å…ˆåŠ è½½åŒ…å¹¶æ˜¾ç¤ºå›¾ç‰‡
%matplotlib inline
import torch
from d2l import torch as d2l

d2l.set_figsize()
img = d2l.plt.imread('../Image/Lions.png')
d2l.plt.imshow(img)
```
```
#å®šä¹‰ä¸¤ç§å››ç»´å‡½æ•°
def box_corner_to_center(boxes):
    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
    #è¡Œæ•°>1,è¡¨ç¤ºå¤šä¸ªæ¡†
    cx = (x1 + x2) / 2
    cy = (y1 + y2) / 2
    w = x2 - x1
    h = y2 - y1
    boxes = torch.stack((cx, cy, w, h), axis=-1)
    #torch.stack(),tensorçš„concatenate
    #Concatenates a sequence of tensors along a new dimension.
    return boxes

def box_center_to_corner(boxes):
    cx, cy, w, h =boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
    x1 = cx - 0.5 * w
    y1 = cy - 0.5 * h
    x2 = cx + 0.5 * w
    y2 = cy + 0.5 * h
    boxes = torch.stack((x1, y1, x2, y2), axis=-1)
    return boxes
```
```
#ç»˜å›¾
def bbox_to_rect(bbox, color):
    return d2l.plt.Rectangle(xy=(bbox[0], bbox[1]), width=bbox[2] - bbox[0],
                             height=bbox[3] - bbox[1], fill=False, edgecolor=color, linewidth=2)
    #å®šä¹‰å›¾å½¢

fig = d2l.plt.imshow(img)
#figæœ¬èº«å°±æ˜¯å›¾ç‰‡
fig.axes.add_patch(bbox_to_rect(dog_bbox, 'blue'))
fig.axes.add_patch(bbox_to_rect(cat_bbox, 'red'))
#æ·»åŠ è¡¥ä¸
```
**ç›®æ ‡æ£€æµ‹æ•°æ®é›†**
```
###ä¸‹è½½å¹¶è¯»å–æ•°æ®
%matplotlib inline
import os
import pandas as pd
import torch
import torchvision
from d2l import torch as d2l

d2l.DATA_HUB['banana-dection'] = (
    d2l.DATA_URL + 'banana-detection.zip',
    '5de26c8fce5ccdea9f91267273464dc968d20d72')

def read_data_bananas(is_train=True):
    data_dir = d2l.download_extract('banana-detection', folder='../data')
    csv_fname = os.path.join('../data/banana-detection', 'bananas_train' if is_train else 'bananas_val', 'label.csv')
    #æ‹¿è®­ç»ƒæˆ–è€…éªŒè¯
    csv_data = pd.read_csv(csv_fname)
    csv_data = csv_data.set_index('img_name')
    #set_index(*arg)å°†argåˆ—ä½œä¸ºè¡Œç´¢å¼•
    images, targets = [], []
    for img_name, target in csv_data.iterrows():
    #iterrows()è¿›è¡Œè¡Œç´¢å¼•ï¼Œè¿”å›ç´¢å¼•å’Œå†…å®¹
        images.append(
            torchvision.io.read_image(
                os.path.join('../data/banana-detection', 'bananas_train' if is_train else
                             'bananas_val', 'images', f'{img_name}')))
            #Reads a JPEG or PNG image into a 3 dimensional RGB Tensor.
            #æŠŠå›¾ç‰‡å¼ é‡åŠ å…¥imagesï¼Œä¹Ÿå°±æ˜¯è¯´æŠŠæ‰€æœ‰å›¾ç‰‡éƒ½è¯»åˆ°å†…å­˜é‡Œ
            #å› ä¸ºæ•°æ®é›†å°
        targets.append(list(target))
        #æŠŠæ‰€è¯†åˆ«å†…å®¹åŠ å…¥targets
    return images, torch.tensor(targets).unsqueeze(1) / 256
    #unsqueeze(1)ï¼Œåœ¨ç¬¬ä¸€ç»´å¢åŠ ç»´åº¦
    #Returns a new tensor with a dimension of size one inserted at the specified position.
    #åŸæ¥æ˜¯dfçš„(1000, 5)ï¼Œç°åœ¨æ˜¯(1000, 1, 5)
    #targetæ˜¯é¦™è•‰çš„æ¡†
    #tensor(target)/256ç›¸å½“äºæŠŠæ¡†æ­£åˆ™åŒ–ï¼Œå˜æˆå…³äºä¸€ä¸ªåƒç´ çš„ä½ç½®

```
```
##æ•°æ®é›†ç±»
class BananasDataset(torch.utils.data.Dataset):
    def __init__(self, is_train):
        self.features, self.labels = read_data_bananas(is_train)
        print('read' + str(len(self.features)) + (f' training examples' if
             is_train else f' validation examples'))
        print(self.labels.shape)
        #è¯»å–å›¾ç‰‡å’Œæ ‡å·å¹¶ä¸”æ‰“å°é•¿åº¦
    
    def __getitem__(self, idx):
    # __getitem__(self, idx)å®šä¹‰äº†ç±»ä¼¼äºç´¢å¼•ï¼Œå»å®ç°å¯ç´¢å¼•çš„åŠŸèƒ½
    # éœ€è¦æ›´å¤æ‚çš„é€»è¾‘å»å®šä¹‰åˆ‡ç‰‡ã€é¡ºåºã€æ­¥é•¿ç­‰
        return (self.features[idx].float(), self.labels[idx])
    
    def __len__(self):
        return len(self.features)
```
```
##ç»˜å›¾
def load_data_bananas(batch_size):
#ä¸€èˆ¬ç»™ä¸€å¼ å›¾ç‰‡åšä¸Šé™mï¼Œæœ‰mç‰©ä½“ï¼Œå¤šäº†å¿½ç•¥å°‘äº†è¡¥é›¶
#æ‰¹é‡å¤§å°+ç‰©ä½“æ•°é‡+ï¼ˆç±»åˆ«+å››ç»´=5ä¸ªï¼‰ç‰¹å¾
    train_iter = torch.utils.data.DataLoader(BananasDataset(is_train=True), batch_size, shuffle=True)
    val_iter = torch.utils.data.DataLoader(BananasDataset(is_train=False), batch_size)
    
    return train_iter, val_iter

batch_size, edge_size = 32, 256 #å›¾ç‰‡å¤§å°256
train_iter, _ = load_data_bananas(batch_size)
batch = next(iter(train_iter))
batch[0].shape, batch[1].shape

imgs = (batch[0][0:10].permute(0, 2, 3, 1)) / 255
#batch[0]æ˜¯imgs
#permute()å‡½æ•°æ”¹å˜tensorçš„ç»´åº¦é¡ºåº
#å˜æˆHWCçš„æ¨¡å¼
#åšå›¾ç‰‡çš„æ—¶å€™ï¼Œä¸€èˆ¬æ˜¯ä¼šç”¨ä¸€ä¸ªToTensor()å°†å›¾ç‰‡å½’ä¸€åŒ–
print(imgs.shape)
axes = d2l.show_images(imgs, 2, 5, scale=2)
#Plot a list of images.

for ax, label in zip(axes, batch[1][0:10]):
    #batch[1]æ˜¯boxes,tensor.shape = (32, 1, 5)
    #bacth[1][0:10]å°±æ˜¯å‰åä¸ªboxes
    #label.shape=(1, 5)
    d2l.show_bboxes(ax, [label[0][1:5] * edge_size], colors=['w'])
    #ç”»æ¡†
    #æ‹¿å‡ºå››ç»´
    #æŠŠæ¡†æŒ‰æ¯”ä¾‹æ”¾å¤§
    # label
```
å›¾ç‰‡å˜å¼ é‡ï¼Œå®½é«˜ä¸å˜ï¼ŒNormalizeçš„æ˜¯RBGä¸‰é€šé“çš„æ•°å€¼ï¼›
è¾¹ç¼˜æ¡†çš„å››ç»´è¢«Nomalizeï¼Œæ˜¯æŠŠå®½é«˜æ”¾ç¼©ã€‚

