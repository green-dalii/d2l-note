<center> 图片分类 VS 目标检测 </center>

![](/Images/1_Hz6t-tokG1niaUfmcysusw.jpeg)

**边缘框**

可以用4个数字定义
- 左上x，左上y，右下x，右下y
- 左上x，左上y，宽，高
- y坐标轴反向

目标识别的数据集通常比图片分类的数据集小很多。

## 目标检测数据集

- 每行表示一个物体
  - 图片文件名，物体类别，边缘框
    - 1+1+4=6个值
- COCO(cocodataset.org)
  - 80类别，330K图片，1.5M物体

**总结**

- 物体检测识别图片里的多个物体的类别和位置
- 位置通常用边缘框表示

### 边缘框实现

```
#先加载包并显示图片
%matplotlib inline
import torch
from d2l import torch as d2l

d2l.set_figsize()
img = d2l.plt.imread('../Image/Lions.png')
d2l.plt.imshow(img)
```
```
#定义两种四维函数
def box_corner_to_center(boxes):
    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
    #行数>1,表示多个框
    cx = (x1 + x2) / 2
    cy = (y1 + y2) / 2
    w = x2 - x1
    h = y2 - y1
    boxes = torch.stack((cx, cy, w, h), axis=-1)
    #torch.stack(),tensor的concatenate
    #Concatenates a sequence of tensors along a new dimension.
    return boxes

def box_center_to_corner(boxes):
    cx, cy, w, h =boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
    x1 = cx - 0.5 * w
    y1 = cy - 0.5 * h
    x2 = cx + 0.5 * w
    y2 = cy + 0.5 * h
    boxes = torch.stack((x1, y1, x2, y2), axis=-1)
    return boxes
```
```
#绘图
def bbox_to_rect(bbox, color):
    return d2l.plt.Rectangle(xy=(bbox[0], bbox[1]), width=bbox[2] - bbox[0],
                             height=bbox[3] - bbox[1], fill=False, edgecolor=color, linewidth=2)
    #定义图形

fig = d2l.plt.imshow(img)
#fig本身就是图片
fig.axes.add_patch(bbox_to_rect(dog_bbox, 'blue'))
fig.axes.add_patch(bbox_to_rect(cat_bbox, 'red'))
#添加补丁
```
**目标检测数据集**
```
###下载并读取数据
%matplotlib inline
import os
import pandas as pd
import torch
import torchvision
from d2l import torch as d2l

d2l.DATA_HUB['banana-dection'] = (
    d2l.DATA_URL + 'banana-detection.zip',
    '5de26c8fce5ccdea9f91267273464dc968d20d72')

def read_data_bananas(is_train=True):
    data_dir = d2l.download_extract('banana-detection', folder='../data')
    csv_fname = os.path.join('../data/banana-detection', 'bananas_train' if is_train else 'bananas_val', 'label.csv')
    #拿训练或者验证
    csv_data = pd.read_csv(csv_fname)
    csv_data = csv_data.set_index('img_name')
    #set_index(*arg)将arg列作为行索引
    images, targets = [], []
    for img_name, target in csv_data.iterrows():
    #iterrows()进行行索引，返回索引和内容
        images.append(
            torchvision.io.read_image(
                os.path.join('../data/banana-detection', 'bananas_train' if is_train else
                             'bananas_val', 'images', f'{img_name}')))
            #Reads a JPEG or PNG image into a 3 dimensional RGB Tensor.
            #把图片张量加入images，也就是说把所有图片都读到内存里
            #因为数据集小
        targets.append(list(target))
        #把所识别内容加入targets
    return images, torch.tensor(targets).unsqueeze(1) / 256
    #unsqueeze(1)，在第一维增加维度
    #Returns a new tensor with a dimension of size one inserted at the specified position.
    #原来是df的(1000, 5)，现在是(1000, 1, 5)
    #target是香蕉的框
    #tensor(target)/256相当于把框正则化，变成关于一个像素的位置

```
```
##数据集类
class BananasDataset(torch.utils.data.Dataset):
    def __init__(self, is_train):
        self.features, self.labels = read_data_bananas(is_train)
        print('read' + str(len(self.features)) + (f' training examples' if
             is_train else f' validation examples'))
        print(self.labels.shape)
        #读取图片和标号并且打印长度
    
    def __getitem__(self, idx):
    # __getitem__(self, idx)定义了类似于索引，去实现可索引的功能
    # 需要更复杂的逻辑去定义切片、顺序、步长等
        return (self.features[idx].float(), self.labels[idx])
    
    def __len__(self):
        return len(self.features)
```
```
##绘图
def load_data_bananas(batch_size):
#一般给一张图片做上限m，有m物体，多了忽略少了补零
#批量大小+物体数量+（类别+四维=5个）特征
    train_iter = torch.utils.data.DataLoader(BananasDataset(is_train=True), batch_size, shuffle=True)
    val_iter = torch.utils.data.DataLoader(BananasDataset(is_train=False), batch_size)
    
    return train_iter, val_iter

batch_size, edge_size = 32, 256 #图片大小256
train_iter, _ = load_data_bananas(batch_size)
batch = next(iter(train_iter))
batch[0].shape, batch[1].shape

imgs = (batch[0][0:10].permute(0, 2, 3, 1)) / 255
#batch[0]是imgs
#permute()函数改变tensor的维度顺序
#变成HWC的模式
#做图片的时候，一般是会用一个ToTensor()将图片归一化
print(imgs.shape)
axes = d2l.show_images(imgs, 2, 5, scale=2)
#Plot a list of images.

for ax, label in zip(axes, batch[1][0:10]):
    #batch[1]是boxes,tensor.shape = (32, 1, 5)
    #bacth[1][0:10]就是前十个boxes
    #label.shape=(1, 5)
    d2l.show_bboxes(ax, [label[0][1:5] * edge_size], colors=['w'])
    #画框
    #拿出四维
    #把框按比例放大
    # label
```