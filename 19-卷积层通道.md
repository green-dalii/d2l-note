# 19 - å·ç§¯å±‚é‡Œçš„å¤šè¾“å…¥å¤šè¾“å‡ºé€šé“

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‡

[![Bilibil](https://i1.hdslb.com/bfs/archive/66e9026b84cf669fc6c3862ac4648b8d3349275a.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1MB4y1F7of)

## å¤šä¸ªè¾“å…¥é€šé“

![RGB](Images/thumb_photoshop-tutorial-r-separate-an-image-into-rgb-color-layers-57693846.png)

å½©è‰²å›¾åƒå¯èƒ½æœ‰ **Rã€Gã€B** ä¸‰ä¸ªé€šé“ï¼ˆæœ‰çš„æ ¼å¼å¦‚ PNG è¿˜åŒ…å« 4 é€šé“ï¼Œå¤šä¸€ä¸ªé€æ˜åº¦ Alpha é€šé“ã€RGB-D å›¾åƒå¤šä¸€ä¸ªæ·±åº¦ä¿¡æ¯é€šé“ç­‰ï¼‰ï¼Œå¦‚æœä½¿ç”¨ä¸Šä¸€èŠ‚å•é€šé“å·ç§¯å±‚ï¼Œå°±è¦è½¬æ¢ä¸ºç°åº¦å›¾ï¼Œè¿™æ ·ä¼šä¸¢å¤±å¾ˆå¤šç‰¹å¾ä¿¡æ¯ã€‚

å½“è¾“å…¥åŒ…å«å¤šä¸ªé€šé“æ—¶ï¼Œéœ€è¦æ„é€ ä¸€ä¸ªä¸è¾“å…¥æ•°æ®å…·æœ‰ç›¸åŒè¾“å…¥é€šé“æ•°çš„å·ç§¯æ ¸ï¼Œä»¥ä¾¿ä¸è¾“å…¥æ•°æ®è¿›è¡Œäº’ç›¸å…³è¿ç®—ã€‚

ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ç»™æ¯ä¸ªé€šé“ä¸€ä¸ªå·ç§¯æ ¸ï¼Œè¾“å‡ºæ˜¯**æ‰€æœ‰é€šé“å·ç§¯ç»“æœçš„å’Œ**ã€‚ä¸‹å›¾è¡¨ç¤ºä¸€ä¸ªä¸¤é€šé“è¾“å…¥çš„ä¾‹å­ ğŸ‘‡

![conv-multi-in](https://zh.d2l.ai/_images/conv-multi-in.svg)

ä¸‹å›¾è¡¨ç¤ºåœ¨ RGB ä¸‰è¾“å…¥é€šé“åšå·ç§¯çš„è¿‡ç¨‹ ğŸ‘‡

![rgb_cov1](Images/rgb_cov1.gif)

![rgb_cov2](Images/rgb_cov2.gif)

å…¬å¼åŒ–è¡¨ç¤ºï¼š

- è¾“å…¥$\bf X$ï¼š$c_i\times n_h\times n_w$
- æ ¸$\bf W$ï¼š$c_i\times k_h\times k_w$
- è¾“å‡º$\bf Y$ï¼š$m_h\times m_w$

$$\bf Y=\sum_{i=0}^{c_i}X_{i,:,:}\star W_{i,:,:}$$

> å…¶ä¸­ï¼Œ$c_i$ è¡¨ç¤ºè¾“å…¥çš„é€šé“ç»´

## å¤šä¸ªè¾“å‡ºé€šé“

åœ¨æœ€æµè¡Œçš„ç¥ç»ç½‘ç»œæ¶æ„ä¸­ï¼Œéšç€ç¥ç»ç½‘ç»œå±‚æ•°çš„åŠ æ·±ï¼Œæˆ‘ä»¬å¸¸ä¼šå¢åŠ è¾“å‡ºé€šé“çš„ç»´æ•°ï¼Œé€šè¿‡å‡å°‘ç©ºé—´åˆ†è¾¨ç‡ä»¥è·å¾—æ›´å¤§çš„é€šé“æ·±åº¦ã€‚ç›´è§‚åœ°è¯´ï¼Œæˆ‘ä»¬å¯ä»¥å°†**æ¯ä¸ªé€šé“çœ‹ä½œæ˜¯å¯¹ä¸åŒç‰¹å¾çš„å“åº”**ã€‚è€Œç°å®å¯èƒ½æ›´ä¸ºå¤æ‚ä¸€äº›ï¼Œå› ä¸ºæ¯ä¸ªé€šé“ä¸æ˜¯ç‹¬ç«‹å­¦ä¹ çš„ï¼Œè€Œæ˜¯ä¸ºäº†å…±åŒä½¿ç”¨è€Œä¼˜åŒ–çš„ã€‚å› æ­¤ï¼Œå¤šè¾“å‡ºé€šé“å¹¶ä¸ä»…æ˜¯å­¦ä¹ å¤šä¸ªå•é€šé“çš„æ£€æµ‹å™¨ã€‚

æˆ‘ä»¬å¯ä»¥æœ‰å¤šä¸ªä¸‰ç»´å·ç§¯æ ¸ï¼Œæ¯ä¸ªæ ¸ç”Ÿæˆä¸€ä¸ªè¾“å‡ºé€šé“ï¼Œè¾“å‡ºæ—¶ä¾¿å¯å åŠ ä¸ºå¤šè¾“å‡ºçš„é€šé“ï¼›

å…¬å¼åŒ–è¡¨ç¤ºï¼š

- è¾“å…¥$\bf X$ï¼š$c_i\times n_h\times n_w$
- æ ¸$\bf W$ï¼š$c_o\times c_i\times k_h\times k_w$
- è¾“å‡º$\bf Y$ï¼š$c_o\times m_h\times m_w$

$$
\bf Y_{i,:,:}=X\star W_{i,:,:,:} \quad \text{for $i=1,â€¦,c_0$}
$$

> å…¶ä¸­ï¼Œ$c_o$ è¡¨ç¤ºè¾“å‡ºçš„é€šé“ç»´

## $1\times 1$å·ç§¯å±‚â€”â€”å¤šé€šé“çš„å…¨è¿æ¥å±‚

![](Images/cov_1x1.jpg)

$1\times 1$å·ç§¯å±‚ï¼Œå³$k_h=k_w=1$çœ‹èµ·æ¥ä¼¼ä¹æ²¡æœ‰å¤šå¤§æ„ä¹‰ï¼Œå¤±å»äº†å·ç§¯å±‚çš„ç‰¹çš„åœ¨é«˜åº¦å’Œå®½åº¦ç»´åº¦ä¸Šï¼Œè¯†åˆ«ç›¸é‚»å…ƒç´ é—´ç›¸äº’ä½œç”¨çš„èƒ½åŠ›ã€‚ä½†å®é™…æ˜¯ä¸€ä¸ªå—æ¬¢è¿çš„é€‰æ‹©ï¼Œå®ƒä¸è¯†åˆ«ç©ºé—´æ¨¡å¼ï¼Œåªæ˜¯**èåˆè¾“å…¥é€šé“çš„ä¿¡æ¯**ã€‚

![conv-1x1](https://zh.d2l.ai/_images/conv-1x1.svg)

> ä¸Šå›¾å±•ç¤ºäº†ä½¿ç”¨ 1Ã—1 å·ç§¯æ ¸ä¸ 3 ä¸ªè¾“å…¥é€šé“å’Œ 2 ä¸ªè¾“å‡ºé€šé“çš„äº’ç›¸å…³è®¡ç®—ã€‚ è¿™é‡Œè¾“å…¥å’Œè¾“å‡ºå…·æœ‰ç›¸åŒçš„é«˜åº¦å’Œå®½åº¦ï¼Œ**è¾“å‡ºä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä»è¾“å…¥å›¾åƒä¸­åŒä¸€ä½ç½®çš„å…ƒç´ çš„çº¿æ€§ç»„åˆã€‚ æˆ‘ä»¬å¯ä»¥å°† 1Ã—1 å·ç§¯å±‚çœ‹ä½œæ˜¯åœ¨æ¯ä¸ªåƒç´ ä½ç½®åº”ç”¨çš„å…¨è¿æ¥å±‚**ï¼Œä»¥ ci ä¸ªè¾“å…¥å€¼è½¬æ¢ä¸º co ä¸ªè¾“å‡ºå€¼ã€‚ å› ä¸ºè¿™ä»ç„¶æ˜¯ä¸€ä¸ªå·ç§¯å±‚ï¼Œæ‰€ä»¥è·¨åƒç´ çš„æƒé‡æ˜¯ä¸€è‡´çš„ã€‚ åŒæ—¶ï¼Œ 1Ã—1 å·ç§¯å±‚éœ€è¦çš„æƒé‡ç»´åº¦ä¸º coÃ—ci ï¼Œå†é¢å¤–åŠ ä¸Šä¸€ä¸ªåç½®ã€‚

## äºŒç»´å·ç§¯å±‚

- è¾“å…¥$\bf X$ï¼š$c_i\times n_h\times n_w$
- æ ¸$\bf W$ï¼š$c_o\times c_i\times k_h\times k_w$
- åå·®$\bf B$ï¼š$c_o\times c_i$
- è¾“å‡º$\bf Y$ï¼š$c_o\times m_h\times m_w$

$$\bf Y=X\star W+B$$

- è®¡ç®—å¤æ‚åº¦ï¼ˆæµ®ç‚¹è®¡ç®—æ•° FLOPï¼‰ï¼š$O(c_ic_ok_hk_wm_hm_w)$

$$
\begin{aligned}
    c_i&=c_o=100\\
    k_h&=h_w=5 \qquad \rightarrow \text{1GFLOP}\\
    m_h&=m_w=64
\end{aligned}
$$

> å‡è®¾æœ‰ 10 å±‚è¿™æ ·çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œ1Mï¼ˆç™¾ä¸‡ï¼‰æ ·æœ¬ï¼Œåˆ™æ€»çš„è®¡ç®—å¤æ‚åº¦ä¸º 10PFlopsï¼Œä¸€èˆ¬ CPU è®¡ç®—èƒ½åŠ›ä¸º 0.15TFLOPS/sï¼Œè¯¥ç¥ç»ç½‘ç»œä½¿ç”¨ CPU å‰å‘è®¡ç®—æ—¶é—´åˆ™ä¸º 18hï¼›ä¸€èˆ¬ GPU è®¡ç®—èƒ½åŠ›ä¸º 12TF/sï¼Œåˆ™ GPU éœ€è¦ 14minã€‚CNN ç›¸å½“äºç”¨è®¡ç®—é‡æ¢å­˜å‚¨æˆæœ¬ã€‚

## æ€»ç»“

ä»¥ RGB ä¸‰é€šé“è¾“å…¥ã€å¤šè¾“å‡ºä¸ºä¾‹ï¼š

- è¾“å‡ºé€šé“æ•°æ˜¯è¯¥å±‚å·ç§¯å±‚çš„è¶…å‚æ•°
- æ¯ä¸ªè¾“å…¥é€šé“æœ‰ç‹¬ç«‹çš„äºŒç»´å·ç§¯æ ¸ï¼Œæ‰€æœ‰é€šé“ç»“æœç›¸åŠ å¾—åˆ°ä¸€ä¸ªè¾“å‡ºé€šé“ç»“æœ
- æ¯ä¸ªè¾“å‡ºé€šé“æœ‰ç‹¬ç«‹çš„ä¸‰ç»´å·ç§¯æ ¸

## ä»£ç å®ç°

- å¤šè¾“å…¥å¤šè¾“å‡ºé€šé“äº’ç›¸å…³è¿ç®—

```python
import torch
from d2l import torch as d2l
#å¤šè¾“å…¥
def corr2d_multi_in(X, K):
    # å…ˆéå† â€œXâ€ å’Œ â€œKâ€ çš„ç¬¬0ä¸ªç»´åº¦ï¼ˆé€šé“ç»´åº¦ï¼‰ï¼Œå†æŠŠå®ƒä»¬åŠ åœ¨ä¸€èµ·
    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))

# éªŒè¯ï¼Œæ„é€ ä¸€ä¸ª(2x3x3)çš„è¾“å…¥ï¼Œ(2,2,2)çš„å·ç§¯æ ¸
X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],
                  [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])
K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])
K.shape
# Out: torch.Size([2, 2, 2])

corr2d_multi_in(X, K)
# Out: tensor([[ 56.,  72.],
#              [104., 120.]])

#å¤šè¾“å…¥å¤šè¾“å‡º
def corr2d_multi_in_out(X, K):
    # è¿­ä»£â€œKâ€çš„ç¬¬0ä¸ªç»´åº¦ï¼Œæ¯æ¬¡éƒ½å¯¹è¾“å…¥â€œXâ€æ‰§è¡Œäº’ç›¸å…³è¿ç®—ã€‚
    # æœ€åå°†æ‰€æœ‰ç»“æœéƒ½å åŠ åœ¨ä¸€èµ·
    return torch.stack([corr2d_multi_in(X, k) for k in K], dim=0)
# stack():Concatenates a sequence of tensors along a new dimension.
# All tensors need to be of the same size.
# dim=0

# ä½¿ç”¨åŸæœ‰çš„Kåˆ›å»ºä¸€ä¸ªæ‹¥æœ‰ä¸‰ä¸ªè¾“å‡ºé€šé“çš„æ ¸Kï¼Œæ ¸å‚æ•°ä¾æ¬¡å¢1
K = torch.stack((K, K + 1, K + 2), dim=0)
K.shape
# Out: torch.size([3,2,2,2])

corr2d_multi_in_out(X, K)
# Out:tensor([[[ 56.,  72.],
#              [104., 120.]],
#
#             [[ 76., 100.],
#              [148., 172.]],
#
#             [[ 96., 128.],
#              [192., 224.]]])
```

- 1x1 å·ç§¯

```python
def corr2d_multi_in_out_1x1(X, K):
    c_i, h, w = X.shape
    c_o = K.shape[0]
    #æ‹‰æˆä¸€ä¸ªçŸ©é˜µ
    X = X.reshape((c_i, h * w))
    #æ‹‰æˆä¸€ä¸ªçŸ©é˜µ
    K = K.reshape((c_o, c_i))
    #çŸ©é˜µä¹˜æ³•
    Y = torch.matmul(K, X)
    #è¿”å›ä¸‰ç»´
    return Y.reshape((c_o, h, w))

X = torch.normal(0, 1, (3, 3, 3))
K = torch.normal(0, 1, (2, 3, 1, 1))

Y1 = corr2d_multi_in_out_1x1(X, K)
Y2 = corr2d_multi_in_out(X, K)
assert float(torch.abs(Y1 - Y2).sum()) < 1e-6
```

- ç®€æ˜å®ç°

```python
nn.Conv2d(input_channel, output_channel, kernel_size=n, padding, stride)
```

## Pytorch æ¨¡å—å‚è€ƒæ–‡æ¡£

- `torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)`Pytorch 2Då·ç§¯æ¨¡å— ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#_1) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)

---

## Q&AğŸ¤“

**Qï¼šä¸€èˆ¬å·ç§¯çš„å°ºå¯¸å’Œè¾“å‡ºé€šé“è¯¥æ€ä¹ˆè®¾è®¡ï¼Ÿ**

**ğŸ™‹â€â™‚ï¸**ï¼šä¸€èˆ¬å¦‚æœå·ç§¯ä½¿å¾—åŸæœ‰è¾“å…¥é«˜å®½å‡åŠï¼Œé‚£ä¹ˆéœ€è¦å°†é€šé“æ•°å¢åŠ ä¸ºåŸæ¥çš„ 2 å€ï¼Œä»¥é˜²æ­¢å› å‹ç¼©è¿‡å¤šè€Œä¸¢å¤±é‡è¦ä¿¡æ¯ã€‚å¯ä»¥è¿‘ä¼¼çœ‹ä½œå‹ç¼©äº†ç©ºé—´å°ºåº¦ï¼ˆé«˜ã€å®½ï¼‰ï¼Œåˆ™éœ€è¦æ›´å¤šçš„è¯­ä¹‰å°ºåº¦ï¼ˆé€šé“æ•°ï¼‰æ¥è¡¨ç¤ºæå–çš„ç‰¹å¾ã€‚

**Qï¼šå·ç§¯å±‚ä¸­çš„ bias å¯¹ç»“æœå½±å“å¤§å—ï¼Ÿæ€æ ·ç†è§£ bias çš„ä½œç”¨ï¼Ÿ**

**ğŸ™‹â€â™‚ï¸**ï¼šbias çš„ä½œç”¨ç›¸å½“äºå¯¹æ•°æ®çš„åˆ†å¸ƒåšå¹³ç§»ï¼Œå…¶å®åœ¨åæœŸéšç€å„ç§å½’ä¸€åŒ–æ–¹æ³•çš„ä½¿ç”¨ï¼ˆå¦‚ BatchNorm ç­‰ï¼‰ï¼Œbias çš„ä½œç”¨è¶Šæ¥è¶Šå°ï¼Œå› ä¸º bias ç­‰ä»·äºè¾“å…¥æ•°æ®å‡å€¼çš„è´Ÿæ•°ï¼Œè™½ç„¶ä¸è¦ bias ä¹Ÿå¯ä»¥ï¼Œä½†å…¶å®è®¡ç®—æˆæœ¬æ¥è¯´å¯ä»¥å¿½ç•¥ä¸è®¡ï¼ŒåŠ ä¸Šä¹Ÿæ— å¦¨ã€‚
