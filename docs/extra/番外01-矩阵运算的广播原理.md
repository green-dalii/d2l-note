在pyTorch、numpy等框架下进行矩阵（张量）运算时，对象常常是对不同维度（形状）的两个矩阵。在此情况下，就要应用矩阵运算的广播原理。
参见 [Broadcastign in Numpy](https://numpy.org/doc/stable/user/basics.broadcasting.html)

1. 标量和向量

>a = np.array([1.0, 2.0, 3.0])
b = 2.0
a * b
array([ 2.,  4.,  6.])

可以看作标量 $b$ 被拉长成与向量 $\bf a$ 同一长度的向量 $\bf b$

![](Images/番01-01.png)

2. 数组和数组

从后缘维度(trailing dimension)开始比较，或者说靠后的维度，向左做比较，当：
- 维度相同
- 有一个为维度长度为1

就可以进行计算：

>A      (4d array):  8 x 1 x 6 x 1
B      (3d array):      7 x 1 x 5
Result (4d array):  8 x 7 x 6 x 5


![](\Images/番01-03.png)

可以理解为，当有一个维度长度为1的时候，会拉成和另一个维度相同的长度（可以看作增加了一个维度），元素值重复，最终两个数组在各个维度都表现一致，就可以按元素进行运算。

所以需要说明的是
> A: (2d array): 4 x 4
> B: (2d array): 2 x 4

虽然在理解上可以传播，但是实际上是不行的，因为 B 中的行数如果复制一倍，并不是对维度的改变。