# 30 - æ¨¡å‹å¾®è°ƒ Fine-tuning

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‡

[![Bilibil](https://i2.hdslb.com/bfs/archive/5cf6b3c8606c1bdda979ea50bf8c3989912315c1.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1Sb4y1d7CR)

## ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒ/è¿ç§»å­¦ä¹ (Fine-tuning / Transfer Learning)

åœ¨å®é™…å·¥ç¨‹åº”ç”¨ä¸­ï¼Œéœ€è¦æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹ç‰¹å®šçš„ä»»åŠ¡å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§ï¼Œå¦‚æœä»å¤´è®­ç»ƒè¯¥æ¨¡å‹ï¼Œåˆ™éœ€è¦å¤§é‡è¯¥ä»»åŠ¡ä¸“ç”¨çš„æ•°æ®é›†æ‰èƒ½ä½¿æ¨¡å‹æ”¶æ•›åˆ°ä¸€ä¸ªå¯æ¥å—çš„ç»“æœã€‚ä½†æ˜¯è¿™ä¸ªä½“é‡çš„ä¸“ç”¨æ•°æ®é›†çš„æ ‡æ³¨æˆæœ¬ä¹Ÿä¼šå¾ˆé«˜ã€‚

![The-lower-level-features-progressively-combine-to-form-higher-layer-features](Images/The-lower-level-features-progressively-combine-to-form-higher-layer-features-in-deep_Q640.jpg)

å¦ä¸€æ–¹é¢ï¼Œä¾‹å¦‚åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸï¼Œå·²æœ‰è®¸å¤šåœ¨ ImageNet ç­‰å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå…¶**é è¿‘åº•å±‚çš„ç¥ç»å…ƒ**ï¼Œç»è®­ç»ƒå·²å…·å¤‡åŸºæœ¬çš„å›¾åƒç‰¹å¾æå–èƒ½åŠ›ï¼Œè¿™æœ‰åŠ©äºè¯†åˆ«è¾¹ç¼˜ã€çº¹ç†ã€å½¢çŠ¶å’Œå¯¹è±¡ç»„åˆã€‚æˆ‘ä»¬å¯ä»¥åœ¨æ­¤æ¨¡å‹åŸºç¡€ä¸Šï¼Œä½¿ç”¨ç›¸å¯¹å°‘é‡çš„ä¸“æœ‰æ ·æœ¬å†è®­ç»ƒï¼Œå°±å¯ä»¥å¾—åˆ°æ¯”è¾ƒå¥½çš„ç»“æœã€‚

![transfer_learning_vs_traditional learning](Images/1_9GTEzcO8KxxrfutmtsPs3Q.png)

## å¾®è°ƒ

### è®­ç»ƒè¿‡ç¨‹

![finetune](https://zh.d2l.ai/_images/finetune.svg)

- åœ¨æºæ•°æ®é›†ï¼ˆä¾‹å¦‚ ImageNet æ•°æ®é›†ï¼‰ä¸Šé¢„è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå³æºæ¨¡å‹ã€‚
- åˆ›å»ºä¸€ä¸ªæ–°çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå³ç›®æ ‡æ¨¡å‹ã€‚**å¤åˆ¶æºæ¨¡å‹ä¸Šçš„æ‰€æœ‰æ¨¡å‹è®¾è®¡åŠå…¶å‚æ•°ï¼ˆè¾“å‡ºå±‚é™¤å¤–ï¼‰**ã€‚æˆ‘ä»¬å‡å®šè¿™äº›æ¨¡å‹å‚æ•°åŒ…å«ä»æºæ•°æ®é›†ä¸­å­¦åˆ°çš„çŸ¥è¯†ï¼Œè¿™äº›çŸ¥è¯†ä¹Ÿå°†é€‚ç”¨äºç›®æ ‡æ•°æ®é›†ã€‚æˆ‘ä»¬è¿˜å‡è®¾æºæ¨¡å‹çš„è¾“å‡ºå±‚ä¸æºæ•°æ®é›†çš„æ ‡ç­¾å¯†åˆ‡ç›¸å…³ï¼›å› æ­¤ä¸åœ¨ç›®æ ‡æ¨¡å‹ä¸­ä½¿ç”¨è¯¥å±‚ã€‚
- å‘ç›®æ ‡æ¨¡å‹æ·»åŠ è¾“å‡ºå±‚ï¼Œå…¶è¾“å‡ºæ•°æ˜¯ç›®æ ‡æ•°æ®é›†ä¸­çš„ç±»åˆ«æ•°ã€‚ç„¶åéšæœºåˆå§‹åŒ–è¯¥å±‚çš„æ¨¡å‹å‚æ•°ã€‚
- åœ¨ç›®æ ‡æ•°æ®é›†ï¼ˆå¦‚æ¤…å­æ•°æ®é›†ï¼‰ä¸Šè®­ç»ƒç›®æ ‡æ¨¡å‹ã€‚è¾“å‡ºå±‚å°†ä»å¤´å¼€å§‹è¿›è¡Œè®­ç»ƒï¼Œè€Œæ‰€æœ‰å…¶ä»–å±‚çš„å‚æ•°å°†æ ¹æ®æºæ¨¡å‹çš„å‚æ•°è¿›è¡Œå¾®è°ƒã€‚
- æ˜¯ä¸€ä¸ªç›®æ ‡æ•°æ®é›†ä¸Šçš„æ­£å¸¸è®­ç»ƒä»»åŠ¡ï¼Œä½†ä½¿ç”¨**æ›´å¼ºçš„æ­£åˆ™åŒ–**
  - ä½¿ç”¨**æ›´å°çš„å­¦ä¹ ç‡**
  - ä½¿ç”¨**æ›´å°‘çš„æ•°æ®è¿­ä»£**
  - ä½¿ç”¨**æ›´å°‘çš„ epoch**
- æºæ•°æ®é›†è¿œå¤æ‚äºç›®æ ‡æ•°æ®ï¼ˆä¾‹å¦‚ç›¸å·® 10 å€ä»¥ä¸Šï¼‰ï¼Œé€šå¸¸å¾®è°ƒæ•ˆæœæ›´å¥½

### å¸¸ç”¨æŠ€æœ¯

#### é‡ç”¨åˆ†ç±»å™¨æƒé‡

- æºæ•°æ®é›†å¯èƒ½ä¹Ÿæœ‰ç›®æ ‡æ•°æ®ä¸­çš„éƒ¨åˆ†æ ‡å·
- å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒå¥½æ¨¡å‹åˆ†ç±»å™¨ä¸­å¯¹åº”æ ‡å·å¯¹åº”çš„å‘é‡æ¥åšåˆå§‹åŒ–

#### å›ºå®šä¸€äº›å±‚

- ç¥ç»ç½‘ç»œé€šå¸¸å­¦ä¹ æœ‰å±‚æ¬¡çš„ç‰¹å¾è¡¨ç¤º
  - ä½å±‚æ¬¡çš„ç‰¹å¾æ›´åŠ é€šç”¨
  - é«˜å±‚æ¬¡çš„ç‰¹å¾åˆ™è·Ÿæ•°æ®é›†ç›¸å…³
- å¯ä»¥å›ºå®šåº•éƒ¨ä¸€äº›å±‚çš„å‚æ•°ï¼Œä¸å‚ä¸æ›´æ–°
  - æ›´å¼ºçš„æ­£åˆ™

### æ€»ç»“

- å¾®è°ƒé€šè¿‡ä½¿ç”¨åœ¨å¤§æ•°æ®é›†ä¸Šå¾—åˆ°çš„é¢„è®­ç»ƒå¥½çš„æ¨¡å‹æ¥åˆå§‹åŒ–æ¨¡å‹æƒé‡æ¥å®Œæˆç²¾åº¦æå‡ï¼Œç›¸å½“äºä½¿ç”¨äº†**å…ˆéªŒçŸ¥è¯†**ï¼Œä¹Ÿç›¸å½“äºå°†æ¨¡å‹åˆå§‹åŒ–åœ¨ä¸€ä¸ªè·ç¦»æœ€ä¼˜è§£é™„è¿‘çš„ä¸€ä¸ªâ€œæ¨¡å‹åˆå§‹åŒ–â€æ–¹æ³•
- é¢„è®­ç»ƒæ¨¡å‹è´¨é‡å¾ˆé‡è¦ï¼ˆæ¯”å¦‚ä¸€èˆ¬é€‰æ‹© ImageNet ä¸Šé¢„è®­ç»ƒçš„ ResNet50 ç­‰ï¼‰
- å¾®è°ƒé€šå¸¸é€Ÿåº¦æ›´å¿«ã€ç²¾åº¦æ›´é«˜

## ä»£ç å®ç°

- è½½å…¥æ•°æ®é›†

```python
d2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip', 'fba480ffa8aa7e0febbb511d181409f899b9baa5')

data_dir = d2l.download_extract('hotdog')
# ä½¿ç”¨datasets.ImageFolderè½½å…¥æ•°æ®é›†
train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))
test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'))

hotdogs = [train_imgs[i][0] for i in range(8)]
not_hotdogs = [train_imgs[-i - 1][0] for i in range(8)]
#æ˜¾ç¤ºæœ€åå…«å¼ å›¾ç‰‡ï¼Œå†™æ³•å¯ä»¥å‚è€ƒ
d2l.show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4)
```

![hot-dogs](https://zh.d2l.ai/_images/output_fine-tuning_368659_30_0.png)

- æ•°æ®å¢å¹¿

```python
# å°†tensoræ¯ä¸ªé€šé“æ­£åˆ™åŒ–ä¸ºå‡å€¼ä¸º[R,G,B]ï¼Œæ–¹å·®ä¸º[a,b,c]
# æ­¤æ“ä½œæ˜¯ä¸ºé€‚é…ImageNeté¢„è®­ç»ƒæ¨¡å‹çš„æ•°æ®å¤„ç†æ–¹æ³•
normalize = torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])

# é€‚é…ImageNetçš„å°ºå¯¸ï¼ˆ224x224ï¼‰
train_augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomResizedCrop(224),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(), normalize
])
# å› ä¸ºå›¾åƒé«˜å®½æ¯”éƒ½ä¸ä¸€æ ·ï¼Œæ‰€ä»¥å…ˆç¼©æ”¾åœ¨ä»ä¸­æˆªå–
test_augs = torchvision.transforms.Compose([
    torchvision.transforms.Resize(256),
    torchvision.transforms.CenterCrop(224),
    torchvision.transforms.ToTensor(), normalize
])
```

- è½½å…¥é¢„è®­ç»ƒæ¨¡å‹

```python
# æå–è®­ç»ƒæ¨¡å‹&ç»éªŒ
# pretrained=True è½½å…¥é¢„è®­ç»ƒæƒé‡
pretrained_net = torchvision.models.resnet18(pretrained=True)
# æ‰“å°æœ€åä¸€å±‚å…¨è¿æ¥å±‚ç»“æ„
pretrained_net.fc
# Out:
# Linear(in_features=512, out_features=1000, bias=True)
```

- è½½å…¥å¹¶åˆå§‹åŒ– fine-tune æ¨¡å‹

```python
finetune_net = torchvision.models.resnet18(pretrained=True)
#é‡å®šä¹‰å…¨è¿æ¥å±‚ï¼Œinput_featuresä¸å˜ï¼Œoutput_labels=2ï¼Œè¡¨ç¤ºäºŒåˆ†ç±»
finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2)
# éšæœºåˆå§‹åŒ–FCå±‚å‚æ•°
nn.init.xavier_uniform_(finetune_net.fc.weight)
```

- å¾®è°ƒæ¨¡å‹

```python
#å®šä¹‰è®­ç»ƒå‡½æ•°
def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, param_group=True):
    # è½½å…¥è®­ç»ƒæ•°æ®é›†
    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'train'), transform=train_augs),
        batch_size=batch_size, shuffle=True)
    # è½½å…¥æµ‹è¯•æ•°æ®é›†
    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'test'), transform=test_augs),
        batch_size=batch_size)
    devices = d2l.try_all_gpus()
    loss = nn.CrossEntropyLoss(reduction="None")
    # æŒ‡å®šå‚æ•°åŒºåˆ†è®­ç»ƒ
    if param_group:
        #æŠŠéå…¨è¿æ¥å±‚çš„å‚æ•°æå–å‡ºæ¥
        params_1x = [param for name, param in net.named_parameters()
                   if name not in ["fc.weight", 'fc.bias']]
        # æŒ‡å®šä¸åŒå±‚å‚æ•°çš„å­¦ä¹ ç‡
        # å…¨è¿æ¥å±‚åå€å­¦ä¹ ç‡ï¼Œä½¿ç”¨æƒé‡è¡°å‡
        # SGDä¼ å…¥çš„æ˜¯å­—å…¸ï¼Œkeysæ˜¯å‚æ•°åç§°ã€‚
        # params: iterable of parameters to optimize or dicts defining parameter groups
        trainer = torch.optim.SGD([{'params': params_1x},
                                  {'params': net.fc.parameters(),
                                   'lr': learning_rate * 10}],
                                 lr=learning_rate, weight_decay=0.001)
    else:
        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)
    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)
```

- å¼€å§‹å¾®è°ƒ

```python
train_fine_tuning(finetune_net, 5e-5)
# Out:
# loss 0.220, train acc 0.926, test acc 0.935
# 820.7 examples/sec on [device(type='cuda', index=0), device(type='cuda', index=1)]
```

![output_fine-tuning](https://zh.d2l.ai/_images/output_fine-tuning_368659_82_1.svg)

## Pytorch æ¨¡å—å‚è€ƒæ–‡æ¡£

- `torchvision.datasets.ImageFolder` torchvison ä»æ–‡ä»¶å¤¹å†…æ„é€ æ•°æ®é›†æ–¹æ³• ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/torchvision/torchvision-datasets/#imagefolder) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.DatasetFolder)
- `torchvision.transforms.Normalize` torchvison ä¸­å›¾ç‰‡æ­£åˆ™æ–¹æ³• ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/torchvision/torchvision-transform/) | [å®˜æ–¹è‹±æ–‡](http://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html)
- `torch.nn.init` Pytorch å‚æ•°åˆå§‹åŒ–ç›¸å…³æ–¹æ³• ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/nn_init/) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/nn.init.html)
