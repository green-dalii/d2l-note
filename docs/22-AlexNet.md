# 22 - æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œAlexNet

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰
[![Bilibil](https://i2.hdslb.com/bfs/archive/d3ac6a33084e673003dfd4f16685419e891d1bc9.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1h54y1L7oe)
### deep learning å‘å±•å†ç¨‹

2000~ æ ¸æ–¹æ³•ï¼šæœ‰ä¸€å¥—å®Œæ•´çš„æ•°å­¦æ¨¡å‹ï¼ŒSVM

2000~ å‡ ä½•å­¦ï¼šæŠŠè®¡ç®—æœºè§†è§‰çš„é—®é¢˜æè¿°æˆå‡ ä½•é—®é¢˜

2010~ ç‰¹å¾å·¥ç¨‹ï¼šå¦‚ä½•æŠ½å–å›¾ç‰‡çš„ç‰¹å¾ï¼ŒSIFT

**æ ¸å¿ƒæ˜¯æ•°æ®**

Eg: ImageNet(2010)

è‡ªç„¶ç‰©ä½“çš„å½©è‰²å›¾: 469X387;
æ ·æœ¬æ•°ï¼š1.2M
ç±»æ•°ï¼š1000

### AlexNet

èµ¢äº†2012å¹´çš„ImageNetç«èµ›ï¼›
æ›´æ·±æ›´å¤§çš„LeNetï¼›
ä¸»è¦æ”¹è¿›ï¼šä¸¢å¼ƒæ³•ã€ReLUã€MaxPooling
è®¡ç®—æœºè§†è§‰æ–¹æ³•è®ºçš„æ”¹å˜ï¼šä»äººå·¥æå–ç‰¹å¾ï¼ˆSVMï¼‰åˆ°è‡ªåŠ¨è·å¾—ç‰¹å¾ï¼ˆCNNï¼‰ï¼Œåˆ†ç±»å™¨å’Œç‰¹å¾æå–åŒæ—¶è®­ç»ƒï¼›å¹¶ä¸”æ„é€ CNNç®€å•é«˜æ•ˆâ€”â€”ä»åŸå§‹æ•°æ®ï¼ˆå­—ç¬¦ä¸²ã€åƒç´ ï¼‰åˆ°æœ€ç»ˆå­¦ä¹ ç»“æœã€‚

**åŸºæœ¬æ¶æ„**
![](\Images/1_3B8iO-se13vA2QfZ4OBRSw.png)

![](\Images/1_bD_DMBtKwveuzIkQTwjKQQ.png)

$$
\begin{array}{l}
Input:X=(3,224,224)\\
Conv1:kernel=11\times11,stride=4\rightarrow X=(96,55,55)\\
MaxPool1:kernel=3\times3,stride=2\rightarrow X=(256,27,27)\\
Conv2:kernel=5\times5,stride=2\rightarrow X=(384,13,13)\\
MaxPool2:kernel=3\times3,stride=2\rightarrow X=(384,13,13)\\
Conv3:3\times3\\
Conv4:3\times3\\
Conv5:3\times3\\
MaxPool3:3\times3\\
Dense1:4096\\
Dense2:4096\\
Dense3:1000
\end{array}
$$

**Details**

- ä»Sigmoid(LeNet)å˜åˆ°äº†ReLUï¼ˆå‡ç¼“æ¢¯åº¦æ¶ˆå¤±ï¼‰ï¼›
- åœ¨å…¨è¿æ¥å±‚ååŠ å…¥äº†ä¸¢å¼ƒå±‚(dropout)ï¼›
- æ•°æ®å¢å¼º

**æ€»ç»“**

AlexNetæ˜¯æ›´å¤§æ›´æ·±çš„LeNetï¼Œ10xå‚æ•°ä¸ªæ•°ï¼Œ260xè®¡ç®—å¤æ‚åº¦ï¼›

æ–°è¿›å…¥äº†ä¸¢å¼ƒæ³•ã€LeRUã€æœ€å¤§æ± åŒ–å±‚å’Œæ•°æ®å¢å¼ºï¼›

AlexNetå½“èµ¢ä¸‹äº†2012ImageNetç«èµ›åï¼Œæ ‡å¿—ç€æ–°çš„ä¸€è½®ç¥ç»ç½‘ç»œçƒ­æ½®çš„å¼€å§‹ã€‚

### ä»£ç å®ç°

```
import torch
from torch import nn
from d2l import torch as d2l
#ç½‘ç»œ
net = nn.Sequential(
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),
    nn.Linear(6400, 4096), nn.ReLU(), nn.Dropout(p=0.5),
    #Dropout(p=0.5)==>50%è¾“å‡ºä¸ºé›¶ï¼Œå‰©ä¸‹çš„ä¹˜2
    nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p=0.5),
    nn.Linear(4096,10)
)
```
```
#æµ‹è¯•
X = torch.randn(1, 1, 224, 224)
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__, 'Output shape:\t', X.shape)
```
```
batch_size = 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
#æˆ‘ä»¬å°†å®ƒä»¬ä»åŸæ¥çš„28x28å¢åŠ åˆ°224x224
#äº‹å®ä¸Šä¸å¯å–çš„ï¼Œå› ä¸ºæ²¡æœ‰å¢å¤§ä¿¡æ¯é‡
lr, num_epochs = 0.01, 10
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```