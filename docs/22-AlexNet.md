# 22 - æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ AlexNet

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‡

[![Bilibil](https://i2.hdslb.com/bfs/archive/d3ac6a33084e673003dfd4f16685419e891d1bc9.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1h54y1L7oe)

## æœºå™¨å­¦ä¹ å‘å±•å†ç¨‹

### æœºå™¨å­¦ä¹ ç†è®ºçš„å‘å±•

![ml_history](Images/ml_history.png)

- 2000 å¹´å‰åï¼š**æ ¸æ–¹æ³•**ï¼Œæœ‰ä¸€å¥—å®Œæ•´çš„æ•°å­¦æ¨¡å‹ï¼Œå¦‚ SVM
- 2000 å¹´å‰åï¼š**å‡ ä½•å­¦**ï¼ŒæŠŠè®¡ç®—æœºè§†è§‰çš„é—®é¢˜æè¿°æˆå‡ ä½•é—®é¢˜ï¼Œå¦‚ç»å…¸ CV ç®—æ³•
- 2010 å‰åï¼š **ç‰¹å¾å·¥ç¨‹**ï¼šå¦‚ä½•æŠ½å–å›¾ç‰‡çš„ç‰¹å¾ï¼Œå¦‚ SIFTã€è§†è§‰è¯è¢‹

### è®¡ç®—æœºç¡¬ä»¶çš„å¿«é€Ÿå‘å±•

![moores_law](Images/moores_law.jpg)

æ‘©å°”å®šå¾‹å±•ç¤ºäº†åŠå¯¼ä½“æŠ€æœ¯è¿›æ­¥å¸¦æ¥çš„è®¡ç®—èƒ½åŠ›çš„çªé£çŒ›è¿›ã€‚

### äº’è”ç½‘çš„å‘å±•å¸¦æ¥æ•°æ®é‡çš„å¢é•¿

- ImageNet(2010)

![imagenet](Images/imagenet.jpg)

è‡ªç„¶ç‰©ä½“çš„å½©è‰²å›¾: 469X387;
æ ·æœ¬æ•°ï¼š1.2M
ç±»æ•°ï¼š1000

## AlexNet

Alex Krizhevskyã€Ilya Sutskever å’Œ Geoff Hinton æå‡ºäº†ä¸€ç§æ–°çš„å·ç§¯ç¥ç»ç½‘ç»œå˜ä½“ AlexNetã€‚åœ¨ 2012 å¹´ ImageNet æŒ‘æˆ˜èµ›ä¸­å–å¾—äº†è½°åŠ¨ä¸€æ—¶çš„æˆç»©ã€‚

- èµ¢äº† 2012 å¹´çš„ ImageNet ç«èµ›ï¼›
- æ›´æ·±æ›´å¤§çš„ LeNetï¼›
- ä¸»è¦æ”¹è¿›ï¼š
  - ä¸¢å¼ƒæ³•
  - ReLUï¼ˆå‡ç¼“æ¢¯åº¦æ¶ˆå¤±ï¼‰
  - MaxPoolingï¼ˆå¢å¤§è¾“å‡ºå€¼ï¼Œå¸¦æ¥æ›´å¤§çš„æ¢¯åº¦ï¼‰
  - ä½¿ç”¨äº†**æ•°æ®å¢å¼º**ï¼ˆData Argumentsï¼‰
- **è®¡ç®—æœºè§†è§‰æ–¹æ³•è®ºçš„æ”¹å˜**ï¼šä»äººå·¥æå–ç‰¹å¾ï¼ˆSVMï¼‰åˆ°é€šè¿‡CNNå­¦ä¹ è·å¾—ç‰¹å¾ï¼Œç«¯åˆ°ç«¯å­¦ä¹ ï¼›å¹¶ä¸”æ„é€  CNN ç®€å•é«˜æ•ˆâ€”â€”ä»åŸå§‹æ•°æ®ï¼ˆå­—ç¬¦ä¸²ã€åƒç´ ï¼‰åˆ°æœ€ç»ˆå­¦ä¹ ç»“æœã€‚

### åŸºæœ¬æ¶æ„

![alexnet](Images/1_3B8iO-se13vA2QfZ4OBRSw.png)

- AlexNetä¸LeNetæ¶æ„å¯¹æ¯”

![lenet&alexnet](https://zh.d2l.ai/_images/alexnet.svg)

### å¤æ‚åº¦

| |å‚æ•°ä¸ªæ•°| |FLOP| |
|--|--|--|--|--|
|  |**AlexNet**|**LeNet**|**AlexNet**|**LeNet**|
|Cov1|35K|150|101M|1.2M|
|Cov2|614K|2.4K|415M|2.4M|
|Cov3-5|3M||445M||
|Dense1|26M|0.48M|26M|0.48M|
|Dense2|16M|0.1M|16M|0.1M|
|**Total**|**46M**|**0.6M**|**1G**|**4M**|
|**Increase**|**76x**|1x(baseline)|**250x**|1x(baseline)|

### æ€»ç»“

- AlexNet æ˜¯æ›´å¤§æ›´æ·±çš„ LeNetï¼Œ10x å‚æ•°ä¸ªæ•°ï¼Œ260x è®¡ç®—å¤æ‚åº¦ï¼›
- æ–°åŠ å…¥äº†ä¸¢å¼ƒæ³•ã€LeRUã€æœ€å¤§æ± åŒ–å±‚å’Œæ•°æ®å¢å¼ºï¼›
- AlexNet å½“èµ¢ä¸‹äº† 2012ImageNet ç«èµ›åï¼Œæ ‡å¿—ç€æ–°çš„ä¸€è½®ç¥ç»ç½‘ç»œçƒ­æ½®çš„å¼€å§‹ã€‚

## ä»£ç å®ç°

- å®šä¹‰ç½‘ç»œç»“æ„

```python
import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(
    # å› ä¸ºè¯¾ç¨‹ä½¿ç”¨çš„FashioMNISTæ•°æ®é›†ï¼Œä¸ºç°åº¦å•é€šé“å›¾åƒ
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),
    nn.Linear(6400, 4096), nn.ReLU(), nn.Dropout(p=0.5),
    nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p=0.5),
    nn.Linear(4096,10)
)
```

- æµ‹è¯•å„å±‚è¾“å‡º

```python
X = torch.randn(1, 1, 224, 224)
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__, 'Output shape:\t', X.shape)

# Out: 
# Conv2d output shape:         torch.Size([1, 96, 54, 54])
# ReLU output shape:   torch.Size([1, 96, 54, 54])
# MaxPool2d output shape:      torch.Size([1, 96, 26, 26])
# Conv2d output shape:         torch.Size([1, 256, 26, 26])
# ReLU output shape:   torch.Size([1, 256, 26, 26])
# MaxPool2d output shape:      torch.Size([1, 256, 12, 12])
# Conv2d output shape:         torch.Size([1, 384, 12, 12])
# ReLU output shape:   torch.Size([1, 384, 12, 12])
# Conv2d output shape:         torch.Size([1, 384, 12, 12])
# ReLU output shape:   torch.Size([1, 384, 12, 12])
# Conv2d output shape:         torch.Size([1, 256, 12, 12])
# ReLU output shape:   torch.Size([1, 256, 12, 12])
# MaxPool2d output shape:      torch.Size([1, 256, 5, 5])
# Flatten output shape:        torch.Size([1, 6400])
# Linear output shape:         torch.Size([1, 4096])
# ReLU output shape:   torch.Size([1, 4096])
# Dropout output shape:        torch.Size([1, 4096])
# Linear output shape:         torch.Size([1, 4096])
# ReLU output shape:   torch.Size([1, 4096])
# Dropout output shape:        torch.Size([1, 4096])
# Linear output shape:         torch.Size([1, 10])
```

- è®­ç»ƒ

```python
batch_size = 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)

lr, num_epochs = 0.01, 10
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```

![output_alexnet](https://zh.d2l.ai/_images/output_alexnet_180871_32_1.svg)

---

## Q&AğŸ¤“

**Qï¼šä½¿ç”¨GPUè®­ç»ƒAlexNetæ—¶ï¼ŒæŠ¥é”™`CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling cublasCreate(handle)`æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿ**

**ğŸ™‹â€â™‚ï¸**ï¼šä¸€èˆ¬æ˜¯æ˜¾å¡æ˜¾å­˜ä¸å¤Ÿäº†ï¼Œå¯ä»¥å°è¯•å°†`batch_size`è°ƒå°ä¸€äº›è¯•è¯•ã€‚

**Qï¼šä¸€èˆ¬CNNè¦æ±‚è¾“å…¥å›¾åƒæ˜¯å›ºå®šå°ºå¯¸ï¼Œå®é™…åº”ç”¨ä¸­ï¼Œæ•°æ®å°ºå¯¸ä¸ä¸€ï¼Œä¼šæ€æ ·å¤„ç†ï¼Ÿå¼ºè¡Œ`resize`å—ï¼Ÿ**

**ğŸ™‹â€â™‚ï¸**ï¼šä¸€èˆ¬ä¸ä¼šå¼ºè¡Œresizeï¼Œå¦åˆ™ä¼šæ”¹å˜å›¾åƒç‰¹å¾ï¼Œè€Œæ˜¯ä¿æŒé•¿å®½æ¯”ä¸å˜çš„resizeï¼Œåœ¨å…¶ä¸­cropå‡ºç¬¦åˆè¦æ±‚çš„å°ºå¯¸æ¥ã€‚
