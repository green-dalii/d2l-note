# 26 - æ‰¹é‡å½’ä¸€åŒ–

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‡

[![Bilibil](https://i2.hdslb.com/bfs/archive/c52c4d88d8fe65f6d2ffac27b8ce6cb02dcdcacc.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1X44y1r77r)

## ç½‘ç»œè¶Šæ·±äº§ç”Ÿçš„é—®é¢˜

- åå‘ä¼ æ’­ï¼ŒæŸå¤±çš„æ¢¯åº¦ä»è¾“å‡ºå±‚å‘åä¼ ï¼Œé è¿‘è¾“å‡ºçš„å±‚è®­ç»ƒè¾ƒå¿«
  - æ¢¯åº¦å¾€ä¸‹è¶Šä¼ é€’è¶Šå°ï¼ˆå°æ•°ç›¸ä¹˜ï¼‰
- æ•°æ®åœ¨æœ€åº•éƒ¨
  - é è¿‘æ•°æ®çš„åº•éƒ¨å±‚è®­ç»ƒè¾ƒæ…¢
  - åº•éƒ¨å±‚ä¸€å˜åŒ–ï¼Œæ‰€æœ‰éƒ½å¾—è·Ÿç€å˜ï¼Œç›¸å½“äºä½å±‚ç‰¹å¾æ”¹å˜ï¼Œä¸æ–­æŠ½è±¡å¾—åˆ°çš„é«˜å±‚ç‰¹å¾ä¹Ÿä¼šéšä¹‹æ”¹å˜
  - é¡¶éƒ¨çš„é‚£äº›å±‚éœ€è¦é‡æ–°å­¦ä¹ å¤šæ¬¡
  - å¯¼è‡´æ”¶æ•›å˜æ…¢

å¯¹äºå…¸å‹çš„å¤šå±‚æ„ŸçŸ¥æœºæˆ–å·ç§¯ç¥ç»ç½‘ç»œã€‚å½“æˆ‘ä»¬è®­ç»ƒæ—¶ï¼Œä¸­é—´å±‚ä¸­çš„å˜é‡ï¼ˆä¾‹å¦‚ï¼Œå¤šå±‚æ„ŸçŸ¥æœºä¸­çš„ä»¿å°„å˜æ¢è¾“å‡ºï¼‰å¯èƒ½å…·æœ‰æ›´å¹¿çš„å˜åŒ–èŒƒå›´ï¼šä¸è®ºæ˜¯æ²¿ç€ä»è¾“å…¥åˆ°è¾“å‡ºçš„å±‚ï¼Œè·¨åŒä¸€å±‚ä¸­çš„å•å…ƒï¼Œæˆ–æ˜¯éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæ¨¡å‹å‚æ•°çš„éšç€è®­ç»ƒæ›´æ–°å˜å¹»è«æµ‹ã€‚ æ‰¹é‡å½’ä¸€åŒ–çš„å‘æ˜è€…éæ­£å¼åœ°å‡è®¾ï¼Œè¿™äº›å˜é‡åˆ†å¸ƒä¸­çš„è¿™ç§åç§»å¯èƒ½ä¼šé˜»ç¢ç½‘ç»œçš„æ”¶æ•›ã€‚ ç›´è§‚åœ°è¯´ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šçŒœæƒ³ï¼Œå¦‚æœä¸€ä¸ªå±‚çš„å¯å˜å€¼æ˜¯å¦ä¸€å±‚çš„ 100 å€ï¼Œè¿™å¯èƒ½éœ€è¦å¯¹å­¦ä¹ ç‡è¿›è¡Œè¡¥å¿è°ƒæ•´ã€‚

åŒæ—¶ï¼Œæ›´æ·±å±‚çš„ç½‘ç»œå¾ˆå¤æ‚ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆã€‚ è¿™æ„å‘³ç€æ­£åˆ™åŒ–å˜å¾—æ›´åŠ é‡è¦ã€‚

## å¦‚ä½•è§£å†³

### æ‰¹é‡å½’ä¸€åŒ–ï¼ˆbatch normalizationï¼‰

æ‰¹é‡å½’ä¸€åŒ–ï¼ˆbatch normalizationï¼‰ [[Ioffe & Szegedy, 2015]](https://arxiv.org/abs/1502.03167)ï¼Œæ˜¯ä¸€ç§æµè¡Œä¸”æœ‰æ•ˆçš„æŠ€æœ¯ï¼Œå¯æŒç»­åŠ é€Ÿæ·±å±‚ç½‘ç»œçš„æ”¶æ•›é€Ÿåº¦ã€‚ å†ç»“åˆåæœŸä»‹ç»çš„æ®‹å·®å—ï¼Œæ‰¹é‡å½’ä¸€åŒ–ä½¿å¾—ç ”ç©¶äººå‘˜èƒ½å¤Ÿè®­ç»ƒ100å±‚ä»¥ä¸Šçš„ç½‘ç»œã€‚

æ‰¹é‡è§„èŒƒåŒ–åº”ç”¨äºå•ä¸ªå¯é€‰å±‚ï¼ˆä¹Ÿå¯ä»¥åº”ç”¨åˆ°æ‰€æœ‰å±‚ï¼‰ï¼Œå…¶åŸç†å¦‚ä¸‹ï¼šåœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè§„èŒƒåŒ–è¾“å…¥ï¼Œå³é€šè¿‡å‡å»å…¶å‡å€¼å¹¶é™¤ä»¥å…¶æ ‡å‡†å·®ï¼Œå…¶ä¸­ä¸¤è€…å‡åŸºäºå½“å‰å°æ‰¹é‡å¤„ç†ã€‚

æ‰¹é‡å½’ä¸€åŒ–å›ºå®šæ¯ä¸€ä¸ªå°æ‰¹é‡ï¼ˆåœ¨ä¸åŒå±‚è¾“å‡ºï¼‰é‡Œé¢çš„å‡å€¼å’Œæ–¹å·®ï¼š

$$
\mu_B={1 \over |B|} \sum_{i \in B} x_i \\

\sigma_B^2={1 \over |B|} \sum_{i \in B} (x_i-\mu_B)^2 + \epsilon
$$

> å…¶ä¸­$B$æŒ‡ä¸€ä¸ªæ‰¹é‡ Batchï¼Œ$\epsilon$ä¸ºä¸€ä¸ªå¾ˆå°çš„æ•°ï¼Œé˜²æ­¢æ–¹å·®ä¸ºé›¶ï¼Œåœ¨ä¸‹æ–‡æ— æ³•è¿›è¡Œé™¤é›¶è¿ç®—

![s](https://theaisummer.com/static/d42512016d9b99eabb69a61bb295cd50/2e9f9/normalization.png)

ç„¶åå†é€šè¿‡ä¸‹å¼å¯¹æ¯ä¸ªæ‰¹é‡åœ¨ä¸åŒå±‚çš„è¾“å‡ºå€¼æ•°æ®åšé¢å¤–çš„è°ƒæ•´ï¼Œåº”ç”¨æ¯”ä¾‹ç³»æ•°$\gamma$å’Œæ¯”ä¾‹åç§»$\beta$ï¼Œå°†æ¯å±‚è¾“å‡ºå€¼å›ºå®šä¸ºå‡å€¼ä¸º${\beta}$ã€æ–¹å·®ä¸º${\gamma}$çš„åˆ†å¸ƒï¼š

$$
x_{i+1}=\gamma{x_i-\mu_B \over \sigma_B} + \beta
$$

### æ‰¹é‡å½’ä¸€åŒ–å±‚

- æ¯”ä¾‹ç³»æ•°${\gamma}$å’Œåç§»ç³»æ•°${\beta}$æ˜¯å­¦ä¹ å‡ºæ¥çš„
- æ‰¹é‡å½’ä¸€åŒ–æ˜¯ä¸€ä¸ªçº¿æ€§å˜æ¢
- ä½œç”¨ä½ç½®
  - å…¨è¿æ¥å±‚å’Œå·ç§¯å±‚è¾“å‡ºä¸Šï¼Œ**æ¿€æ´»å‡½æ•°ä¹‹å‰**
    > å› ä¸ºä¸€èˆ¬æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ reluï¼‰ ä¼šå°†æ•°æ®æ˜ å°„ä¸ºæ­£æ•°ï¼Œæ‰€ä»¥ä¸èƒ½å†å¸¦å›æ­£è´Ÿå„å¼‚çš„çŠ¶æ€
  - å…¨è¿æ¥å±‚å’Œå·ç§¯å±‚è¾“å…¥ä¸Š
- å¯¹äºå…¨è¿æ¥å±‚ï¼Œä½œç”¨åœ¨**ç‰¹å¾ç»´**ï¼ˆç‹¬ç«‹æ”¹å˜æ¯ä¸ªç‰¹å¾çš„åˆ†å¸ƒï¼‰
- å¯¹äºå·ç§¯å±‚ï¼Œä½œç”¨äº**é€šé“ç»´**ï¼ˆå³ä¸€ä¸ªæ»‘åŠ¨çª—å£é‡Œåƒç´ çš„ç‰¹å¾ï¼‰

## æ‰¹é‡å½’ä¸€åŒ–çš„ä½œç”¨

- å¯ä»¥**åŠ é€Ÿæ”¶æ•›å¹¶è®©è®­ç»ƒæ›´ç¨³å®š**ï¼ˆå› ä¸ºå¯ä»¥ç”¨æ›´å¤§çš„å­¦ä¹ ç‡ï¼Œè€Œé˜²æ­¢å­¦ä¹ ç‡è¿‡å¤§é€ æˆçš„æ— æ³•æ”¶æ•›æŠ–åŠ¨æˆ–è€…é è¿‘è¾“å‡ºå±‚æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ï¼‰
- ä¸€èˆ¬ä¸æ”¹å˜æ¨¡å‹çš„ç²¾åº¦
- åªæœ‰**æ‰¹é‡è¶³å¤Ÿå¤§**å’Œè¿ç”¨åœ¨æ·±å±‚ç½‘ç»œæ—¶ï¼Œæ‰¹é‡å½’ä¸€åŒ–æ•ˆæœæ‰èƒ½æœ‰æ•ˆä¸”ç¨³å®šã€‚å¦‚æœæˆ‘ä»¬å°è¯•ä½¿ç”¨å¤§å°ä¸º1çš„å°æ‰¹é‡åº”ç”¨æ‰¹é‡è§„èŒƒåŒ–ï¼Œå°†æ— æ³•å­¦åˆ°ä»»ä½•ä¸œè¥¿ã€‚
  > å› ä¸ºåœ¨å‡å»å‡å€¼ä¹‹åï¼Œæ¯ä¸ªéšè—å•å…ƒå°†ä¸º0ã€‚ æ‰€ä»¥ï¼Œåªæœ‰ä½¿ç”¨è¶³å¤Ÿå¤§çš„å°æ‰¹é‡ï¼Œæ‰¹é‡è§„èŒƒåŒ–è¿™ç§æ–¹æ³•æ‰æ˜¯æœ‰æ•ˆä¸”ç¨³å®šçš„ã€‚ è¯·æ³¨æ„ï¼Œåœ¨åº”ç”¨æ‰¹é‡è§„èŒƒåŒ–æ—¶ï¼Œæ‰¹é‡å¤§å°çš„é€‰æ‹©å¯èƒ½æ¯”æ²¡æœ‰æ‰¹é‡è§„èŒƒåŒ–æ—¶æ›´é‡è¦

![bn](Images/batch_norm3.jpg)

> ä¸Šå›¾ä»¥ä½¿ç”¨ VGG ç½‘ç»œä¸ºä¾‹å±•ç¤º BatchNorm çš„æ•ˆæœï¼Œæ©™è‰²ä»£è¡¨æ ‡å‡†ç»“æ„ï¼Œè“è‰²ä»£è¡¨å¢åŠ äº† BatchNorm çš„å¯¹æ¯”ç»“æ„ï¼Œå“çº¢è‰²ä»£è¡¨å¢åŠ äº†â€œNoisy BatchNormâ€çš„å¯¹æ¯”ç»“æ„ã€‚ä»å·¦ä¾§å›¾å¯çœ‹å‡ºåŠ å…¥ BatchNorm åï¼Œè®­ç»ƒç²¾è¯»æ”¶æ•›å¾—æ›´å¿«ï¼ŒåŒæ—¶æŠ–åŠ¨æ›´å°ï¼ˆä½†ä¸æ”¹å˜æœ€ç»ˆçš„ç²¾åº¦ï¼‰ï¼›ä»å³ä¾§å›¾å¯çœ‹å‡ºåŠ å…¥ BatchNorm åï¼Œå„å±‚è¾“å‡ºåˆ†å¸ƒæ›´åŠ â€œå‡è¡¡â€ã€‚

![bn2](Images/batch_norm.jpg)

> é€šè¿‡ä¸Šå›¾å¯¹æ¯”å®éªŒï¼Œå¯ä»¥çœ‹å‡ºä½¿ç”¨ BN åï¼ŒæŸå¤±ä¸‹é™æ›´å¿«æ›´å¹³ç¨³ï¼Œæ¢¯åº¦æŠ–åŠ¨æ›´ç¨³å®šã€‚

### æ‰¹é‡å½’ä¸€åŒ–ä½œç”¨çš„åŸç†

- æœ€åˆçš„è®ºæ–‡è¡¨ç¤ºå¯ä»¥å‡å°‘å†…éƒ¨åå˜é‡è½¬ç§»
- åç»­è®ºæ–‡æŒ‡å‡º batch normalization ç›¸å½“äºåœ¨å°æ‰¹é‡é‡Œ**å¢åŠ å™ªéŸ³**$\mu,\sigma$ï¼Œå¯¹æ•°æ®è¿›è¡Œäº†éšæœºåç§»å’Œç¼©æ”¾ï¼ˆç›®å‰è¿˜æ²¡æœ‰ä¸€ä¸ªç»Ÿä¸€çš„ç»“è®ºï¼‰
- **æ²¡å¿…è¦å’Œä¸¢å¼ƒæ³•æ··åˆä½¿ç”¨**ï¼ˆåœ¨[ç•ªå¤– 04-Kaggle ç«èµ›å®è·µç»éªŒ](extra/ç•ªå¤–04-Kaggleç«èµ›å®è·µç»éªŒ.md)ä¸€ç¯‡ä¸­æœ‰ç›¸å…³å®è·µè¯æ˜ï¼‰

## BatchNormã€LayerNormã€InstanceNormã€GroupNorm åŒºåˆ«

ç›®å‰å¸¸ç”¨çš„æœ‰**BatchNormã€LayerNormã€InstanceNormã€GroupNorm**å››ç§å½’ä¸€åŒ–æ–¹æ³•ã€‚

![norm](Images/normalization.png)

> ä¸Šå›¾ä¸­æ¯ä¸ªç«‹æ–¹ä½“ä»£è¡¨ä¸€ä¸ª Batch çš„æ•°æ®ï¼Œå…¶ä¸­ C ä»£è¡¨ Channel é€šé“ç»´ï¼ŒN ä»£è¡¨ batch ç»´ï¼Œ(H,W)ä»£è¡¨ä¸€ä¸ªç©ºé—´ç»´ï¼ˆä¾‹å¦‚äºŒç»´å›¾åƒï¼‰

- **BatchNorm**ï¼š æ˜¯åœ¨ batch ä¸Šä½œç”¨äºæ¯ä¸ª Channal ç»´çš„å½’ä¸€åŒ–ï¼Œå¤šç”¨äº CNNï¼Œå¯¹å° batchsize æ•ˆæœä¸å¥½
- **LayerNorm**ï¼š åœ¨é€šé“æ–¹å‘ä¸Šä½œç”¨äºä¸€ä¸ª batch ä¸­ä¸€ä¸ªæ ·æœ¬ï¼ˆå¦‚ä¸€å¼ å›¾çš„æ‰€æœ‰é€šé“ï¼‰çš„å½’ä¸€åŒ–ï¼Œä¸»è¦å¯¹ RNN ä½œç”¨æ˜æ˜¾ï¼Œç°å¤šç”¨äº Transformerï¼Œå¯å‚è€ƒç¬”è®° ğŸ‘‰[56-Transformer](56-Transformer.md)
- **InstanceNorm**ï¼š ä½œç”¨äºä¸€ä¸ªæ ·æœ¬çš„ä¸€ä¸ªé€šé“çš„å½’ä¸€åŒ–ï¼Œå¤šç”¨åœ¨é£æ ¼åŒ–è¿ç§»
- **GroupNorm**ï¼š å°† channel åˆ†ç»„ï¼Œç„¶åå†åšå½’ä¸€åŒ–, åœ¨ batchsize<16 çš„æ—¶å€™, å¯ä»¥ä½¿ç”¨è¿™ç§å½’ä¸€åŒ–

![graph-normalization-methods](Images/graph-normalization-methods.png)

> ä¸Šå›¾å±•ç¤ºäº†å„ç§ Normalization çš„è®ºæ–‡ä½¿ç”¨ç‡ï¼Œå¯çœ‹å‡ºéšç€ Transformer åŠå…¶å˜ç§çš„å¹¿æ³›åº”ç”¨ï¼ŒLayerNorm ä½¿ç”¨ç‡é€å¹´å¢é«˜ï¼›ä¸»æµæ–¹æ³•è¿˜æ˜¯ BatchNorm ä¸ LayerNorm

![Results-normalization](Images/Results-normalization-imagenet-resnet50.png)

> ä¸Šå›¾å±•ç¤ºäº†åœ¨ç›¸åŒ ResNet-50 ç½‘ç»œæ¶æ„ä¸‹ï¼Œä¸åŒå½’ä¸€åŒ–æ–¹æ³•çš„éªŒè¯è¯¯å·®æ¯”è¾ƒå›¾ï¼ˆbatch size=64 imagesï¼‰

å…·ä½“å…³äºå››ç§å½’ä¸€åŒ–çš„ç»¼è¿°ï¼Œå¯ä»¥å‚è€ƒ AISummer è¿™ç¯‡æ–‡ç«  ğŸ‘‰[[1]](https://theaisummer.com/normalization/)å’Œè¿™ç¯‡[çŸ¥ä¹](https://zhuanlan.zhihu.com/p/395855181)

## ä»£ç å®ç°

- å®šä¹‰ batch_norm è¿ç®—

```python
import torch
from torch import nn
from d2l import torch as d2l

def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):
    # moving_mean/varå…¨å±€çš„æœŸæœ›å’Œæ–¹å·®ï¼Œè¿‘ä¼¼äºæ•´ä¸ªæ•°æ®é›†ä¸Š
    # epsï¼šå¾ˆå°çš„å›ºå®šå€¼ï¼Œé¿å…é™¤é›¶ï¼Œå¾ˆé‡è¦
    # momentumï¼šç”¨äºæ›´æ–°movingçš„åŠ¨é‡ï¼Œé€šå¸¸å–å›ºå®šå€¼
    if not torch.is_grad_enabled(): #åšinferenceè€Œétrainï¼Œæ‰€ä»¥ä¸æ±‚æ¢¯åº¦
        # ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†çš„å‡å€¼å’Œæ–¹å·®è®¡ç®—
        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)
    else:
        assert len(X.shape) in (2, 4)
        # X.shapeè¾“å…¥è¦ä¹ˆä¸º2ï¼Œä»£è¡¨å…¨è¿æ¥å±‚(batch_samples,features)
        if len(X.shape) == 2:
            #æŒ‰ç‰¹å¾æ±‚å‡å€¼å’Œæ–¹å·®
            mean = X.mean(dim=0)    # æŒ‰è¡Œæ±‚å‡å€¼ï¼Œå°†æ¯åˆ—æ±‚å‡å€¼åå‹ç¼©åˆ°ä¸€è¡Œ
            var = ((X - mean)**2).mean(dim=0)
        # è¦ä¹ˆä¸º4ï¼Œä»£è¡¨2Då·ç§¯å±‚ï¼Œ(batch_samples,channals,w,h)
        else:
            # å¯¹æ¯ä¸€ä¸ªé€šé“çš„å…¨éƒ¨å…ƒç´ æ±‚å‡å€¼æ–¹å·®ï¼Œå¾—åˆ°ä¸€ä¸ª(1,channal_num,1,1)çš„çŸ©é˜µ
            # dimæŒ‡ä»£çš„ç»´æ•°è¡¨æ˜è®¡ç®—åè¯¥ç»´åº¦å‹ç¼©ä¸º1
            mean = X.mean(dim=(0, 2, 3), keepdim=True)
            var = ((X - mean)**2).mean(dim=(0, 2, 3), keepdim=True)

        # å¯¹Xæ¯ä¸ªå…ƒç´ è¿›è¡Œå½’ä¸€åŒ–
        X_hat = (X - mean) / torch.sqrt(var + eps)
        # å¯¹moving_meanã€moving_varåšæ»‘åŠ¨çª—å£å¹³æ»‘æ›´æ–°ï¼Œç±»ä¼¼åŠ¨é‡
        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean
        moving_var = momentum * moving_var + (1.0 - momentum) * var
    Y = gamma * X_hat + beta
    return Y, moving_mean.data, moving_var.data
```

- å®šä¹‰ BatchNorm å±‚

> å› ä¸ºä¾æ®ä¸Šæ–‡æ‰€è¿°ï¼Œgammaã€betaæ˜¯éœ€è¦æ›´æ–°çš„å‚æ•°ï¼Œæ‰€ä»¥éœ€è¦ä½¿ç”¨nn.Parameteræ¥æ„é€ ä¿è¯å¯å­˜å‚¨æ¢¯åº¦ä»è€Œå¯è¢«ä¼˜åŒ–å™¨è¿›è¡Œæ›´æ–°

```python
class BatchNorm(nn.Module):
    def __init__(self, num_features, num_dims):
        super().__init__()
        if num_dims == 2:   # å…¨è¿æ¥å±‚
            shape = (1, num_features)
        else:   # 2Då·ç§¯å±‚
            shape = (1, num_features, 1, 1)
        # gammaå’Œbetaæ˜¯éœ€è¦å‚æ•°å­¦ä¹ çš„å‚æ•°ï¼Œä½¿ç”¨Parameterå­˜å‚¨æ¢¯åº¦
        self.gamma = nn.Parameter(torch.ones(shape))
        self.beta = nn.Parameter(torch.zeros(shape))
        # éœ€è¦ä¸æ–­è¿­ä»£æ‹Ÿåˆçš„å…¨å±€å‡å€¼æ–¹å·®
        # åˆå§‹åŒ–æ—¶ç”±äºæ— æ³•å¾—åˆ°å…¨å±€å€¼ï¼Œé¦–å…ˆç»™å®šä¸€ä¸ªåˆå§‹å€¼
        self.moving_mean = torch.zeros(shape)
        self.moving_var = torch.ones(shape)

    def forward(self, X):
        # æ£€æµ‹moving_mean/varæ‰€åœ¨è®¾å¤‡ï¼Œå¦‚æœä¸æ•°æ®ä¸åœ¨ä¸€èµ·ï¼Œåˆ™ç§»åŠ¨åˆ°æ•°æ®æ‰€åœ¨è®¾å¤‡
        if self.moving_mean.device != X.device:
            self.moving_mean = self.moving_mean.to(X.device)
            self.moving_var = self.moving_var.to(X.device)

        Y, self.moving_mean, self.moving_var = batch_norm(
            X, self.gamma, self.beta, self.moving_mean,
            self.moving_var, eps=1e-5, momentum=0.9)
        return Y
```

- å°† BatchNorm åµŒå¥—è¿›ä¸€ä¸ª LeNet ç¥ç»ç½‘ç»œ

```python
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5), BatchNorm(6, num_dims=4),
    nn.Sigmoid(), nn.MaxPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), BatchNorm(16, num_dims=4),
    nn.Sigmoid(), nn.MaxPool2d(kernel_size=2, stride=2),
    nn.Flatten(), nn.Linear(16 * 4 * 4, 120),
    BatchNorm(120, num_dims=2), nn.Sigmoid(),
    nn.Linear(120, 84), BatchNorm(84, num_dims=2),
    nn.Sigmoid(), nn.Linear(84, 10))
#å¯¹çº¿æ€§å±‚åªæœ‰(256ï¼Œ16*4*4)çŸ©é˜µçš„norm
```

- è®­ç»ƒ

```python
lr, num_epochs, batch_size = 1.0, 10, 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())

# Out:
# loss 0.271, train acc 0.899, test acc 0.862
# 32546.7 examples/sec on cuda:0
```

![output_batch-norm](https://zh.d2l.ai/_images/output_batch-norm_cf033c_42_1.svg)

> å¯¹æ¯”åŸå§‹LeNetç»“æœï¼šå¯çŸ¥æ”¶æ•›æ›´å¿«ï¼Œæ¨ç†é€Ÿåº¦å‡æ…¢20%

```python
# Out:(Original LeNet)
# loss 0.473, train acc 0.823, test acc 0.786
# 40832.5 examples/sec on gpu(0)
```

![output_lenet](https://zh.d2l.ai/_images/output_lenet_4a2e9e_52_1.svg)

```python
# æŸ¥çœ‹netç´¢å¼•ä¸º1çš„batchnormå±‚å‚æ•°
net[1].gamma.reshape((-1,)), net[1].beta.reshape((-1,)) #-1è¡¨ç¤ºè‡ªåŠ¨è®¡ç®—è¡Œï¼Œæ‰€ä»¥é»˜è®¤å¡«å……æ‰€æœ‰åˆ—

# Out:
# (tensor([2.6914, 2.5985, 3.8031, 2.4383, 1.4624, 2.6880], device='cuda:0',
#         grad_fn=<ViewBackward>),
#  tensor([-3.1298,  2.5322, -2.1505,  2.3287,  0.0692,  1.7874], device='cuda:0',
#         grad_fn=<ViewBackward>))
```

- ç®€æ˜å®ç°

```python
#æ³¨æ„1dä¸2dçš„åŒºåˆ«ã€‚
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6),
    nn.Sigmoid(), nn.MaxPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16),
    nn.Sigmoid(), nn.MaxPool2d(kernel_size=2, stride=2),
    nn.Flatten(), nn.Linear(16 * 4 * 4, 120),
    nn.BatchNorm1d(120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.BatchNorm1d(84),
    nn.Sigmoid(), nn.Linear(84, 10))

# nn.Flatten()
#é»˜è®¤ä»ç¬¬1ä¸ªç»´åº¦ï¼ˆè€Œä¸æ˜¯ç¬¬0ç»´ï¼‰å¼€å§‹æ‹‰å¹³ç›´è‡³æœ€åä¸€ä¸ªç»´åº¦
#æ‰€ä»¥Flatten()ä¸€ä¸ªäºŒç»´çŸ©é˜µä¸å‘ç”Ÿä»»ä½•å½¢çŠ¶å˜åŒ–ã€‚
```

## å¡å°”æ›¼æ»¤æ³¢

> åœ¨æ­¤ç¬”è®°åˆç‰ˆæ—¶ï¼Œç†è§£ä»£ç å®ç°æ—¶ï¼Œæˆ‘ä»¬ä»¥ä¸ºåœ¨æ›´æ–°`moving_mean`å’Œ`moving_var`æ—¶é‡‡ç”¨äº†å¡å°”æ›¼æ»¤æ³¢çš„æ€æƒ³ï¼Œæ‰€ä»¥å†™äº†æœ¬æ®µå†…å®¹ï¼Œåæ¥æ ¡è®¢æ—¶å‘ç°å…¶å®ä½¿ç”¨çš„æ˜¯åŠ¨é‡çš„æ€æƒ³ã€‚Anywayï¼Œå°±æŠŠä¹‹å‰åˆ›ä½œçš„å†…å®¹è´´åœ¨æœ€åï¼Œä¹Ÿæ˜¯ä¸€ç§å­¦ä¹ å˜›ï¼Œä¸äºğŸ˜›

~~åœ¨æ¨ç†çš„æ—¶å€™ï¼Œæ ·æœ¬ä¸€ä¸ªä¸€ä¸ªè¿›å…¥ç½‘ç»œï¼Œæ²¡æœ‰æ‰¹é‡å‡å€¼ã€æ–¹å·®å¯æ±‚ã€‚å¯ä»¥ç”¨è®­ç»ƒæ•°æ®é›†å¾—åˆ°å‡å€¼ã€æ–¹å·®ä½œä¸ºåˆå€¼ï¼Œä¸æ–­è¿­ä»£é€¼è¿‘å…¨å±€çš„å‡å€¼æ–¹å·®ã€‚å…¨å±€æœŸæœ›çš„æ›´æ–°è¦å€ŸåŠ©**Karlman æ»¤æ³¢**[[2]](https://wiwiki.kfd.me/wiki/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2)~~

ç‚¹å‡»ä¸‹å›¾å‚è€ƒ Matlab å®˜æ–¹åˆ¶ä½œçš„ä¼˜ç§€ç§‘æ™®è§†é¢‘ ğŸ‘‡

[![karlman](https://i0.hdslb.com/bfs/archive/b16e54070ffd2768a763a768463311b085de66d3.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1V5411V72J)

å¯¹åŒä¸€ä¸ªç›®æ ‡ï¼Œå¤šæ¬¡æµ‹é‡å€¼$z_1,z_2,z_3,...,z_k$ï¼Œå…¶æœŸæœ›$x_1, x_2,...,x_k$

$$
\begin{aligned}
\hat x_k&={1\over k}(z_1+z_2+z_3+...+z_{k-1}+z_k)\\
&={1\over k}(z_1+z_2+z_3+...+z_{k-1})+{1\over k}z_k\\
&={1\over k}{k-1\over k-1}(z_1+z_2+z_3+...+z_{k-1})+{1\over k}z_k\\
&={k-1\over k}\hat x_{k-1}+{1\over k}z_k\\
&=\hat x_{k-1}-{1\over k}\hat x_{k-1}+{1\over k}z_k\\
&=\hat x_{k-1}+{1\over k}(z_k-\hat x_{k-1})
\end{aligned}
$$

éšç€$k$çš„å¢åŠ ï¼Œæµ‹é‡å€¼$z_k$å°±ä¸å†é‡è¦

$$\hat x_k=\hat x_{k-1}+k_k(z_k-\hat x_{k-1})$$

$k_k$: Karlman Gain

å½“å‰ä¼°è®¡å€¼=ä¸Šä¸€æ¬¡çš„ä¼°è®¡å€¼+ç³»æ•° Ã—(å½“å‰æµ‹é‡å€¼-ä¸Šä¸€æ¬¡çš„ä¼°è®¡å€¼)

- åªä¸ä¸Šä¸€æ¬¡çš„ä¼°è®¡å€¼æœ‰å…³ï¼Œé€’å½’ç®—æ³•ã€‚

$$k_k={e_e\over e_e+e_m}$$

> ä¼°è®¡è¯¯å·®ï¼š$e_e$ï¼Œæµ‹é‡è¯¯å·®ï¼š$e_m$

- $e_e\gt\gt e_m: k_k\rightarrow1\quad \hat x_k=\hat x_{k-1}+z_k-\hat x_{k-1}=z_k$ï¼Œå½“ä¼°è®¡è¯¯å·®è¿œå¤§äºæµ‹é‡è¯¯å·®æ—¶ï¼Œä»¥æµ‹é‡å€¼ä¸ºå‡†
- $e_e\lt\lt e_m: k_k\rightarrow0\quad \hat x_k=\hat x_{k-1}$å½“ä¼°è®¡è¯¯å·®è¿œå°äºæµ‹é‡è¯¯å·®æ—¶ï¼Œä»¥ä¼°è®¡å€¼ä¸ºå‡†

## Pytorch æ¨¡å—å‚è€ƒæ–‡æ¡£

- Pytorch æ‰€æœ‰å¸¸ç”¨ Normalization å±‚æ–‡æ¡£ ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#normalization-layers-source) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/nn.html#normalization-layers)

## å‚è€ƒèµ„æ–™

[1] [in-layer normalization techniques for training very deep neural networks](https://theaisummer.com/normalization/)

[2] [å¡å°”æ›¼æ»¤æ³¢-ç»´åŸºç™¾ç§‘](https://wiwiki.kfd.me/wiki/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2)

---

## Q&AğŸ¤“

**Qï¼šæœ¬ç¯‡ä»‹ç»çš„BachNormå’Œä¹‹å‰æåˆ°çš„Xavieréšæœºåˆå§‹åŒ–æ–¹æ³•åœ¨æ•ˆæœä¸Šæœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ**

**ğŸ™‹â€â™‚ï¸**ï¼šæœ¬è´¨ä¸ŠBachNormå’ŒXavieråˆå§‹åŒ–æ€è·¯æ˜¯ç›¸ä¼¼çš„ï¼Œéƒ½æ˜¯è¦ä½¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´åŠ ç¨³å®šã€‚Xavieråˆå§‹åŒ–æ˜¯åœ¨è®­ç»ƒåˆï¼Œä½¿å¾—æ¢¯åº¦å¤„äºæ¯”è¾ƒç¨³å®šçš„èŒƒå›´ï¼Œä½†ä¸èƒ½ä¿è¯ä¹‹åçš„çŠ¶æ€ï¼›BatchNormæ˜¯åœ¨æ¯æ¬¡æ‰¹é‡è®­ç»ƒæ—¶ï¼Œå¼ºè¡Œé€šè¿‡å½’ä¸€åŒ–ä½¿å¯¹åº”å±‚æ¢¯åº¦å¤„äºæ¯”è¾ƒç¨³å®šçš„çŠ¶æ€è€Œä¸è‡³äºæ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸ã€‚
