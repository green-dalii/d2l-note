# 23 - ä½¿ç”¨å—çš„ç½‘ç»œ VGG

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‡

[![Bilibil](https://i1.hdslb.com/bfs/archive/4fbdc632ed7cbf51e5097fc1c10c196887376775.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1Ao4y117Pd)

## æ„æƒ³ç¼˜ç”±â€”â€”æ¨¡å—åŒ–æ€æƒ³

å› ä¸º AlexNet æ¯” LeNet æ›´æ·±æ›´å¤§è€Œè·å¾—æ›´å¥½çš„ç²¾åº¦ï¼Œé‚£ä¹ˆèƒ½ä¸èƒ½æ›´æ·±æ›´å¤§ï¼Ÿæœ‰ä»¥ä¸‹å‡ ç§é€”å¾„ï¼š

> æ›´å¤šçš„å…¨è¿æ¥å±‚ï¼ˆå å­˜å‚¨ç©ºé—´ï¼Œæˆæœ¬é«˜ï¼‰
>
> æ›´å¤šçš„å·ç§¯å±‚ï¼ˆä¸å¥½æ ‡å‡†åŒ–ï¼‰
>
> å°†å·ç§¯å±‚ç»„åˆæˆå¿« âˆš

è™½ç„¶ AlexNet è¯æ˜æ·±å±‚ç¥ç»ç½‘ç»œå“æœ‰æˆæ•ˆï¼Œä½†å®ƒæ²¡æœ‰æä¾›ä¸€ä¸ªé€šç”¨çš„æ¨¡æ¿æ¥æŒ‡å¯¼åç»­çš„ç ”ç©¶äººå‘˜è®¾è®¡æ–°çš„ç½‘ç»œã€‚

ä¸æ–°èƒ½æºæ±½è½¦æ¨¡å—åŒ–ç”Ÿäº§ã€èŠ¯ç‰‡è®¾è®¡ä¸­å·¥ç¨‹å¸ˆä»æ”¾ç½®æ™¶ä½“ç®¡åˆ°é€»è¾‘å…ƒä»¶å†åˆ°é€»è¾‘å—çš„è¿‡ç¨‹ç±»ä¼¼ï¼Œç¥ç»ç½‘ç»œæ¶æ„çš„è®¾è®¡ä¹Ÿé€æ¸å˜å¾—æ›´åŠ æŠ½è±¡ã€‚ç ”ç©¶äººå‘˜å¼€å§‹ä»å•ä¸ªç¥ç»å…ƒçš„è§’åº¦æ€è€ƒé—®é¢˜ï¼Œå‘å±•åˆ°æ•´ä¸ªå±‚ï¼Œç°åœ¨åˆè½¬å‘å—ï¼Œé‡å¤å±‚çš„æ¨¡å¼ã€‚

![modularization](Images/modularization.jpg)

ä½¿ç”¨å—çš„æƒ³æ³•é¦–å…ˆå‡ºç°åœ¨ç‰›æ´¥å¤§å­¦çš„[è§†è§‰å‡ ä½•ç»„ï¼ˆVisual Geometry Groupï¼ŒVGGï¼‰](http://www.robots.ox.ac.uk/~vgg/)çš„ VGG ç½‘ç»œä¸­ã€‚é€šè¿‡ä½¿ç”¨å¾ªç¯å’Œå­ç¨‹åºï¼Œå¯ä»¥å¾ˆå®¹æ˜“åœ°åœ¨ä»»ä½•ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶çš„ä»£ç ä¸­å®ç°è¿™äº›é‡å¤çš„æ¶æ„ã€‚

![vgg](Images/vgg.png)

## VGG å—

![vgg_block](Images/vgg_block.svg)

æ¯ä¸ª VGG å—ç”±ä»¥ä¸‹ç»„ä»¶ç»„æˆï¼š

- n ä¸ª 3x3 å·ç§¯å±‚ï¼Œå¡«å…… padding=1ï¼ˆå¯é‡å¤ n å±‚ï¼Œm é€šé“ï¼Œè¾“å…¥é€šé“ç­‰äºè¾“å‡ºé€šé“ï¼‰
- 2x2 æœ€å¤§æ± åŒ–å±‚ï¼ˆæ­¥å¹… stride=2ï¼‰

> ä½œè€…å®éªŒè¯æ˜ï¼Œæ›´æ·±çš„ 3x3 æ•ˆæœå¥½äºæµ…çš„ 5x5ï¼›ç”±äºæœ‰æ­¥å¹…çš„å­˜åœ¨ï¼Œæ¯ä¸ªå—çš„è¾“å‡ºå°ºå¯¸å‡åŠï¼Œä¸€èˆ¬ä½¿ç”¨æ—¶æ¯ä¸ªå—è®¾å®šä½¿é€šé“æ•°ç¿»å€ï¼Œç©ºé—´å°ºå¯¸å‡åŠã€‚

## VGG æ¶æ„

å°†å¤šä¸ª VGG å—ä¸²è¿åæ¥å…¨è¿æ¥å±‚ï¼Œä¸åŒæ¬¡æ•°çš„é‡å¤å—å¾—åˆ°ä¸åŒçš„æ¶æ„ï¼Œå¦‚ï¼šVGG-16ï¼ŒVGG-19â€¦â€¦

![vgg](https://zh.d2l.ai/_images/vgg.svg)

## æ€»ç»“

![Comparison-of-popular-CNN-architectures](Images/model_zoo.png)

> ä¸Šå›¾å±•ç¤ºä¸åŒç¥ç»ç½‘ç»œæ¶æ„çš„ Benchmark[1]ï¼Œæ¨ªè½´ä»£è¡¨æ¨¡å‹é¢„æµ‹é€Ÿåº¦ï¼Œçºµè½´ä»£è¡¨å‡†ç¡®ç‡ï¼Œåœ†åœˆå¤§å°ä»£è¡¨æ¨¡å‹å­˜å‚¨ç©ºé—´å¤§å°

- VGG ä½¿ç”¨å¯é‡å¤ä½¿ç”¨çš„å·ç§¯å—æ¥æ„å»ºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆæ¨¡å—åŒ–ï¼‰
- ä¸åŒçš„å·ç§¯å—å’Œè¶…å‚æ•°å¯ä»¥å¾—åˆ°ä¸åŒå¤æ‚åº¦çš„å˜ç§ä»¥é€‚åº”ä¸åŒéœ€æ±‚ï¼ˆç±»ä¼¼è½¦è¾†é«˜ä½é…ï¼‰

## ä»£ç å®ç°

- å®ç° VGG å—

```python
import torch
from torch import nn
from d2l import torch as d2l

def vgg_block(num_convs, in_channels, out_channels):
    layers = []
    for _ in range(num_convs):  # ä½¿ç”¨"_"åŒ¿åå˜é‡
        layers.append(nn.Conv2d(
            in_channels, out_channels, kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
    return nn.Sequential(*layers)   # ä½¿ç”¨*ç¬¦å·è§£åŒ…åˆ—è¡¨å…ƒç´ 
```

- å®ç°VGG11

```python
conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))
#åˆ†åˆ«æ˜¯å·ç§¯å±‚æ•°è¾“å‡ºé€šé“æ•°,VGG11
#ç»å…¸è®¾è®¡ï¼Œé«˜å®½å‡åŠï¼Œé€šé“æ•°ç¿»ä¸€å€

def vgg(conv_arch):
    conv_blks = []
    in_channels = 1
    #åœ¨å‡½æ•°çš„é¡ºåºç»“æ„é‡Œè¢«æ”¹å˜äº†
    for (num_convs, out_channels) in conv_arch:
        conv_blks.append(vgg_block(
            num_convs, in_channels, out_channels))
        in_channels = out_channels

    # nn.Sequentialå¯åµŒå¥—nn.Sequential
    return nn.Sequential(
        *conv_blks, nn.Flatten(),
        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(),
        nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(),
        nn.Dropout(0.5), nn.Linear(4096, 10))

net = vgg(conv_arch)
```

- æ£€æŸ¥å„å±‚è¾“å‡ºå°ºå¯¸

```python
X = torch.randn(size=(1, 1, 224, 224))
for blk in net:
    X = blk(X)
    print(blk.__class__.__name__, 'output shape:\t', X.shape)

# Out:
# Sequential output shape:     torch.Size([1, 64, 112, 112])
# Sequential output shape:     torch.Size([1, 128, 56, 56])
# Sequential output shape:     torch.Size([1, 256, 28, 28])
# Sequential output shape:     torch.Size([1, 512, 14, 14])
# Sequential output shape:     torch.Size([1, 512, 7, 7])
# Flatten output shape:        torch.Size([1, 25088])
# Linear output shape:         torch.Size([1, 4096])
# ReLU output shape:   torch.Size([1, 4096])
# Dropout output shape:        torch.Size([1, 4096])
# Linear output shape:         torch.Size([1, 4096])
# ReLU output shape:   torch.Size([1, 4096])
# Dropout output shape:        torch.Size([1, 4096])
# Linear output shape:         torch.Size([1, 10])
```

- è®­ç»ƒ

```python
ratio = 4
# å®éªŒæ•°æ®ä¸å¤§çš„æƒ…å†µä¸‹ï¼Œä¸ºå‡å°è®¡ç®—é‡ï¼Œæ‰€æœ‰å·ç§¯é€šé“æ•°ç¼©å°ä¸ºåŸå››åˆ†ä¹‹ä¸€
small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]

net = vgg(small_conv_arch)
lr, num_epochs, batch_size = 0.05, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())

# Out:
# loss 0.178, train acc 0.934, test acc 0.919
# 2546.8 examples/sec on cuda:0
```

> åˆ†æç»“æœå¯çŸ¥ï¼Œå¯¹æ¯”AlexNetç²¾åº¦æ›´é«˜ï¼Œè®¡ç®—é€Ÿåº¦æ…¢äº†å°†è¿‘1å€

![output_vgg](https://zh.d2l.ai/_images/output_vgg_4a7574_59_1.svg)

## å‚è€ƒèµ„æ–™

[1] [GluonCV model zoo](https://cv.gluon.ai/model_zoo/index.html)ï¼šå±•ç¤ºä¸åŒç¥ç»ç½‘ç»œæ¶æ„çš„ Benchmark
