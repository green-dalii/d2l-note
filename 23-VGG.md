# 23 - ä½¿ç”¨å—çš„ç½‘ç»œVGG

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰
[![Bilibil](https://i1.hdslb.com/bfs/archive/4fbdc632ed7cbf51e5097fc1c10c196887376775.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1Ao4y117Pd)
## ä½¿ç”¨å—çš„ç½‘ç»œâ€”â€”VGG(Visual Geometry Group)

Aæ¯”Læ›´æ·±æ›´å¤§ä»¥æœŸè·å¾—æ›´å¥½çš„ç²¾åº¦ï¼Œèƒ½ä¸èƒ½æ›´æ·±æ›´å¤§ï¼Ÿ

â€”â€”æ›´å¤šçš„å…¨é‡æ¥å±‚ï¼ˆå å†…å­˜ï¼Œæˆæœ¬é«˜ï¼‰
â€”â€”æ›´å¤šçš„å·ç§¯å±‚ï¼ˆæ²¡æœ‰å¤åˆ¶3x3çš„å¿…è¦ï¼‰
â€”â€”å°†å·ç§¯å±‚ç»„åˆæˆå¿«âˆš

**VGGå—**

3x3å·ç§¯å±‚ï¼Œå¡«å……1ï¼ˆnå±‚ï¼Œmé€šé“ï¼Œè¾“å…¥é€šé“ç­‰äºè¾“å‡ºé€šé“ï¼‰
2x2æœ€å¤§æ± åŒ–å±‚ï¼ˆæ­¥å¹…2ï¼‰

å®è·µè¯æ˜ï¼Œæ›´å¤šçš„3x3å¥½äºå°‘å„¿å¤§çš„5x5

å¤šä¸ªVGGå—åæ¥å…¨è¿æ¥å±‚

ä¸åŒæ¬¡æ•°çš„é‡å¤å¿«å¾—åˆ°ä¸åŒçš„æ¶æ„ï¼ŒVGG-16ï¼ŒVGG-19ã€‚

![](\Images/Overall-architecture-of-the-Visual-Geometry-Group-16-VGG-16-model-VGG-16-comprises.png)

æœ‰ç‚¹å„¿åƒæ˜¯**æ›´å¤§æ›´æ·±**çš„AlexNetã€‚

![](\Images/Comparison-of-popular-CNN-architectures-The-vertical-axis-shows-top-1-accuracy-on.png)

**æ€»ç»“**

VGGä½¿ç”¨å¯é‡å¤ä½¿ç”¨çš„å·ç§¯å—æ¥æ„å»ºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼›
ä¸åŒçš„å·ç§¯å—å’Œè¶…å‚æ•°å¯ä»¥å¾—åˆ°ä¸åŒå¤æ‚åº¦çš„å˜ç§ï¼›

## ä»£ç å®ç°

```
import torch
from torch import nn
from d2l import torch as d2l
#å®šä¹‰å—
def vgg_block(num_convs, in_channels, out_channels):
    layers = []
    for _ in range(num_convs):
        layers.append(nn.Conv2d(
            in_channels, out_channels, kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
    return nn.Sequential(*layers)

conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))
#åˆ†åˆ«æ˜¯å·ç§¯å±‚æ•°è¾“å‡ºé€šé“æ•°,VGG11
#ç»å…¸è®¾è®¡ï¼Œé«˜å®½å‡åŠï¼Œé€šé“æ•°ç¿»ä¸€å€

#å®šä¹‰æ¨¡å‹
def vgg(conv_arch):
    conv_blks = []
    in_channels = 1
    #åœ¨å‡½æ•°çš„é¡ºåºç»“æ„é‡Œè¢«æ”¹å˜äº†
    for (num_convs, out_channels) in conv_arch:
        conv_blks.append(vgg_block(
            num_convs, in_channels, out_channels))
        in_channels = out_channels
    
    return nn.Sequential(
        *conv_blks, nn.Flatten(),
        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(),
        nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(),
        nn.Dropout(0.5), nn.Linear(4096, 10))

net = vgg(conv_arch)

#æµ‹è¯•

X = torch.randn(size=(1, 1, 224, 224))
for blk in net:
    X = blk(X)
    print(blk.__class__.__name__, 'output shape:\t', X.shape)

#è®­ç»ƒ
ratio = 4
small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]
#é€šé“æ•°å‡åŠ
net = vgg(small_conv_arch)
lr, num_epochs, batch_size = 0.05, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```