# 13 - ä¸¢å¼ƒæ³•

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰
[![Bilibil](https://i1.hdslb.com/bfs/archive/f68d47e72ff00bd216c4c4fc8d44006540d91370.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1Y5411c7aY?spm_id_from=333.999.0.0)

### åŠ¨æœº

ä¸€ä¸ªå¥½çš„æ¨¡å‹éœ€è¦å¯¹è¾“å…¥æ•°æ®çš„æ‰°åŠ¨é²æ£’

ä½¿ç”¨æœ‰å™ªéŸ³çš„æ•°æ®ç­‰ä»·äºTikhonovæ­£åˆ™

ä¸¢å¼ƒæ³•ï¼šåœ¨å±‚ä¹‹é—´åŠ å…¥å™ªéŸ³ã€‚

### æ— åå·®çš„åŠ å…¥å™ªéŸ³

å¯¹${\bf x}$åŠ å…¥å™ªéŸ³å¾—åˆ°${\bf x\prime}$ï¼Œæˆ‘ä»¬å¸Œæœ›

${\bf E[x\prime]=x}$

å¸Œæœ›è™½ç„¶åŠ å…¥äº†å™ªéŸ³ï¼Œä½†æœŸæœ›ä¸å‘ç”Ÿæ”¹å˜ã€‚

ä¸¢å¼ƒå‘å¯¹æ¯ä¸ªå…ƒç´ è¿›è¡Œå¦‚ä¸‹æ‰°åŠ¨ï¼š

$$x_i^\prime=\begin{cases}
0 &with\ pobability\ p\\
{x_i\over1-p} &otherwise\end{cases}$$

ç›¸å½“äºæœ‰ä¸€å®šæ¦‚ç‡ $p$ ä½¿ä¸€ä¸ªå€¼å˜ä¸ºé›¶ï¼Œæˆ–è€…ä½¿ä¹‹å˜å¤§ã€‚

### ä½¿ç”¨ä¸¢å¼ƒæ³•

é€šå¸¸å°†ä¸¢å¼ƒæ³•ä½œç”¨åœ¨éšè—å…¨è¿æ¥å±‚çš„è¾“å‡ºä¸Šã€‚

$${\bf h}=\sigma({\bf W_1x+b_1})$$
$${\bf h^\prime}=dropout({\bf h})$$
$${\bf o}={\bf W_2h^\prime+b_2}$$
$${\bf y}=softmax({\bf o})$$

![ä½¿ç”¨ä¸¢å¼ƒæ³•](\Images/1_iWQzxhVlvadk6VAJjsgXgg.png)


### æ¨ç†ä¸­çš„ä¸¢å¼ƒæ³•

æ­£åˆ™é¡¹åªåœ¨è®­ç»ƒä¸­ä½¿ç”¨ï¼šä»–ä»¬å½±å“æ¨¡å‹å‚æ•°çš„æ›´æ–°ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä¸¢å¼ƒæ³•ç›´æ¥è¿”å›è¾“å…¥

$${\bf h}=dropout({\bf h})$$

è¿™æ ·ä¹Ÿèƒ½ä¿è¯ç¡®å®šæ€§çš„è¾“å‡ºã€‚

åœ¨æœ€åŸå§‹çš„ç†å¿µé‡Œï¼Œdropoutç›¸å½“äºæ¯ä¸€æ¬¡å–ä¸€æ‰¹é‡çš„å­ç¥ç»ç½‘ç»œåšå¹³å‡ã€‚å®éªŒä¸­ï¼Œè¡¨ç°å‡ºçš„æ•ˆæœæ›´åƒæ˜¯ä¸€ä¸ªæ­£åˆ™é¡¹ã€‚

å¸¸ä½œç”¨åœ¨å¤šå±‚æ„ŸçŸ¥æœºçš„éšè—å±‚è¾“å‡ºä¸Šï¼›

ä¸¢å¼ƒæ¦‚ç‡ä½¿æ§åˆ¶æ¨¡å‹å¤æ‚åº¦çš„è¶…å‚æ•°ã€‚

## ä»£ç å®ç°

åŒæ ·ä»¥Mnistå›¾åº“ä¸ºä¾‹ã€‚

- **å®šä¹‰dropoutå‡½æ•°**

```
import torch
from torch import nn
from d2l import torch as d2l

def dropout_layer(X, dropout):
    assert 0 <=dropout <= 1
    #å¦‚æœå…¶å€¼ä¸ºå‡ï¼ˆå³ä¸º0ï¼‰ï¼Œæ‰“å°å‡ºé”™ä¿¡æ¯,ç„¶åç»ˆæ­¢ç¨‹åºè¿è¡Œã€‚
    #åœ¨å‡½æ•°å¼€å§‹å¤„æ£€éªŒä¼ å…¥å‚æ•°çš„åˆæ³•æ€§
    if dropout == 1:
        return torch.zeros_like(X)
    if dropout == 0:
        return X
    mask = (torch.randn(X.shape)  > dropout).float()
    #randn(random normal)
    #å¯¹tensoråšboolè¿”å›çš„ä¹Ÿæ˜¯tensorçš„å¹¿æ’­å¼æ¯”è¾ƒ
    #ç¡®å®šå“ªä¸€é¡¹å…ƒç´ è¢«æ¸…é›¶
    
    return mask * X / (1.0 -dropout)
    #ä¸ºäº†èƒ½å¿«é€Ÿè®¡ç®—
```

- **è®­ç»ƒ**

```
num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256
#x.shape=(1,784),y.shape=(1,10),w1.shape=(784,256),w2.shape=(256,256),w3.shape=(256,10)
dropout1, dropout2 = 0.2, .5

class Net(nn.Module):
    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training=True):
        super(Net, self).__init__()
        #super() å‡½æ•°æ˜¯ç”¨äºè°ƒç”¨çˆ¶ç±»(è¶…ç±»)çš„ä¸€ä¸ªæ–¹æ³•ã€‚
        #super(Class, self).xxxï¼Œæˆ–è€…ç®€å†™ä¸ºsuper().xxx
        #è¿™é‡Œè°ƒç”¨çš„å°±æ˜¯Netçš„çˆ¶ç±»nn.Moduleçš„__init__()
        #é‡Œé¢åŒ…å«äº†æ‰€éœ€çš„æ–¹æ³•ã€‚
        self.num_inputs = num_inputs
        self.training = is_training
        self.lin1 = nn.Linear(num_inputs, num_hiddens1)
        #(784,256) h1=xWT
        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)
        #(256,256)
        self.lin3 = nn.Linear(num_hiddens2, num_outputs)
        #(256,10)
        self.relu = nn.ReLU()
    
    def forward(self, X):
        H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs))))
        #(1,784)*(784,256)
        if self.training == True:
            H1 = dropout_layer(H1, dropout1)
            #h1'=dropout(h1)
        H2 = self.relu(self.lin2(H1))
         #(1,256)*(256,256)=(1,256)
        if self.training == True:
            H2 = dropout_layer(H2, dropout2)
            #h2'=dropout(h2)
        out = self.lin3(H2)
        #(256,256)*(256,10)=(1,10)
        return out

net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)

num_epochs, lr, batch_size = 10, .5, 256
loss = nn.CrossEntropyLoss()
#æ‰“åŒ…äº†softmax
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
#X=(256,784)
trainer = torch.optim.SGD(net.parameters(), lr=lr)
#æ­¤å¤„è°ƒç”¨äº†netè¿™ä¸ªclassé‡Œé¢æ‰€æœ‰çš„å±æ€§ï¼Œw1-w3,b1-b3.
#net.parameters(recurse=True)å°±æ˜¯è¿”å›æ¨¡å—å’Œæ‰€æœ‰å­æ¨¡å—çš„å‚æ•°ã€‚
#è¿”å›çš„æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨
#æ‰€ä»¥è¦ç”¨å¾ªç¯ï¼Œæˆ–è€…å†…ç½®å¾ªç¯çš„æ–¹æ³•è°ƒç”¨ã€‚
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```
![è®­ç»ƒç»“æœ](\Images/å¾®ä¿¡æˆªå›¾_20211217154852.png)

- **ç®€ä»‹å®ç°**

```
net = nn.Sequential(nn.Flatten(),
                  nn.Linear(784, 256),
                  nn.ReLU(),
                  nn.Dropout(dropout1),
                  nn.Linear(256, 256),
                  nn.ReLU(),
                  nn.Dropout(dropout2),
                  nn.Linear(256, 10))
def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights)

trainer = torch.optim.SGD(net.parameters(), lr=lr)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```
![](\Images/å¾®ä¿¡æˆªå›¾_20211217155233.png)