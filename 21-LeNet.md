# 21 - ç»å…¸å·ç§¯ç¥ç»ç½‘ç»œ LeNet

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‡

[![Bilibil](https://i2.hdslb.com/bfs/archive/31bbec5db68b26ae5c86a5c7a6ac5b52f5751de1.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1t44y1r7ct)

## LeNet

ä¹‹å‰æˆ‘ä»¬å°†[softmax å›å½’æ¨¡å‹](09-Softmaxå›å½’.md)å’Œ[å¤šå±‚æ„ŸçŸ¥æœºæ¨¡å‹](10-å¤šå±‚æ„ŸçŸ¥æœº.md)åº”ç”¨äº Fashion-MNIST æ•°æ®é›†ä¸­çš„æœè£…å›¾ç‰‡ã€‚ ä¸ºäº†èƒ½å¤Ÿåº”ç”¨ softmax å›å½’å’Œå¤šå±‚æ„ŸçŸ¥æœºï¼Œæˆ‘ä»¬é¦–å…ˆå°†æ¯ä¸ªå¤§å°ä¸º $(28 \times 28)$ çš„å›¾åƒå±•å¹³ä¸ºä¸€ä¸ª 784 ç»´çš„å›ºå®šé•¿åº¦çš„ä¸€ç»´å‘é‡ï¼Œç„¶åç”¨å…¨è¿æ¥å±‚å¯¹å…¶è¿›è¡Œå¤„ç†ã€‚ è€Œç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»æŒæ¡äº†å·ç§¯å±‚çš„å¤„ç†æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å›¾åƒä¸­ä¿ç•™ç©ºé—´ç»“æ„ã€‚ åŒæ—¶ï¼Œç”¨å·ç§¯å±‚ä»£æ›¿å…¨è¿æ¥å±‚çš„å¦ä¸€ä¸ªå¥½å¤„æ˜¯ï¼šæ¨¡å‹æ›´ç®€æ´ã€æ‰€éœ€çš„å‚æ•°æ›´å°‘ã€‚

![LeNet](Images/LeNet.gif)

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»**LeNet**ï¼Œå®ƒæ˜¯æœ€æ—©å‘å¸ƒçš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€ï¼Œå› å…¶åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§èƒ½è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚ è¿™ä¸ªæ¨¡å‹æ˜¯ç”± AT&T è´å°”å®éªŒå®¤çš„ç ”ç©¶å‘˜ Yann LeCun åœ¨ 1989 å¹´æå‡ºçš„ï¼ˆå¹¶ä»¥å…¶å‘½åï¼‰ï¼Œç›®çš„æ˜¯è¯†åˆ«å›¾åƒ [LeCun et al., 1998[1]](https://axon.cs.byu.edu/~martinez/classes/678/Papers/Convolution_nets.pdf)ä¸­çš„æ‰‹å†™æ•°å­—ã€‚ å½“æ—¶ï¼ŒYann LeCun å‘è¡¨äº†ç¬¬ä¸€ç¯‡é€šè¿‡åå‘ä¼ æ’­æˆåŠŸè®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œçš„ç ”ç©¶ï¼Œè¿™é¡¹å·¥ä½œä»£è¡¨äº†åå¤šå¹´æ¥ç¥ç»ç½‘ç»œç ”ç©¶å¼€å‘çš„æˆæœã€‚

å½“æ—¶ï¼ŒLeNet å–å¾—äº†ä¸æ”¯æŒå‘é‡æœºï¼ˆSVM,support vector machinesï¼‰æ€§èƒ½ç›¸åª²ç¾çš„æˆæœï¼Œæˆä¸ºç›‘ç£å­¦ä¹ çš„ä¸»æµæ–¹æ³•ã€‚ LeNet è¢«å¹¿æ³›ç”¨äºè‡ªåŠ¨å–æ¬¾æœºï¼ˆATMï¼‰æœºä¸­ï¼Œå¸®åŠ©è¯†åˆ«å¤„ç†æ”¯ç¥¨çš„æ•°å­—ã€‚ æ—¶è‡³ä»Šæ—¥ï¼Œä¸€äº›è‡ªåŠ¨å–æ¬¾æœºä»åœ¨è¿è¡Œ Yann LeCun å’Œä»–çš„åŒäº‹ Leon Bottou åœ¨ä¸Šä¸–çºª 90 å¹´ä»£å†™çš„ä»£ç å‘¢ï¼

![lenet](https://zh.d2l.ai/_images/lenet.svg)

æ¯ä¸ªå·ç§¯å—ä¸­çš„åŸºæœ¬å•å…ƒæ˜¯ä¸€ä¸ª**å·ç§¯å±‚**ã€ä¸€ä¸ª**sigmoid æ¿€æ´»å‡½æ•°**å’Œ**å¹³å‡æ±‡èšå±‚**ã€‚è¯·æ³¨æ„ï¼Œè™½ç„¶ ReLU å’Œæœ€å¤§æ±‡èšå±‚æ›´æœ‰æ•ˆï¼Œä½†å®ƒä»¬åœ¨ 20 ä¸–çºª 90 å¹´ä»£è¿˜æ²¡æœ‰å‡ºç°ã€‚æ¯ä¸ªå·ç§¯å±‚ä½¿ç”¨$(5\times 5)$å·ç§¯æ ¸å’Œä¸€ä¸ª sigmoid æ¿€æ´»å‡½æ•°ã€‚è¿™äº›å±‚å°†è¾“å…¥æ˜ å°„åˆ°å¤šä¸ªäºŒç»´ç‰¹å¾è¾“å‡ºï¼Œé€šå¸¸åŒæ—¶å¢åŠ é€šé“çš„æ•°é‡ã€‚ç¬¬ä¸€å·ç§¯å±‚æœ‰ 6 ä¸ªè¾“å‡ºé€šé“ï¼Œè€Œç¬¬äºŒä¸ªå·ç§¯å±‚æœ‰ 16 ä¸ªè¾“å‡ºé€šé“ã€‚æ¯ä¸ª$(2\times2)$æ± æ“ä½œï¼ˆæ­¥éª¤ 2ï¼‰é€šè¿‡ç©ºé—´ä¸‹é‡‡æ ·å°†ç»´æ•°å‡å°‘ 4 å€ã€‚å·ç§¯çš„è¾“å‡ºå½¢çŠ¶ç”±æ‰¹é‡å¤§å°ã€é€šé“æ•°ã€é«˜åº¦ã€å®½åº¦å†³å®šã€‚

ä¸ºäº†å°†å·ç§¯å—çš„è¾“å‡ºä¼ é€’ç»™ç¨ å¯†å—ï¼Œæˆ‘ä»¬å¿…é¡»åœ¨å°æ‰¹é‡ä¸­å±•å¹³æ¯ä¸ªæ ·æœ¬ã€‚æ¢è¨€ä¹‹ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªå››ç»´è¾“å…¥è½¬æ¢æˆå…¨è¿æ¥å±‚æ‰€æœŸæœ›çš„äºŒç»´è¾“å…¥ã€‚è¿™é‡Œçš„äºŒç»´è¡¨ç¤ºçš„ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯ç´¢å¼•å°æ‰¹é‡ä¸­çš„æ ·æœ¬ï¼Œç¬¬äºŒä¸ªç»´åº¦æ˜¯ç»™å‡ºæ¯ä¸ªæ ·æœ¬çš„å¹³é¢å‘é‡è¡¨ç¤ºã€‚LeNet çš„ç¨ å¯†å—æœ‰ä¸‰ä¸ªå…¨è¿æ¥å±‚ï¼Œåˆ†åˆ«æœ‰ 120ã€84 å’Œ 10 ä¸ªè¾“å‡ºã€‚å› ä¸ºæˆ‘ä»¬åœ¨æ‰§è¡Œåˆ†ç±»ä»»åŠ¡ï¼Œæ‰€ä»¥è¾“å‡ºå±‚çš„ 10 ç»´å¯¹åº”äºæœ€åè¾“å‡ºç»“æœçš„æ•°é‡ã€‚

## æ€»ç»“

- æ˜¯æ—©æœŸæˆåŠŸçš„ç¥ç»ç½‘ç»œ
- å…ˆä½¿ç”¨å·ç§¯å±‚æ¥å­¦ä¹ å›¾ç‰‡çš„ç©ºé—´ä¿¡æ¯
- ç„¶åä½¿ç”¨å…¨è¿æ¥å±‚æ¥è½¬æ¢åˆ°ç±»åˆ«ç©ºé—´ã€‚

## ä»£ç å®ç°

- å®šä¹‰ç½‘ç»œ

```python
import torch
from torch import nn
from d2l import torch as d2l

class Reshape(torch.nn.Module):
    def forward(self, x):
        return x.view(-1, 1, 28, 28)
        #Returns a new tensor with the same data as the self tensor
        #but of a different shape
        #æ‰¹é‡ä¸å˜ï¼Œé€šé“å”¯ä¸€ï¼Œ

net = torch.nn.Sequential(
    Reshape(), nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    # nn.Flatten()é»˜è®¤ä»ç¬¬1ç»´åˆ°æœ€åä¸€ç»´å±•å¹³ï¼Œä¿ç•™ç¬¬0ç»´æ‰¹é‡ç»´
    nn.Flatten(),
    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.Sigmoid(),
    nn.Linear(84, 10))
```

- æµ‹è¯•

```python
X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__, 'output shape: \t', X.shape)
    #è°ƒç”¨layerçš„åå­—

```

- è®­ç»ƒ

```python
batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)

def evaluate_accuracy_gpu(net, data_iter, device=None):
    if isinstance(net, torch.nn.Module):
        net.eval()
        if not device:
            device = next(iter(net.parameters())).device
            #æŸ¥çœ‹å­˜å‚¨è®¾å¤‡
        metric = d2l.Accumulator(2)
        for X, y in data_iter:
            if isinstance(X, list):
                X = [x.to(device) for x in X]
            else:
                X = X.to(device)
            y = y.to(device)
            metric.add(d2l.accuracy(net(X), y), y.numel())
        return metric[0] / metric[1]

```

- è®­ç»ƒå‡½æ•°

```python
def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):
    def init_weights(m):
        if type(m) == nn.Linear or type(m) == nn.Conv2d:
            nn.init.xavier_uniform_(m.weight)
    net.apply(init_weights)
    print('training on', device)
    net.to(device)
    optimizer = torch.optim.SGD(net.parameters(), lr=lr)
    loss = nn.CrossEntropyLoss()
    #é»˜è®¤å–å¹³å‡æŸå¤±
    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                           legend=['train loss', 'train acc', 'test acc'])
    timer, num_batches = d2l.Timer(), len(train_iter)
    for epoch in range(num_epochs):
        metric = d2l.Accumulator(3)
        # metric.data=[0.,0.,0.]
        net.train()
        for i, (X, y) in enumerate(train_iter):
            # X.shape=(256,1,28,28)
            timer.start()
            optimizer.zero_grad()
            X, y = X.to(device), y.to(device)
            y_hat = net(X)
            l = loss(y_hat, y)
            l.backward()
            optimizer.step()
            metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])
            #è¿”å›ä¸‰ä¸ªæ ‡é‡ï¼Œl*256,accuracy,256

            timer.stop()
            train_l = metric[0] / metric[2]
            #å¹³å‡æŸå¤±
            train_acc = metric[1] / metric[2]
            #æ­£ç¡®ç‡
            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:
                animator.add(epoch + (i + 1) / num_batches,
                             (train_l, train_acc, None))
        test_acc = evaluate_accuracy_gpu(net, test_iter)
        animator.add(epoch + 1, (None, None, test_acc))
    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '
          f'test acc {test_acc:.3f}')
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '
          f'on {str(device)}')

```

```python
lr, num_epochs = 0.9, 10
train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```

![result](Images/å±å¹•æˆªå›¾%202021-12-24%20170823.png)

## å‚è€ƒèµ„æ–™

[1][lecun, y., bottou, l., bengio, y., haffner, p., & others. (1998). gradient-based learning applied to document recognition. proceedings of the ieee, 86(11), 2278â€“2324.](https://axon.cs.byu.edu/~martinez/classes/678/Papers/Convolution_nets.pdf)

[2][cnn explianer](https://poloclub.github.io/cnn-explainer/)ï¼šä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œå¯è§†åŒ– Demo

---

## Q&AğŸ¤“

**Qï¼šmax pooling å’Œ average pooling å“ªä¸ªç”¨çš„æ›´å¤šï¼Ÿ**

**ğŸ™‹â€â™‚ï¸**ï¼šäºŒè€…å·®åˆ«ä¸å¤§ï¼ˆå¯èƒ½åœ¨å…·ä½“é—®é¢˜æœ‰ç»†å¾®å·®åˆ«ï¼‰ï¼Œä¸€èˆ¬æ¥è¯´ max pooling ç”¨çš„æ›´å¤šï¼Œå› ä¸º max pooling å¾—åˆ°çš„æ•°å€¼æ›´å¤§ï¼Œç›¸å¯¹æ¢¯åº¦æ¯” average ä¹Ÿä¸ªæ›´å¤§ï¼Œæ›´å¥½è®­ç»ƒã€‚
