# 15 - Kaggle åŠ å·æˆ¿ä»·é¢„æµ‹å®æˆ˜

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‡

[![Bilibil](https://i0.hdslb.com/bfs/archive/d66e2524575703d66340b8fd486793523fc5c32f.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1NK4y1P7Tu?spm_id_from=333.999.0.0)

ä¹‹å‰å‡ èŠ‚æˆ‘ä»¬å­¦ä¹ äº†ä¸€äº›è®­ç»ƒæ·±åº¦ç½‘ç»œçš„åŸºæœ¬å·¥å…·å’Œç½‘ç»œæ­£åˆ™åŒ–çš„æŠ€æœ¯ï¼ˆå¦‚**æƒé‡è¡°å‡**ã€**æš‚é€€æ³•**ç­‰ï¼‰ã€‚ æœ¬èŠ‚æˆ‘ä»¬å°†é€šè¿‡ Kaggle æ¯”èµ›ï¼Œå°†æ‰€å­¦çŸ¥è¯†ä»˜è¯¸å®è·µã€‚ Kaggle çš„æˆ¿ä»·é¢„æµ‹æ¯”èµ›æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚ æ­¤æ•°æ®é›†ç”± Bart de Cock äº 2011 å¹´æ”¶é›†ï¼Œ æ¶µç›–äº† 2006-2010 å¹´æœŸé—´äºšåˆ©æ¡‘é‚£å·åŸƒå§†æ–¯å¸‚çš„æˆ¿ä»·ã€‚ è¿™ä¸ªæ•°æ®é›†æ˜¯ç›¸å½“é€šç”¨çš„ï¼Œä¸ä¼šéœ€è¦ä½¿ç”¨å¤æ‚æ¨¡å‹æ¶æ„ã€‚ å®ƒæ¯”å“ˆé‡Œæ£®å’Œé²å®¾è²å°”å¾·çš„æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†è¦å¤§å¾—å¤šï¼Œä¹Ÿæœ‰æ›´å¤šçš„ç‰¹å¾ã€‚

æœ¬èŠ‚æˆ‘ä»¬å°†è¯¦ç»†ä»‹ç»æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®¾è®¡å’Œè¶…å‚æ•°é€‰æ‹©ã€‚ é€šè¿‡äº²èº«å®è·µï¼Œä½ å°†è·å¾—ä¸€æ‰‹ç»éªŒï¼Œè¿™äº›ç»éªŒå°†æŒ‡å¯¼ä½ æ•°æ®ç§‘å­¦å®¶èŒä¸šç”Ÿæ¶¯ã€‚

> è¯¥æ¯”èµ›é¡¹ç›®ç½‘å€ï¼šç‚¹å‡» ğŸ‘‰[è¿™é‡Œ](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview)ï¼Œæ•°æ®æè¿°ï¼šç‚¹å‡» ğŸ‘‰[è¿™é‡Œ](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)

- å‡†å¤‡å·¥ä½œâ€”â€”å®šä¹‰æ•°æ®ä¸‹è½½å‡½æ•°

```python
import hashlib  # å¯¼å…¥æ•£åˆ—è®¡ç®—åŒ…
#æŠŠä»»æ„é•¿åº¦çš„è¾“å…¥ï¼Œé€šè¿‡æŸç§hashç®—æ³•ï¼Œå˜æ¢æˆå›ºå®šé•¿åº¦çš„è¾“å‡ºï¼Œ

import os
import tarfile #TarFileç±»å¯¹äºå°±æ˜¯tarå‹ç¼©åŒ…å®ä¾‹
import zipfile
import requests

DATA_HUB = dict()
DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'

def download(name, cache_dir=os.path.join('..', 'data')):
    # os.path.join()è·¯å¾„æ‹¼æ¥ï¼Œç›¸å½“äº../dataæ–‡ä»¶å¤¹ã€‚

    assert name in DATA_HUB, f"{name} ä¸å­˜åœ¨äº {DATA_HUB}"
    url, sha1_hash = DATA_HUB[name]
    os.makedirs(cache_dir, exist_ok=True)   #os.makedirs()yç”¨äºåˆ›å»ºç›®å½•ï¼Œexist_ok=Trueï¼Œé»˜è®¤ä¸ºFalse,ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨ä¼šæŠ¥é”™
    fname = os.path.join(cache_dir, url.split('/')[-1]) #æŠŠurlæŒ‰ç…§/æ‹†åˆ†ï¼Œæå–æœ€åä¸€ä¸ªå­—ç¬¦ä¸²è¿æ¥ç›®å½•ï¼Œä½œä¸ºæ–‡ä»¶å

    if os.path.exists(fname):   #os.path.exists()æ£€æµ‹æ–‡ä»¶æ˜¯å¦å·²ä¸‹è½½
        sha1 = hashlib.sha1()   # æŒ‡å®šsha1æ•£åˆ—ç®—æ³•
        with open(fname, 'rb') as f:    # 'rb'äºŒè¿›åˆ¶åªè¯»æ–¹å¼
            while True: # é»˜è®¤è¯»å–æ‰€æœ‰å†…å®¹
                data = f.read(1048576)  # file.read([size])æŒ‡å®šä¸€æ¬¡æœ€å¤šå¯è¯»å–çš„å­—ç¬¦ï¼ˆå­—èŠ‚ï¼‰ä¸ªæ•°
                #size=1048576=1024*1024,æ¯æ¬¡çš„è¯»å–1Mbã€‚

                if not data:    # å¦‚è¿‡è¿”å›ç©ºï¼Œåˆ™åœæ­¢è¯»å–
                    break
                sha1.update(data)   #update()åˆå¹¶ä¸è¦†ç›–å½“å‰å†…å®¹
        if sha1.hexdigest() == sha1_hash:
            return fname  # å¦‚æœè®¡ç®—çš„æ•£åˆ—å€¼ä¸æŒ‡å®šç›¸ç­‰ï¼Œåˆ™è¿”å›æ–‡ä»¶

    # å¦‚æœç›®å½•ä¸‹æ²¡æœ‰æ–‡ä»¶ï¼Œåˆ™è¿›è¡Œä¸‹è½½
    print(f'æ­£åœ¨ä»{url}ä¸‹è½½{fname}...')
    r = requests.get(url, stream=True, verify=True) # æŒ‡å®šä½¿ç”¨æµå¼ä¸‹è½½æ–¹å¼
    with open(fname, 'wb') as f:    # 'wb'äºŒè¿›åˆ¶å†™å…¥æ–¹å¼
        f.write(r.content)
    return fname
```

- ä¸‹è½½&è§£å‹å‡½æ•°

```python
def download_extract(name, folder=None):
    fname = download(name)
    base_dir = os.path.dirname(fname)   # æå–æ–‡ä»¶è·¯å¾„
    data_dir, ext = os.path.splitext(fname) # åˆ†ç¦»æ–‡ä»¶åä¸æ‰©å±•å

    if ext == '.zip':   # è§£å‹zipæ ¼å¼æ–‡ä»¶
        fp = zipfile.ZipFile(fname, 'r')
    elif ext in ('tar', '.gz'): # è§£å‹taræ ¼å¼æ–‡ä»¶
        fp = tarfile.open(fname, 'r')
    else:
        assert False
    fp.extractall(base_dir) # æŒ‡å®šè§£å‹è·¯å¾„
    return os.path.join(base_dir, folder) if folder else data_dir

def download_all():
    for name in DATA_HUB:
        download(name)
```

- ä¸‹è½½å¹¶è¯»å–æ•°æ®

```python
%matplotlib inline
import numpy as np
import pandas as pd
import torch
from torch import nn
from d2l import torch as d2l

DATA_HUB['kaggle_house_train'] = (
    DATA_URL + 'kaggle_house_pred_train.csv',
    '585e9cc93e70b39160e7921475f9bcd7d31219ce')

DATA_HUB['kaggle_house_test'] = (
    DATA_URL + 'kaggle_house_pred_test.csv',
    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')

train_data = pd.read_csv(download('kaggle_house_train'))
test_data = pd.read_csv(download('kaggle_house_test'))
```

- æ•°æ®é¢„å¤„ç†

```python
all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1]))
# é»˜è®¤æŒ‰è¡Œè¿æ¥çºµå‘å±‚å ï¼ˆå¢åŠ è¡Œæ•°ï¼‰è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®
# åˆ¨å»train_dataç¬¬ä¸€åˆ—ID,å’Œæœ€åä¸€åˆ—labels,test_dataç¬¬ä¸€åˆ—ID


# å–å‡ºæ‰€æœ‰æ•°å€¼ç±»å‹ï¼ˆé'object'ï¼‰çš„ç‰¹å¾ç´¢å¼•
numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index
# å¯¹æ•°å€¼åˆ—è¿›è¡Œnormalizationï¼Œå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1
all_features[numeric_features] = all_features[numeric_features].apply(
lambda x: (x - x.mean()) / (x.std()))
# å¯¹ç¼ºå¤±å€¼è¡¥é›¶
all_features[numeric_features] = all_features[numeric_features].fillna(0)

all_features = pd.get_dummies(all_features, dummy_na=True)  #get_dummies()è¿›è¡Œone-hotç¼–ç 
all_features.shape
```

> æ­¤å¤„å¯¹è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®åˆå¹¶ä¸€èµ·è®¡ç®—å‡å€¼å’Œæ–¹å·®çš„æ–¹æ³•ä»…é€‚ç”¨äº Kaggle æ¯”èµ›ï¼Œå› ä¸ºæ¯”èµ›ä¸­ä¼šä¸ºæäº¤çš„æ¨¡å‹æä¾›**æ–°çš„**æµ‹è¯•æ•°æ®é›†ã€‚å¦‚æœåœ¨å®é™…é¡¹ç›®ä¸­ï¼Œé¡»ä»…åœ¨è®­ç»ƒæ•°æ®é›†è®¡ç®—å‡å€¼æ–¹å·®åï¼Œå†åº”ç”¨åˆ°æµ‹è¯•æ•°æ®çš„å½’ä¸€åŒ–ã€‚å¦åˆ™åœ¨å…¨æ•°æ®é›†ä¸Šè®¡ç®—ï¼Œä¼šå¯¼è‡´ä¸€å®šç¨‹åº¦çš„**ç‰¹å¾æ³„éœ²**ï¼ˆç±»ä¼¼è€ƒè¯•æ¼é¢˜ï¼‰ï¼Œè€Œé€ æˆæµ‹è¯•ç²¾åº¦è™šé«˜ã€‚

- å°†æ•°æ®è½¬æ¢ä¸º Tensor

```python
# è·å¾—è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®çš„åˆ‡åˆ†ç‚¹
n_train = train_data.shape[0]   # 1460
# è½¬æ¢è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®
train_features = torch.tensor(all_features[:n_train].values,dtype=torch.float32)    # 1460*331
test_features = torch.tensor(all_features[n_train:].values,dtype=torch.float32)     # 1459*331
# è½¬æ¢è®­ç»ƒæ ‡ç­¾
train_labels = torch.tensor(train_data.SalePrice.values.reshape(-1, 1),dtype=torch.float32)     # 1460*1
```

- åˆ›å»ºç¥ç»ç½‘ç»œ

```python
# MSEæŸå¤±å‡½æ•°
loss = nn.MSELoss()
in_features = train_features.shape[1]   # 331

# å®šä¹‰ä¸€ä¸ªå•å±‚ç¥ç»ç½‘ç»œåšçº¿æ€§å›å½’
def get_net():
    net = nn.Sequential(nn.Linear(in_features, 1))
    return net
```

- é‡æ–°å®šä¹‰æŸå¤±å‡½æ•°

æˆ¿ä»·å°±åƒè‚¡ç¥¨ä»·æ ¼ä¸€æ ·ï¼Œæˆ‘ä»¬å…³å¿ƒçš„æ˜¯ç›¸å¯¹æ•°é‡ï¼Œè€Œä¸æ˜¯ç»å¯¹æ•°é‡ã€‚å› æ­¤ï¼Œ**æˆ‘ä»¬æ›´å…³å¿ƒç›¸å¯¹è¯¯å·®$\frac{y - \hat{y}}{y}$**ï¼Œè€Œä¸æ˜¯ç»å¯¹è¯¯å·®$y - \hat{y}$ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬åœ¨ä¿„äº¥ä¿„å·å†œæ‘åœ°åŒºä¼°è®¡ä¸€æ ‹æˆ¿å­çš„ä»·æ ¼æ—¶ï¼Œå‡è®¾æˆ‘ä»¬çš„é¢„æµ‹åå·®äº† 10 ä¸‡ç¾å…ƒï¼Œç„¶è€Œé‚£é‡Œä¸€æ ‹å…¸å‹çš„æˆ¿å­çš„ä»·å€¼æ˜¯ 12.5 ä¸‡ç¾å…ƒï¼Œé‚£ä¹ˆæ¨¡å‹å¯èƒ½åšå¾—å¾ˆç³Ÿç³•ã€‚å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæˆ‘ä»¬åœ¨åŠ å·è±ªå®…åŒºçš„é¢„æµ‹å‡ºç°åŒæ ·çš„ 10 ä¸‡ç¾å…ƒçš„åå·®ï¼Œï¼ˆåœ¨é‚£é‡Œï¼Œæˆ¿ä»·ä¸­ä½æ•°è¶…è¿‡ 400 ä¸‡ç¾å…ƒï¼‰è¿™å¯èƒ½æ˜¯ä¸€ä¸ªä¸é”™çš„é¢„æµ‹ã€‚

**è§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯ç”¨ä»·æ ¼é¢„æµ‹çš„å¯¹æ•°æ¥è¡¡é‡å·®å¼‚**ã€‚äº‹å®ä¸Šï¼Œè¿™ä¹Ÿæ˜¯æ¯”èµ›ä¸­å®˜æ–¹ç”¨æ¥è¯„ä»·æäº¤è´¨é‡çš„è¯¯å·®æŒ‡æ ‡ã€‚å³å°†$\delta$ for $|\log y - \log \hat{y}| \leq \delta$
è½¬æ¢ä¸º$e^{-\delta} \leq \frac{\hat{y}}{y} \leq e^\delta$ã€‚è¿™ä½¿å¾—é¢„æµ‹ä»·æ ¼çš„å¯¹æ•°ä¸çœŸå®æ ‡ç­¾ä»·æ ¼çš„å¯¹æ•°ä¹‹é—´å‡ºç°ä»¥ä¸‹å‡æ–¹æ ¹è¯¯å·®ï¼š

$$\sqrt{\frac{1}{n}\sum_{i=1}^n\left(\log y_i -\log \hat{y}_i\right)^2}.$$

```python
# logæŸå¤±
def log_rmse(net, features, labels):
    # clamp(x, min, max)ï¼Œé’³åˆ¶å€¼åœ¨[min, max]
    clipped_preds = torch.clamp(net(features), 1, float('inf'))
    #Lossæ±‚å‡æ–¹æŸå¤±ï¼Œè¾“å‡ºä¸€ä¸ªæ ‡é‡
    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))
    return rmse.item()

#tensor.item()=number
#Returns the value of this tensor as a standard Python number.
#This only works for tensors with one elementï¼ˆæ ‡é‡ï¼‰.
```

- è®­ç»ƒå‡½æ•°

è®­ç»ƒå‡½æ•°å°†å€ŸåŠ©**Adam ä¼˜åŒ–å™¨**ï¼Œè€Œä¸æ˜¯åŸæ¥çš„**SGD ä¼˜åŒ–å™¨**ï¼Œå¹¶å¯ç”¨**æƒé‡è¡°å‡**ï¼ˆweight decayï¼‰ã€‚Adam ä¼˜åŒ–å™¨çš„ä¸»è¦å¸å¼•åŠ›åœ¨äºå®ƒå¯¹åˆå§‹å­¦ä¹ ç‡ä¸é‚£ä¹ˆæ•æ„Ÿã€‚

```python
def train(net, train_features, train_labels, test_features, test_labels,
          num_epochs, learning_rate, weight_decay, batch_size):
    train_ls, test_ls = [], []
    train_iter = d2l.load_array((train_features, train_labels), batch_size)
    optimizer = torch.optim.Adam(net.parameters(),
                                lr=learning_rate,
                                weight_decay=weight_decay)
    for epoch in range(num_epochs):
        for X, y in train_iter:
            optimizer.zero_grad()
            l = loss(net(X), y)
            l.backward()
            optimizer.step()
        # æ¯ä¸ªepochè®¡ç®—è®­ç»ƒé›†çš„rmse losså¹¶æ·»åŠ åˆ°åˆ—è¡¨
        train_ls.append(log_rmse(net, train_features, train_labels))
        # æ¯ä¸ªepochè®¡ç®—æµ‹è¯•é›†çš„rmse losså¹¶æ·»åŠ åˆ°åˆ—è¡¨
        if test_labels is not None:
            test_ls.append(log_rmse(net, test_features, test_labels))
    return train_ls, test_ls    # è¿”å›è®­ç»ƒå’Œæµ‹è¯•æŸå¤±çš„åˆ—è¡¨é•¿åº¦åˆ†åˆ«ä¸ºepochæ­¤å¤„
```

- å®šä¹‰ K-æŠ˜äº¤å‰éªŒè¯æ­¥éª¤

```python
# å¯¹æ•°æ®è¿›è¡Œk-æŠ˜äº¤å‰éªŒè¯çš„åˆ’åˆ†ï¼Œå¹¶è¿”å›ç¬¬iæŠ˜çš„è®­ç»ƒæ•°æ®æ•°æ®å’ŒéªŒè¯æ•°æ®
def get_k_fold_data(k, i, X, y):
    assert k > 1
    fold_size = X.shape[0] // k     # â€œ//â€ä»£è¡¨zæ•´é™¤ï¼Œå¾—åˆ°æ¯æŠ˜åº”æœ‰çš„æ ·æœ¬æ•°
    X_train, y_train = None, None

    for j in range(k):
         # slice(start, stop[, step])è¿”å›ä¸€ä¸ªåˆ‡ç‰‡ç´¢å¼•
        idx = slice(j * fold_size, (j + 1) * fold_size)
        # æ¯ä¸ªå¾ªç¯åˆ‡ç‰‡å‡ºfold_sizeä¸ªå­æ•°æ®é›†j
        X_part, y_part = X[idx, :], y[idx]
        # å½“å¾ªç¯è‡³æŒ‡å®šçš„ç¬¬iå—æ—¶ï¼Œå–å‡ºå½“ä½œvalidéªŒè¯é›†
        if j == i:
            X_valid, y_valid = X_part, y_part
        # å¦åˆ™å½“X_trainä¸ºç©ºæ—¶ï¼Œå–å‡ºç¬¬jå—å½“ä½œè®­ç»ƒé›†
        elif X_train is None:
            X_train, y_train = X_part, y_part
        # å½“è®­ç»ƒé›†ä¸ä¸ºç©ºæ—¶ï¼Œçºµå‘ä¾æ¬¡è¿ç»“æ•°æ®é›†
        else:
            X_train = torch.cat([X_train, X_part], 0)
            y_train = torch.cat([y_train, y_part], 0)
    # è¿”å›çš„æ˜¯ç¬¬iä¸ªæŠ˜ä¸ºæµ‹è¯•æ•°æ®é›†é›†ã€å…¶ä½™ä¸ºè®­ç»ƒæ•°æ®é›†çš„k-foldæ•°æ®
    return X_train, y_train, X_valid, y_valid


# å®šä¹‰k-æŠ˜è®­ç»ƒè¿‡ç¨‹
def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):
    train_l_sum, valid_l_sum = 0, 0
    # é€šè¿‡å¾ªç¯ï¼Œä¾æ¬¡å–å‡ºkæŠ˜çš„æ¯ä¸€å½“å‰æŠ˜çš„å­é›†ä½œä¸ºæµ‹è¯•æ•°æ®é›†ï¼Œå…¶ä½™ä¸ºè®­ç»ƒæ•°æ®é›†è¿›è¡Œè®­ç»ƒ
    for i in range(k):
        # ä»¥ç¬¬iæŠ˜ä¸ºæµ‹è¯•é›†ï¼Œå…¶ä½™ä¸ºè®­ç»ƒé›†
        data = get_k_fold_data(k, i, X_train, y_train)
        net = get_net()
        # *dataè¡¨ç¤ºæŠŠå…¶è¿”å›å€¼å…ƒç»„(X_train, y_train, X_valid, y_valid)ä¼ å‚
        # iåœ¨epochä¹‹å‰ï¼Œè¡¨ç¤ºå¯¹äºæ¯ä¸€æŠ˜ï¼Œè¿›è¡Œepochsæ¬¡è®­ç»ƒ
        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,
                                  weight_decay, batch_size)

        # æŠŠæ¯ä¸ªkæŠ˜è®­ç»ƒç»“æœçš„æœ€åä¸€ä¸ªï¼ˆä¹Ÿå°±æ˜¯æœ€ç²¾ç¡®ï¼‰epochçš„æŸå¤±åšç´¯åŠ ï¼Œ
        train_l_sum += train_ls[-1]
        valid_l_sum += valid_ls[-1]
        # åªç”»ç¬¬ä¸€æŠ˜çš„å›¾
        if i == 0:
            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],
                    xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs],
                    legend=['train', 'valid'], yscale='log')
        print(f'æŠ˜{i + 1}ï¼Œè®­ç»ƒlog rmse{float(train_ls[-1]):f},'
             f'éªŒè¯log rmse{float(valid_ls[-1]):f}')
    # è¿”å›æ‰€æœ‰æŠ˜çš„å¹³å‡æŸå¤±
    return train_l_sum / k, valid_l_sum / k
```

- ä½¿ç”¨ k-æŠ˜äº¤å‰éªŒè¯è¿›è¡Œè®­ç»ƒ
  > k=5ï¼Œepoch=100ï¼Œlearning_rate=5ï¼Œwd=0ï¼Œbatch_size=64

```python
k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64
train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,
                         weight_decay, batch_size)
#X_train: train_features.shape=(1459, 331), y_train: train_labels.shape=(1459, 1), k=5, batch_size=64
#data = get_k_fold_data(k, i, X_train, y_train)
#fold_size=1459//5=291
#i=0, X_part, y_part = X[(0:291), :], y[0:291]=X_valid, y_valid; X_train, y_train=X[(291:), :], y[291:]

print(f'{k}-æŠ˜éªŒè¯ï¼šå¹³å‡è®­ç»ƒlog rmse:{float(train_l):f},'
     f'å¹³å‡éªŒè¯log rmse: {float(valid_l):f}')#è¡¨ç¤ºå°æ•°å®šä¹‰ç²¾åº¦ï¼Œé»˜è®¤å…­ä½æµ®ç‚¹æ•°
#f'{}'æ˜¯{}.format()çš„ç®€æ˜“å†™æ³•
```

![result](https://zh.d2l.ai/_images/output_kaggle-house-price_1852a7_137_1.svg)

æ¥ä¸‹æ¥å°±éœ€è¦**ä¸æ–­è°ƒæ•´è®­ç»ƒçš„è¶…å‚æ•°å¹¶é‡å¤ä¸Šè¿° k-æŠ˜äº¤å‰éªŒè¯**ï¼Œå¦‚ epochã€lrã€wdã€net ç±»å‹ã€å‚æ•°åˆå§‹åŒ–ç­‰ç­‰ï¼Œé€šè¿‡æ¯”è¾ƒä¸åŒè¶…å‚æ•°åœ¨ k-æŠ˜äº¤å‰éªŒè¯çš„éªŒè¯æŸå¤±å¤§å°ï¼Œæ¥ç¡®å®šä¸€ä¸ªæœ€å¥½çš„è¶…å‚æ•°é€‰æ‹©ã€‚

ç¡®å®šå¥½è¶…å‚æ•°åï¼Œåœ¨è®­ç»ƒæ•°æ®é›†ä¸Šå†è®­ç»ƒä¸€æ¬¡ï¼Œå¹¶åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¿›è¡Œé¢„æµ‹ï¼Œå°†ç»“æœä¿å­˜è‡³ CSV æ–‡ä»¶å¹¶æäº¤ã€‚

- é¢„æµ‹æµ‹è¯•é›†å¹¶ä¿å­˜è¾“å‡º

```python
def train_and_pred(train_features, test_feature, train_labels, test_data,
                  num_epochs, lr, weight_decay, batch_size):
    net = get_net()
    train_ls, _ = train(net, train_features, train_labels, None, None,
                       num_epochs, lr, weight_decay, batch_size)
    #ä¼ å‡ºçš„æ˜¯æ¯ä¸ªepochçš„lossï¼Œè€Œtest_ls=None
    d2l.plot(np.arange(1, num_epochs + 1), [train_ls], xlabel = 'epoch',
            ylabel='log rmse', xlim=[1, num_epochs], yscale='log')
    print(f'train log rmse {float(train_ls[-1]):f}')    #è¾“å‡ºæœ€åä¸€ä¸ªepochçš„lossã€‚

    preds = net(test_features).detach().numpy() #detach()å°†å˜é‡ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»å¹¶æ¸…é™¤æ¢¯åº¦
    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])
    #(1, -1)æ’åˆ—ä¸ºä¸€è¡Œï¼Œå¹¶å–å‡ºç¬¬0ç»´ä½œä¸ºtest_data Dataframeå¯¹è±¡çš„'SalePrice'åˆ—
    #pd.Series()è½¬åŒ–ä¸ºä¸€ä¸ªpandas Serieså¯¹è±¡
    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)
    #æŠŠ['Id']åˆ—å’Œ['labels']ä»¥åˆ—(axis=1)æ¨ªå‘ç›¸è¿ã€‚
    submission.to_csv('submission.csv', index=False)
    #ä¿å­˜è·¯å¾„ä¸º./submission.csv
    #index=Falseï¼Œä¸ä¿å­˜ç´¢å¼•åˆ—

train_and_pred(train_features, test_features, train_labels, test_data,
              num_epochs, lr, weight_decay, batch_size)
```

![result](https://zh.d2l.ai/_images/output_kaggle-house-price_1852a7_161_1.svg)

## è¯¾åä½œä¸š

æœ¬èŠ‚è¯¾æœ€åï¼Œææ²è€å¸ˆåŠ¨å‘˜å¤§å®¶å» Kaggle ä¸Šåšä»–ä¸ºè¯¾ç¨‹ä¸“é—¨å¼€è®¾çš„ä¸€ä¸ªå°ç«èµ›**California House Prices**ï¼Œä½œä¸ºå‰æœŸå­¦ä¹ æ•ˆæœçš„å®è·µå·©å›ºå’Œæ£€éªŒã€‚å¤§å®¶å¯ä»¥ç‚¹å‡»ä¸‹å›¾è®¿é—®æŸ¥çœ‹ ğŸ‘‡ã€‚ç›®å‰ä»ç„¶å¯ä»¥æäº¤æˆç»©ï¼Œæ•´ä¸ªæ•°æ®é›†å¤§å°åœ¨ 80Mb å·¦å³ï¼Œæ¶‰åŠ 40 ä¸ªç‰¹å¾ï¼Œè®­ç»ƒæ•°æ®å…± 47439 æ¡ï¼Œæµ‹è¯•æ•°æ®å…± 31626 æ¡ã€‚

[![overview](Images/kaggle_California.png)](https://www.kaggle.com/c/california-house-prices/overview)

## Python æ¨¡å—å‚è€ƒæ–‡æ¡£

- `pandas.concat(objs, axis=0, join='outer', ignore_index=False, keys=None,levels=None, names=None, verify_integrity=False, copy=True)`Pandas Dataframe åˆå¹¶è¿ç»“æ“ä½œ ğŸ§[ä¸­æ–‡](http://www.pypandas.cn/docs/user_guide/merging.html#concatenating-objects) | [å®˜æ–¹è‹±æ–‡](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html#pandas-concat)
- `Dataframe.iloc()`Pandas ç´¢å¼•é€‰æ‹©å™¨ ğŸ§[ä¸­æ–‡](http://www.pypandas.cn/docs/user_guide/merging.html#concatenating-objects) | [å®˜æ–¹è‹±æ–‡](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html#pandas-concat)
- `Dataframe.dtypes` Pandas æ•°æ®ç±»å‹ ğŸ§ [å®˜æ–¹è‹±æ–‡](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#dtypes)
- `Dataframe.apply()` Pandas Apply å‡½æ•° ğŸ§[ä¸­æ–‡](http://www.pypandas.cn/docs/getting_started/10min.html#apply-%E5%87%BD%E6%95%B0) | [å®˜æ–¹è‹±æ–‡](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html?highlight=apply#pandas.DataFrame.apply)
- `pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)` Pandas å¯¹ç±»åˆ«ä¿¡æ¯è¿›è¡Œ one-hot ç¼–ç å‡½æ•° ğŸ§[ä¸­æ–‡](https://zhuanlan.zhihu.com/p/139144355) | [å®˜æ–¹è‹±æ–‡](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies)
- `hashlib`Python æ ‡å‡†åº“ hashlib å®‰å…¨å“ˆå¸Œä¸æ¶ˆæ¯æ–‡æ¡£ ğŸ§[å®˜æ–¹ä¸­æ–‡](https://docs.python.org/zh-cn/3/library/hashlib.html) | [å®˜æ–¹è‹±æ–‡](https://docs.python.org/3/library/hashlib.html)
- `tarfile`Python æ ‡å‡†åº“ tarfile è¯»å†™ tar å½’æ¡£æ–‡ä»¶æ–‡æ¡£ ğŸ§[å®˜æ–¹ä¸­æ–‡](https://docs.python.org/zh-cn/3/library/tarfile.html) | [å®˜æ–¹è‹±æ–‡](https://docs.python.org/3/library/tarfile.html)
- `zipfile`Python æ ‡å‡†åº“ zipfile è¯»å†™ zip å½’æ¡£æ–‡ä»¶æ–‡æ¡£ ğŸ§[å®˜æ–¹ä¸­æ–‡](https://docs.python.org/zh-cn/3/library/zipfile.html) | [å®˜æ–¹è‹±æ–‡](https://docs.python.org/3/library/zipfile.html)
- `requests`â€œRequestsï¼Œå”¯ä¸€çš„ä¸€ä¸ªéè½¬åŸºå› çš„ Python HTTP åº“â€ ğŸ§[å®˜æ–¹ä¸­æ–‡](https://docs.python-requests.org/zh_CN/latest/) | [å®˜æ–¹è‹±æ–‡](https://docs.python-requests.org/en/latest/)
- `torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)`PyTorch å®ç°çš„ Adam ä¼˜åŒ–å™¨æ–‡æ¡£ ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-optim/) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)
- `torch.cat(inputs, dimension=0)`PyTorch å¯¹è¾“å…¥å¼ é‡åºåˆ—è¿›è¡Œè¿æ¥æ“ä½œ ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch/#indexing-slicing-joining-mutating-ops) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/generated/torch.cat.html?highlight=cat#torch.cat)

---
