# 47 - é•¿çŸ­æœŸè®°å¿†ç½‘ç»œLSTM

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰
[![Bilibil](https://i0.hdslb.com/bfs/archive/05748657d6dcc33037810daa434d1d6301f481d7.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1JU4y1H7PC)

ä½œè€…ä¸æ·±åº¦å­¦ä¹ ä¸‰å·¨æœ‰çŸ›ç›¾ã€‚

### é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ

- å¿˜è®°é—¨ï¼šå°†å€¼æœ0å‡å°‘
- è¾“å…¥é—¨ï¼šå†³å®šä¸æ˜¯å¿½ç•¥æ‰è¾“å…¥æ•°æ®
- è¾“å‡ºé—¨ï¼šå†³å®šæ˜¯ä¸æ˜¯ä½¿ç”¨éšçŠ¶æ€

![](\Images/047-02.gif)

**é—¨**

$$
\begin{split}
&{\bf I}_t=\sigma({\bf X}_t{\bf W}_{xi}+{\bf H}_{t-1}{\bf W}_{hi}+{\bf b}_i)\\
&{\bf F}_t=\sigma({\bf X}_t{\bf W}_{xf}+{\bf H}_{t-1}{\bf W}_{hf}+{\bf b}_f)\\
&{\bf O}_t=\sigma({\bf X}_t{\bf W}_{xo}+{\bf H}_{t-1}{\bf W}_{ho}+{\bf b}_o)
\end{split}
$$

**å€™é€‰è®°å¿†å•å…ƒ**

$${\bf \~C}_t=tanh({\bf X}_t{\bf W}_{xc}+{\bf H}_{t-1}{\bf W}_{hc}+{\bf b}_c)$$

- RNNçš„è¾“å‡º
- ${\bf C, \~C}$ ä¸ $\bf H$ å½¢çŠ¶ç›¸åŒ

**è®°å¿†å•å…ƒ**

$${\bf C}_t={\bf F}_tâŠ™{\bf C}_{t-1}+{\bf I}_tâŠ™{\bf\~C}_t$$

- $F=0$ï¼Œèˆå»ä¸Šä¸€ä¸ªè®°å¿†å•å…ƒ
- $I=0$ï¼Œèˆå¼ƒå½“ä¸‹çš„è®°å¿†å•å…ƒ
- ä¸¤è€…ç›¸åŠ ï¼Œ${\bf C}_{t-1}$ å’Œ ${\bf\~C}_t$ éƒ½ç»è¿‡éçº¿æ€§å˜æ¢ï¼Œåœ¨ $0-1$ ä¹‹é—´ï¼Œæ‰€ä»¥${\bf C}_{t}$ åœ¨ $0-2$ ä¹‹é—´
  - ä»”ç»†æƒ³æ¥ï¼Œ$\bf C$ æ²¡æœ‰ç»è¿‡éçº¿æ€§ï¼Œå¯ä»¥å åŠ å‡ºæ¯”è¾ƒå¤§çš„å€¼ 
   
**éšçŠ¶æ€**

$${\bf H}_t={\bf O}_tâŠ™tanh({\bf C}_t)$$
- æ‰€ä»¥è¦å†æ¬¡éçº¿æ€§æŠŠ ${\bf C}_t$ clampä½ã€‚
- ${\bf O}_t=0$ï¼ŒæŠŠè¾“å…¥å’Œå‰ä¸€åˆ»çŠ¶æ€éƒ½èˆå¼ƒï¼Œç›¸å½“äºé‡ç½® ${\bf H}_t$
- ${\bf O}$ æ˜¯å¯¹ ${\bf H}$ çš„ä¿å­˜ä¸å¦
- ç›¸å½“äº ${\bf C}$ æ˜¯å¯¹ ${\bf H}$ çŠ¶æ€çš„ä¸­é—´é‡

**è¾“å‡º**

${\bf O}_t=\phi({\bf W}_{ho}{\bf H}_t+{\bf b}_o)$

- ä¸RNNæœ€åå½¢å¼ç›¸åŒ

![](\Images/047-03.png)

### ä»£ç å®ç°

LSTMã€GRUå’ŒRNNåªæ˜¯çŸ©é˜µè¿ç®—çš„forwardå‡½æ•°ä¸Šç•¥æœ‰ä¸åŒã€‚

```
import torch
from torch import nn
from d2l import torch as d2l

batch_size, num_steps = 32, 35
train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
```
```
def get_lstm_params(vocab_size, num_hiddens, device):
    num_inputs = num_outputs = vocab_size

    def normal(shape):
        return torch.randn(size=shape, device=device)*0.01

    def three():
        return (normal((num_inputs, num_hiddens)),
                normal((num_hiddens, num_hiddens)),
                torch.zeros(num_hiddens, device=device))

    W_xi, W_hi, b_i = three()  # è¾“å…¥é—¨å‚æ•°
    W_xf, W_hf, b_f = three()  # é—å¿˜é—¨å‚æ•°
    W_xo, W_ho, b_o = three()  # è¾“å‡ºé—¨å‚æ•°
    W_xc, W_hc, b_c = three()  # å€™é€‰è®°å¿†å…ƒå‚æ•°
    # è¾“å‡ºå±‚å‚æ•°
    W_hq = normal((num_hiddens, num_outputs))
    b_q = torch.zeros(num_outputs, device=device)
    # é™„åŠ æ¢¯åº¦
    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,
              b_c, W_hq, b_q]
    for param in params:
        param.requires_grad_(True)
        #tensoræ‰æœ‰requires_gradå±æ€§
    return params
```
```
def init_lstm_state(batch_size, num_hiddens, device):
    return (torch.zeros((batch_size, num_hiddens), device=device),#Håˆå§‹åŒ–
            torch.zeros((batch_size, num_hiddens), device=device)) # Cåˆå§‹åŒ–
```
```
def lstm(inputs, state, params):
    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,
     W_hq, b_q] = params
    (H, C) = state
    outputs = []
    for X in inputs:
        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)
        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)
        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)
        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)
        C = F * C + I * C_tilda
        H = O * torch.tanh(C)
        Y = (H @ W_hq) + b_q
        #è¾“å‡ºè¿˜æ˜¯åœ¨Hä¸Š
        outputs.append(Y)
    return torch.cat(outputs, dim=0), (H, C)
```
```
vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu()
num_epochs, lr = 500, 1
model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params,
                            init_lstm_state, lstm)
d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)
```
![](Images/047-04.png)