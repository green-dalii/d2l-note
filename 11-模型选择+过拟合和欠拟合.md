# 11 - æ¨¡å‹é€‰æ‹©å’Œè¿‡æ‹Ÿåˆæ¬ æ‹Ÿåˆ

---

ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰
[![Bilibil](https://i2.hdslb.com/bfs/archive/5ca1d49f172c9940461d6b42d51e9c7d89da3c2a.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1kX4y1g7jp?spm_id_from=333.999.0.0)

## æ¨¡å‹é€‰æ‹©

**è®­ç»ƒè¯¯å·®**ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šçš„è¯¯å·®ã€‚

**æ³›åŒ–è¯¯å·®**ï¼šæ¨¡å‹åœ¨æ–°æ•°æ®é›†ä¸Šçš„è¯¯å·®ã€‚

**éªŒè¯æ•°æ®é›†**ï¼šä¸€ä¸ªç”¨æ¥è¯„ä¼°æ¨¡å‹å¥½åçš„æ•°æ®é›†ã€‚

**æµ‹è¯•æ•°æ®é›†**ï¼šåªç”¨ä¸€æ¬¡çš„æ•°æ®é›†ã€‚ï¼ˆä¸èƒ½ç”¨æ¥è°ƒæ•´è¶…å‚æ•°ï¼‰

**K-åˆ™äº¤å‰éªŒè¯**

å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®é›†ï¼Œå°†è®­ç»ƒæ•°æ®é›†åˆ†å‰²æˆ $K$ å—ï¼Œ
For $i=1,...,K$
ä½¿ç”¨ç¬¬ $i$ å—ä½œä¸ºéªŒè¯æ•°æ®é›†ï¼Œå…¶ä½™çš„ä½œä¸ºè®­ç»ƒæ•°æ®é›†ã€‚
æŠ¥å‘Š $K$ ä¸ªéªŒè¯é›†è®­ç»ƒçš„è¯¯å·®ï¼Œ
å¸¸ç”¨$K=5$æˆ–$10$

å–ç²¾åº¦æœ€å¥½å¯¹æ¯ä¸ªè¶…å‚æ•°è¿›è¡Œè°ƒæ•´ã€‚

## è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ(overfitting and underfitting)

|  æ¨¡å‹å¤æ‚åº¦\æ•°æ®é›† |ç®€å•   |å¤æ‚   |
|---|---|---|
| ä½ | æ­£å¸¸  | æ¬ æ‹Ÿåˆ  |
| é«˜ | è¿‡æ‹Ÿåˆ| æ­£å¸¸|

- **æ¨¡å‹å®¹é‡**

æ‹Ÿåˆå„ç§å‡½æ•°çš„èƒ½åŠ›

ä½å®¹é‡çš„æ¨¡å‹éš¾ä»¥æ‹Ÿåˆè®­ç»ƒæ•°æ®

é«˜å®¹é‡çš„æ¨¡å‹å¯ä»¥è®°ä½æ‰€æœ‰çš„è®­ç»ƒæ•°æ®

![æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆ](Images/overfitting_2.png)

![è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ](Images/1_4LnmIbcIiHM0g8q_XJrD7A.gif)


![ç›¸å…³è¯¯å·®](Images/Screenshot-2020-02-06-at-11.09.13.png)

è¦æ—¨åœ¨äºï¼Œé¦–å…ˆä¿è¯æ¨¡å‹å®¹é‡ï¼Œå†æ§åˆ¶ç²¾åº¦ï¼Œå¯èƒ½ä¼šæ‰¿å—ä¸€å®šçš„è¿‡æ‹Ÿåˆã€‚

**ä¼°è®¡æ¨¡å‹å®¹é‡**

éš¾ä»¥åœ¨ä¸åŒç§ç±»ç®—æ³•ä¹‹é—´æ¯”è¾ƒï¼Œä¾‹å¦‚æ ‘æ¨¡å‹å’Œç¥ç»ç½‘ç»œã€‚

ç»™å®šä¸€ä¸ªæ¨¡å‹ç§ç±»ï¼Œå°†æœ‰ä¸¤ä¸ªä¸»è¦å› ç´ ï¼š

- å‚æ•°çš„ä¸ªæ•°
- å‚æ•°å€¼çš„é€‰æ‹©èŒƒå›´

**VCç»´**

ç»Ÿè®¡å­¦ä¹ ç†è®ºçš„ä¸€ä¸ªæ ¸å¿ƒæ€æƒ³

å¯¹ä¸€ä¸ªåˆ†ç±»æ¨¡å‹ï¼ŒVCç»´ç­‰äºä¸€ä¸ªæœ€å¤§çš„æ•°æ®é›†å¤§å°ï¼Œä¸ç®¡å¦‚ä½•ç»™å®šæ ‡å·ï¼Œéƒ½å­˜åœ¨ä¸€ä¸ªæ¨¡å‹æ¥å¯¹å®ƒè¿›è¡Œå®Œç¾åˆ†ç±»ã€‚= èƒ½å¤Ÿå®Œç¾åœ°è®°ä½ä¸€ä¸ªæ•°æ®é›†ã€‚

Eg:2ç»´è¾“å…¥çš„æ„ŸçŸ¥æœºï¼Œ VCç»´=3ï¼Œå³èƒ½å¤Ÿåˆ†ç±»ä»»ä½•ä¸‰ä¸ªç‚¹ï¼Œä½†ä¸æ˜¯å››ä¸ª(XOR)ã€‚

æ”¯æŒNç»´è¾“å…¥çš„æ„ŸçŸ¥æœºVCç»´æ˜¯N+1ï¼Œ
ä¸€äº›å¤šå±‚æ„ŸçŸ¥æœºçš„VCç»´æ˜¯$O(Nlog_2N)$

æä¾›äº†ä¸ºä»€ä¹ˆä¸€ä¸ªæ¨¡å‹å¥½çš„ç†è®ºä¾æ®ï¼Œå¯ä»¥è¡¡é‡è®­ç»ƒè¯¯å·®å’Œæ³›åŒ–è¯¯å·®ä¹‹é—´çš„é—´éš”ã€‚

ä½†æ·±åº¦å­¦ä¹ ä¸­å¾ˆå°‘ä½¿ç”¨ï¼š
- è¡¡é‡ä¸æ˜¯å¾ˆå‡†ç¡®
- è®¡ç®—æ·±åº¦å­¦ä¹ æ¨¡å‹çš„VCç»´å¾ˆå›°éš¾

**æ•°æ®å¤æ‚åº¦**

- æ ·æœ¬ä¸ªæ•°
- æ¯ä¸ªæ ·æœ¬çš„å…ƒç´ ä¸ªæ•°ï¼ˆå¼ é‡çš„ç»´åº¦å’Œå¤§å°ï¼‰
- æ—¶é—´ã€ç©ºé—´ç»“æ„ï¼ˆå›¾ç‰‡çš„ç©ºé—´ç»“æ„ã€è§†é¢‘çš„æ—¶é—´ç©ºé—´ç»´åº¦ï¼‰
- å¤šæ ·æ€§ï¼ˆå¦‚åˆ†å‡ ç±»ï¼‰

æ¨¡å‹å®¹é‡éœ€è¦åŒ¹é…æ•°æ®å¤æ‚åº¦

ç»Ÿè®¡å­¦æä¾›äº†ä¸€äº›ç†è®ºä¾æ®ï¼Œå®é™…è¦é è®­ç»ƒ/æ³›åŒ–è¯¯å·®å¯¹æ¯”

## ä»£ç å®ä¾‹

å¯¹ä¸‰é˜¶å¤šé¡¹å¼ç”Ÿæˆè®­ç»ƒå’Œæµ‹è¯•æ•°æ®ï¼š

$$y=5+1.2x-3.4{x^2\over2!}+5.6{x^3\over3!}+\epsilon\ where\ \epsilon\sim\aleph(0,0.1^2)$$

ç”¨é˜¶ä¹˜ä½œä¸ºåˆ†æ¯æŠµæ¶ˆæ±‚å¯¼ç³»æ•°çš„å½±å“ã€‚

- **åˆ›å»ºæ•°æ®é›†**

```
import numpy as np
import math
import torch
from torch import nn
from d2l import torch as d2l

max_degree = 20
n_train, n_test = 100, 1000
true_w = np.zeros(max_degree)
true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])
#å…¶ä½™w=0ï¼Œå™ªéŸ³é¡¹ï¼Œå³ä¸€ä¸ª20ç»´çš„å‘é‡ï¼Œåªæœ‰å‰å››é¡¹æœ‰å®å€¼ã€‚

features = np.random.normal(size=(n_train + n_test, 1))
# np.random.normalçš„ä½ç½®å‚æ•°loc=0.0,scale=1.0å®šä¹‰äº†æ­£æ€åˆ†å¸ƒ
# size=(1100, 1)è¿”å›ä¸€ä¸ªé•¿åº¦1100çš„åˆ—å‘é‡
np.random.shuffle(features)
poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))
# np.power(a,b)è¿”å›a**b,å¦‚æœæ˜¯ä¸¤ä¸ªä¸åŒç»´åº¦çš„æ•°ç»„ï¼Œåˆ™ä»¥è¡Œä¸ºå¹¿æ’­æ³•åˆ™ã€‚
# (1100,1)**(1,20)=(1100,20)
for i in range(max_degree):
    poly_features[:, i] /= math.gamma(i + 1)
    #å¯¹å…¶è¿›è¡Œgammaå‡½æ•°å˜æ¢ï¼Œå¯ä»¥è§†ä½œé˜¶ä¹˜gamma(z)=(z-1)!
labels = np.dot(poly_features, true_w)
# (1100,20)*(20,1)=(1100,1)
labels += np.random.normal(scale=.1, size=labels.shape)
# åå·®b, y = XwT + b
# è¿™1100ä¸ªæ•£ç‚¹åŠ ä¸Šæ‰°åŠ¨(ç¬¬5-20é˜¶è®¡ç®—)ä¸åå·®ä¹‹å’Œï¼Œå·²ç»ä¸å®Œå…¨æœä»åŸå¤šé¡¹å¼ï¼Œæ‰€ä»¥è¦å…ˆæ‹Ÿåˆå‡ºæ›²çº¿ã€‚

true_w, features, poly_features, labels = [torch.tensor(x, dtype=torch.float32) for x in [true_w, features, poly_features, labels]]

features[:2], poly_features[:2, :], labels[:2]
```

- **è®­ç»ƒ**

```
def evaluate_loss(net, data_iter, loss):  
    metric = d2l.Accumulator(2)  
    for X, y in data_iter:
        out = net(X)
        y = y.reshape(out.shape)
        #æŠŠyå’Œy_hatå½¢çŠ¶ç»Ÿä¸€
        l = loss(out, y)
        metric.add(l.sum(), l.numel())
    return metric[0] / metric[1]
```
```
def train(train_features, test_features, train_labels, test_labels,
          num_epochs=400):
    #features-x;labels-y
    loss = nn.MSELoss(reduction='none')
    #æŸå¤±ä¸æ±‚å¹³å‡
    input_shape = train_features.shape[-1]
    #train_features.shapeæ˜¯è¿”å›çš„æ˜¯(m,n)çš„å…ƒç»„ï¼Œæ‰€ä»¥-1ä»£è¡¨åˆ—æ‰€å¯¹åº”å…ƒç´ nã€‚
    #inputæ˜¯poly_features[:,:n],æ­£å¸¸æ˜¯4é˜¶ï¼Œæ¬ æ‹Ÿåˆ<4ï¼Œè¿‡æ‹Ÿåˆ>4
    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False))
    #(nï¼Œ1), y_hat = w1x1+w2x2+w3x3+w4x4ï¼Œå›å½’ç»“æœåªè€ƒè™‘å‰å››é¡¹ã€‚
    #å¦‚æœæ¬ æ‹Ÿåˆï¼Œå°±ä¼šæ¼é¡¹ï¼›å¦‚æœè¿‡æ‹Ÿåˆï¼Œå°±ä¼šå¤šè€ƒè™‘å¹²æ‰°é¡¹ã€‚
    batch_size = min(10, train_labels.shape[0])
    #labelsæ˜¯ä¸€ä¸ªå‘é‡ï¼Œåªæœ‰ä¸€ä¸ªç»´åº¦ï¼Œä¸º1000ï¼Œä½†æ˜¯.shape()è¿”å›çš„æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œæ‰€ä»¥å¿…é¡»æå–å…ƒç´ ã€‚
    train_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)),
                                batch_size)
    #.load_array/DataLoaderéƒ½æ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼Œä»æå–(train_features, train_labels.reshape(-1,1)
    #ä¸¤ä¸ªæ•°æ®æºåˆ†åˆ«ä½œä¸ºæå–æºï¼Œæ¯æ¬¡æ‰¹é‡=batch_size
    #æŠŠlabelså˜æˆäºŒç»´çŸ©é˜µï¼Œä¸featuresç»Ÿä¸€ç»´åº¦ï¼Œä»è€Œæå–ã€‚
    #is_trainè¡¨ç¤ºç”¨äºè®­ç»ƒã€‚
    test_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)),
                               batch_size, is_train=False)
    trainer = torch.optim.SGD(net.parameters(), lr=0.001)
    animator = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log',
                            xlim=[1, num_epochs], ylim=[1e-3, 1e2],
                            legend=['train', 'test'])
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net, train_iter, loss, trainer)
        if epoch == 0 or (epoch + 1) % 20 == 0:
            animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),
                                     evaluate_loss(net, test_iter, loss)))
            #å¤§æ¦‚å°±æ˜¯è¯´æ¯20ä¸ªepochç»˜åˆ¶ä¸€ä¸ªæ•°æ®ç‚¹ã€‚
    print('weight:', net[0].weight.data.numpy())
    #netæ˜¯ä¸€ä¸ªSequential()çš„æ¨¡å—æ‰“åŒ…å…ƒç»„ï¼Œnet[0]å°±æ˜¯nn.Linearæ¨¡å—
    #ç”¨.data.numpy()å°†å¼ é‡è½¬åŒ–æˆæ•°ç»„
                         
```
- **æ­£å¸¸æ‹Ÿåˆ**

```
# ä»å¤šé¡¹å¼ç‰¹å¾ä¸­é€‰æ‹©å‰4ä¸ªç»´åº¦ï¼Œå³1,x,x^2/2!,x^3/3!
train(poly_features[:n_train, :4], poly_features[n_train:, :4],
      labels[:n_train], labels[n_train:])
#å–å‰1000å’Œå100ä½œä¸ºè®­ç»ƒ/æµ‹è¯•ï¼Œå¹¶ä¸”åªé€‰æ‹©æ­£ç¡®çš„å‰å››é˜¶ã€‚
#labelsæ˜¯æ‰€æœ‰æ‰°åŠ¨å’Œå½¢æˆçš„æ•£ç‚¹
```
![æ­£å¸¸æ‹Ÿåˆ](Images/æ­£å¸¸æ‹Ÿåˆ.png)

- **æ¬ æ‹Ÿåˆ**
```
# ä»å¤šé¡¹å¼ç‰¹å¾ä¸­é€‰æ‹©å‰4ä¸ªç»´åº¦ï¼Œå³1,x,x^2/2!,x^3/3!
train(poly_features[:n_train, :4], poly_features[n_train:, :4],
      labels[:n_train], labels[n_train:])
#å–å‰1000å’Œå100ä½œä¸ºè®­ç»ƒ/æµ‹è¯•ï¼Œå¹¶ä¸”åªé€‰æ‹©æ­£ç¡®çš„å‰å››é˜¶ã€‚
#labelsæ˜¯æ‰€æœ‰æ‰°åŠ¨å’Œå½¢æˆçš„æ•£ç‚¹
```
![æ¬ æ‹Ÿåˆ](Images/æ¬ æ‹Ÿåˆ.png)
- **è¿‡æ‹Ÿåˆ**

```
# ä»å¤šé¡¹å¼ç‰¹å¾ä¸­é€‰å–æ‰€æœ‰ç»´åº¦
train(poly_features[:n_train, :], poly_features[n_train:, :],
      labels[:n_train], labels[n_train:], num_epochs=1500)
```
![è¿‡æ‹Ÿåˆ](Images/è¿‡æ‹Ÿåˆ.png)

å…³äºæœºå™¨å­¦ä¹ æ¨¡å‹æœ‰ä¸€ä¸ªé‡ç‚¹ï¼Œå› ä¸ºè®¡ç®—æ˜¯åŸºäºå¼ é‡çš„çŸ©é˜µè¿ç®—ï¼Œæ‰€ä»¥è¦æ˜ç¡®æ¯ä¸€ä¸ªæ¨¡å—é‡Œè¾“å…¥è¾“å‡ºçš„ç»´åº¦å’Œæ•°æ®ç±»å‹ï¼Œæ•´ä½“å½¢çŠ¶çš„ç»Ÿä¸€ï¼Œè¿˜æœ‰å†…ç½®è¿ç®—æ˜¯å¦å­˜åœ¨è½¬ç½®ï¼Œå»ºè®®æ¯æ¬¡å®šä¹‰/å¼•ç”¨ä¸€ä¸ªæ•°æ®é›†æ—¶æ³¨é‡Šå…¶ç»´åº¦ï¼Œå¹¶åœ¨æ¨¡å—å¼•ç”¨æ—¶æ³¨é‡Šç›¸åº”çš„è°ƒå…¥ç»´åº¦ï¼Œä½¿å‰åç›¸åŒ¹é…ã€‚