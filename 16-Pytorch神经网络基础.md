# 16 - Pytorch ç¥ç»ç½‘ç»œåŸºç¡€

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‡

[![Bilibil](https://i0.hdslb.com/bfs/archive/9a09827a8220e688f6866c928f58f5a256788aab.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1AK4y1P7vs)

## å±‚å’Œå—

**å—**ï¼ˆblockï¼‰å¯ä»¥æè¿°å•ä¸ªå±‚ã€ç”±å¤šä¸ªå±‚ç»„æˆçš„ç»„ä»¶æˆ–æ•´ä¸ªæ¨¡å‹æœ¬èº«ã€‚ä½¿ç”¨å—è¿›è¡ŒæŠ½è±¡çš„ä¸€ä¸ªå¥½å¤„æ˜¯å¯ä»¥å°†ä¸€äº›å—ç»„åˆæˆæ›´å¤§çš„ç»„ä»¶ï¼Œ è¿™ä¸€è¿‡ç¨‹é€šå¸¸æ˜¯é€’å½’çš„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ é€šè¿‡å®šä¹‰ä»£ç æ¥æŒ‰éœ€ç”Ÿæˆä»»æ„å¤æ‚åº¦çš„å—ï¼Œ æˆ‘ä»¬å¯ä»¥**é€šè¿‡ç®€æ´çš„ä»£ç å®ç°å¤æ‚çš„ç¥ç»ç½‘ç»œ**ã€‚

![block](https://zh.d2l.ai/_images/blocks.svg)

ä»ç¼–ç¨‹çš„è§’åº¦æ¥çœ‹ï¼Œå—ç”±**ç±»**ï¼ˆclassï¼‰è¡¨ç¤ºã€‚ å®ƒçš„ä»»ä½•å­ç±»éƒ½å¿…é¡»å®šä¹‰ä¸€ä¸ªå°†å…¶è¾“å…¥è½¬æ¢ä¸ºè¾“å‡ºçš„å‰å‘ä¼ æ’­å‡½æ•°ï¼Œ å¹¶ä¸”å¿…é¡»å­˜å‚¨ä»»ä½•å¿…éœ€çš„å‚æ•°ã€‚

### ä½¿ç”¨ Sequential å®ç°å±‚

`nn.Sequential`å®šä¹‰äº†ä¸€ç§ç‰¹æ®Šçš„ Moduleï¼Œé€šè¿‡å®ä¾‹åŒ– nn.Sequential æ¥æ„å»ºæˆ‘ä»¬çš„æ¨¡å‹ï¼Œ å±‚çš„æ‰§è¡Œé¡ºåºæ˜¯ä½œä¸ºå‚æ•°ä¼ é€’çš„ã€‚

```python
import torch
from torch import nn
from torch.nn import functional as F

net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256,10))

X = torch.rand(2, 20)
net(X)
```

### ä½¿ç”¨ Block å®ç°å—

ä»»ä½•ä¸€ä¸ªå±‚ã€ç¥ç»ç½‘ç»œéƒ½å¯ä»¥çœ‹ä½œ Module çš„ä¸€ä¸ªå­ç±»ã€‚

```python
class MLP(nn.Module):
    # å¿…é¡»å…ˆä½¿ç”¨çˆ¶ç±»çš„initåˆå§‹åŒ–ï¼Œæ¥ä¸‹æ¥å¯ä»¥å®šä¹‰å„å±‚
    def __init__(self):
        super().__init__()
        self.hidden = nn.Linear(20, 256)
        self.out = nn.Linear(256, 10)
    # å¿…é¡»é‡æ–°å®šä¹‰å‰é¦ˆè¿‡ç¨‹
    def forward(self, X):
        return self.out(F.relu(self.hidden(X)))

net = MLP()
net(X)
```

### è‡ªå®šä¹‰ Sequential å®ç°

```python
class MySequential(nn.Module):
    def __init__(self, *args):
        super().__init__()
        for idx, module in enumerate(args):
            # è¿™é‡Œï¼Œ`module`æ˜¯`Module`å­ç±»çš„ä¸€ä¸ªå®ä¾‹ã€‚æˆ‘ä»¬æŠŠå®ƒä¿å­˜åœ¨'Module'ç±»çš„æˆå‘˜
            # å˜é‡`_modules` ä¸­ã€‚`module`çš„ç±»å‹æ˜¯OrderedDict
            self._modules[str(idx)] = module

    def forward(self, X):
        # OrderedDictä¿è¯äº†æŒ‰ç…§æˆå‘˜æ·»åŠ çš„é¡ºåºéå†å®ƒä»¬
        for block in self._modules.values():
            X = block(X)
        return X

net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))
net(X)
```

### è‡ªå®šä¹‰ Block å®ç°

```python
class FixedHiddenMLP(nn.Module):
    def __init__(self):
        super().__init__()
        #éšæœºç”Ÿæˆ20*20ä¸å‚ä¸è®­ç»ƒçš„æƒé‡
        self.rand_weight = torch.rand((20, 20), requires_grad=False)
        self.linear = nn.Linear(20, 20)

    def forward(self, X):
        X = self.linear(X)
        X = F.relu(torch.mm(X, self.rand_weight) + 1)   ##torch.mm()çŸ©é˜µä¹˜æ³•ï¼Œå‡è®¾æœ‰ä¸€ä¸ªåç§»1
        X = self.linear(X)
        # å¯ä»¥åœ¨å‰å‘è®¡ç®—ä¸­ä½¿ç”¨Pythonæ§åˆ¶æµæ¥å®ç°æ›´å¤æ‚çš„è¿‡ç¨‹
        while X.abs().sum() > 1:
            X /= 2
        return X.sum()

net = FixedHiddenMLP()
net(X)
```

> åœ¨è¿™ä¸ª`FixedHiddenMLP`æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªéšè—å±‚ï¼Œ
> å…¶æƒé‡ï¼ˆ`self.rand_weight`ï¼‰åœ¨å®ä¾‹åŒ–æ—¶è¢«éšæœºåˆå§‹åŒ–ï¼Œä¹‹åä¸ºå¸¸é‡ã€‚
> è¿™ä¸ªæƒé‡ä¸æ˜¯ä¸€ä¸ªæ¨¡å‹å‚æ•°ï¼Œå› æ­¤å®ƒæ°¸è¿œä¸ä¼šè¢«åå‘ä¼ æ’­æ›´æ–°ã€‚
> ç„¶åï¼Œç¥ç»ç½‘ç»œå°†è¿™ä¸ªå›ºå®šå±‚çš„è¾“å‡ºé€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚
>
> æ³¨æ„ï¼Œåœ¨è¿”å›è¾“å‡ºä¹‹å‰ï¼Œæ¨¡å‹åšäº†ä¸€äº›ä¸å¯»å¸¸çš„äº‹æƒ…ï¼š
> å®ƒè¿è¡Œäº†ä¸€ä¸ª while å¾ªç¯ï¼Œåœ¨$L_1$èŒƒæ•°å¤§äº$1$çš„æ¡ä»¶ä¸‹ï¼Œ
> å°†è¾“å‡ºå‘é‡é™¤ä»¥$2$ï¼Œç›´åˆ°å®ƒæ»¡è¶³æ¡ä»¶ä¸ºæ­¢ã€‚
> æœ€åï¼Œæ¨¡å‹è¿”å›äº†`X`ä¸­æ‰€æœ‰é¡¹çš„å’Œã€‚
> æ³¨æ„ï¼Œæ­¤æ“ä½œå¯èƒ½ä¸ä¼šå¸¸ç”¨äºåœ¨ä»»ä½•å®é™…ä»»åŠ¡ä¸­ï¼Œ
> æˆ‘ä»¬åªæ˜¯å‘ä½ å±•ç¤ºå¦‚ä½•å°†ä»»æ„ä»£ç é›†æˆåˆ°ç¥ç»ç½‘ç»œè®¡ç®—çš„æµç¨‹ä¸­ã€‚

### æ··åˆ Sequential å’Œ Block ä½¿ç”¨

```python
class NestMLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),
                                nn.Linear(64, 32), nn.ReLU())
        self.linear = nn.Linear(32, 16)

    def forward(self, X):
        return self.linear(self.net(X))

chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())
chimera(X)
```

ç»¼ä¸Šï¼Œå—å¯ä»¥ç†è§£ä¸ºèƒ½å¤Ÿå®ç°ä¸€ä¸ªæˆ–å¤šä¸ªå±‚çš„ç±»ï¼Œé€šè¿‡å®šä¹‰ç±»çš„å®ä¾‹åŒ–æ¥å®Œæˆç¥ç»ç½‘ç»œçš„è¿ç®—ã€‚

## å‚æ•°ç®¡ç†

### å‚æ•°è®¿é—®

æˆ‘ä»¬ä»å·²æœ‰æ¨¡å‹ä¸­è®¿é—®å‚æ•°ã€‚å½“é€šè¿‡`Sequential`ç±»å®šä¹‰æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç´¢å¼•æ¥è®¿é—®æ¨¡å‹çš„ä»»æ„å±‚ã€‚è¿™å°±åƒæ¨¡å‹æ˜¯ä¸€ä¸ªåˆ—è¡¨ä¸€æ ·ï¼Œæ¯å±‚çš„å‚æ•°éƒ½åœ¨å…¶å±æ€§ä¸­ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚çš„å‚æ•°ã€‚

> `state_dict()` æŸ¥çœ‹å­—å…¸å½¢å¼çš„æ¨¡å‹å‚æ•°æ•°å€¼

```python
# å¯ä»¥æŠŠSequentialçœ‹ä½œä¸€ä¸ªlistï¼Œå¯ä»¥ç”¨ç´¢å¼•æ‹¿å‡ºæ¯ä¸€å±‚çš„å‚æ•°ã€‚å¾—åˆ°ä¸€ä¸ªæœ‰åºå­—å…¸ã€‚
print(net[2].state_dict())
# Outï¼šOrderedDict([('weight', tensor([[-0.0284,  0.0011, -0.2123,  0.2835,  0.3124,  0.0953, -0.2331, -0.2731]])), ('bias', tensor([-0.3001]))])
# module.state_dict().keys()=['weight','bias']
```

> è¾“å‡ºçš„ç»“æœå‘Šè¯‰æˆ‘ä»¬ä¸€äº›é‡è¦çš„äº‹æƒ…ï¼š
> é¦–å…ˆï¼Œè¿™ä¸ªå…¨è¿æ¥å±‚åŒ…å«ä¸¤ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯è¯¥å±‚çš„æƒé‡å’Œåç½®ã€‚
> ä¸¤è€…éƒ½å­˜å‚¨ä¸ºå•ç²¾åº¦æµ®ç‚¹æ•°ï¼ˆfloat32ï¼‰ã€‚
> æ³¨æ„ï¼Œå‚æ•°åç§°å…è®¸å”¯ä¸€æ ‡è¯†æ¯ä¸ªå‚æ•°ï¼Œå³ä½¿åœ¨åŒ…å«æ•°ç™¾ä¸ªå±‚çš„ç½‘ç»œä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚

### ç›®æ ‡å‚æ•°

æ¯ä¸ªå‚æ•°éƒ½è¡¨ç¤ºä¸º **å‚æ•°ç±»ï¼ˆParameterï¼‰** çš„ä¸€ä¸ªå®ä¾‹ã€‚è¦å¯¹å‚æ•°æ‰§è¡Œä»»ä½•æ“ä½œï¼Œé¦–å…ˆæˆ‘ä»¬éœ€è¦è®¿é—®åº•å±‚çš„æ•°å€¼ã€‚æœ‰å‡ ç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ã€‚æœ‰äº›æ¯”è¾ƒç®€å•ï¼Œè€Œå¦ä¸€äº›åˆ™æ¯”è¾ƒé€šç”¨ã€‚ä¸‹é¢çš„ä»£ç ä»ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ï¼ˆå³ç¬¬ä¸‰ä¸ªç¥ç»ç½‘ç»œå±‚ï¼‰æå–åç½®ï¼Œæå–åè¿”å›çš„æ˜¯ä¸€ä¸ªå‚æ•°ç±»å®ä¾‹ï¼Œå¹¶è¿›ä¸€æ­¥è®¿é—®è¯¥å‚æ•°çš„å€¼ã€‚

> `nn.bias/.weight(.data/.grad)` ç›´æ¥æŸ¥çœ‹å‚æ•°

```python
print(type(net[2].bias))
# Out:<class 'torch.nn.parameter.Parameter'>
print(net[2].bias)
# Out:Parameter containing:
# tensor([-0.3001], requires_grad=True)
print(net[2].bias.data)
# Out: tensor([-0.3001], requires_grad=True)
net[2].weight.grad == None  # .gradè®¿é—®æ¢¯åº¦
# Out: True
```

> å‚æ•°æ˜¯å¤åˆçš„å¯¹è±¡ï¼ŒåŒ…å«å€¼`.data`ã€æ¢¯åº¦`.grad`å’Œé¢å¤–ä¿¡æ¯ã€‚ è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦æ˜¾å¼å‚æ•°å€¼çš„åŸå› ã€‚ é™¤äº†å€¼ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è®¿é—®æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ã€‚

### ä¸€æ¬¡è®¿é—®æ‰€æœ‰å…ƒç´ 

å½“æˆ‘ä»¬éœ€è¦å¯¹æ‰€æœ‰å‚æ•°æ‰§è¡Œæ“ä½œæ—¶ï¼Œé€ä¸ªè®¿é—®å®ƒä»¬å¯èƒ½ä¼šå¾ˆéº»çƒ¦ã€‚ å½“æˆ‘ä»¬å¤„ç†æ›´å¤æ‚çš„å—ï¼ˆä¾‹å¦‚ï¼ŒåµŒå¥—å—ï¼‰æ—¶ï¼Œæƒ…å†µå¯èƒ½ä¼šå˜å¾—ç‰¹åˆ«å¤æ‚ï¼Œ å› ä¸ºæˆ‘ä»¬éœ€è¦é€’å½’æ•´ä¸ªæ ‘æ¥æå–æ¯ä¸ªå­å—çš„å‚æ•°ã€‚ ä¸‹é¢ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ¼”ç¤ºæ¥æ¯”è¾ƒè®¿é—®ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚çš„å‚æ•°å’Œè®¿é—®æ‰€æœ‰å±‚ã€‚

> `.named_parameters()` è¿”å› iteratorï¼Œç”¨äºå¾ªç¯ï¼Œè¿”å›(å‚æ•°å, å‚æ•°æ•°å€¼)ã€‚

```python
print(*[(name, param.shape) for name, param in net[0].named_parameters()])
print(*[(name, param.shape) for name, param in net.named_parameters()])
# *ä»£è¡¨æŠŠlist/tupleé‡Œçš„å…ƒç´ åˆ†å¼€ï¼Œè€Œéæ•´ä¸ªè¾“å‡º
```

è¿˜æä¾›äº†å¦ä¸€ç§è®¿é—®ç½‘ç»œå‚æ•°çš„æ–¹å¼ï¼Œé€šè¿‡åç§°ï¼ˆé»˜è®¤ä»¥`å±‚æ•°åºå·.weight or .bias`ï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

```python
net.state_dict()['2.bias'].data
```

### ä»åµŒå¥—å—æ”¶é›†å‚æ•°

> `.add_module(name, module`) åœ¨å½“å‰æ¨¡å—æ·»åŠ å«åç§°çš„å­æ¨¡å—ï¼Œç›¸æ¯”è¾ƒ`Sequential()`è€Œè¨€å¯ä»¥æŒ‡å®šå„å±‚åç§°ï¼ˆè€Œä¸æ˜¯é»˜è®¤çš„â€œ0ã€1ã€2â€¦â€¦â€ï¼‰

```python
def block1():
    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU())

def block2():
    net = nn.Sequential()
    for i in range(4):
        net.add_module(f'block {i}', block1())
        #åµŒå¥—å››ä¸ªblock1
        #add_module(name, module)
        #The module can be accessed as an attribute using the given name.
    return net

rgnet = nn.Sequential(block2(), nn.Linear(4, 1))
rgnet(X)
```

```python
print(rgnet)
'''
Out: Sequential(
  (0): Sequential(
    (block 0): Sequential(
      (0): Linear(in_features=4, out_features=8, bias=True)
      (1): ReLU()
      (2): Linear(in_features=8, out_features=4, bias=True)
      (3): ReLU()
    )
    (block 1): Sequential(
      (0): Linear(in_features=4, out_features=8, bias=True)
      (1): ReLU()
      (2): Linear(in_features=8, out_features=4, bias=True)
      (3): ReLU()
    )
    (block 2): Sequential(
      (0): Linear(in_features=4, out_features=8, bias=True)
      (1): ReLU()
      (2): Linear(in_features=8, out_features=4, bias=True)
      (3): ReLU()
    )
    (block 3): Sequential(
      (0): Linear(in_features=4, out_features=8, bias=True)
      (1): ReLU()
      (2): Linear(in_features=8, out_features=4, bias=True)
      (3): ReLU()
    )
  )
  (1): Linear(in_features=4, out_features=1, bias=True)
)
'''
```

å› ä¸ºå±‚æ˜¯åˆ†å±‚åµŒå¥—çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿå¯ä»¥åƒé€šè¿‡åµŒå¥—åˆ—è¡¨ç´¢å¼•ä¸€æ ·è®¿é—®å®ƒä»¬ã€‚ ä¸‹é¢ï¼Œæˆ‘ä»¬è®¿é—®ç¬¬ä¸€ä¸ªä¸»è¦çš„å—ä¸­ã€ç¬¬äºŒä¸ªå­å—çš„ç¬¬ä¸€å±‚çš„åç½®é¡¹ã€‚

```python
rgnet[0][1][0].bias.data
# Out: tensor([0.4441, 0.0795, 0.3999, 0.3522, 0.3384, 0.0372, 0.1860, 0.3830])
```

## å‚æ•°åˆå§‹åŒ–

çŸ¥é“äº†å¦‚ä½•è®¿é—®å‚æ•°åï¼Œç°åœ¨æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•æ­£ç¡®åœ°åˆå§‹åŒ–å‚æ•°ã€‚ æˆ‘ä»¬åœ¨[14-æ•°å€¼ç¨³å®šæ€§&æ¨¡å‹åˆå§‹åŒ–&æ¿€æ´»å‡½æ•°](14-æ•°å€¼ç¨³å®šæ€§&æ¨¡å‹åˆå§‹åŒ–&æ¿€æ´»å‡½æ•°.md)ä¸­è®¨è®ºäº†è‰¯å¥½åˆå§‹åŒ–çš„å¿…è¦æ€§ã€‚ æ·±åº¦å­¦ä¹ æ¡†æ¶æä¾›**é»˜è®¤éšæœºåˆå§‹åŒ–**ï¼Œ ä¹Ÿå…è®¸æˆ‘ä»¬åˆ›å»ºè‡ªå®šä¹‰åˆå§‹åŒ–æ–¹æ³•ï¼Œ æ»¡è¶³æˆ‘ä»¬é€šè¿‡å…¶ä»–è§„åˆ™å®ç°åˆå§‹åŒ–æƒé‡ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼ŒPyTorch ä¼š**æ ¹æ®ä¸€ä¸ªèŒƒå›´å‡åŒ€åœ°åˆå§‹åŒ–æƒé‡å’Œåç½®çŸ©é˜µ**ï¼Œ è¿™ä¸ªèŒƒå›´æ˜¯æ ¹æ®è¾“å…¥å’Œè¾“å‡ºç»´åº¦è®¡ç®—å‡ºçš„ã€‚ PyTorch çš„ nn.init æ¨¡å—æä¾›äº†å¤šç§é¢„ç½®åˆå§‹åŒ–æ–¹æ³•ã€‚

### å†…ç½®åˆå§‹åŒ–

- ä½¿ç”¨æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ï¼š`nn.init.normal(tensor, mean=0, std=1)`

```python
def init_normal(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, mean=0, std=0.01)
        # _è¡¨ç¤ºç›´æ¥æ›¿æ¢æ‰m.weightï¼Œè€Œéè¿”å›å€¼
        nn.init.zeros_(m.bias)

net.apply(init_normal)  #ç›¸å½“äºä¸€ä¸ªfor loop
net[0].weight.data[0], net[0].bias.data[0]
```

- ä½¿ç”¨å¸¸æ•°åˆå§‹åŒ–ï¼š`torch.nn.init.constant(tensor, val)`

```python
def init_constant(m):
    if type(m) == nn.Linear:
        nn.init.constant_(m.weight, 1)
        nn.init.zeros_(m.bias)

net.apply(init_constant)
net[0].weight.data[0], net[0].bias.data[0]
```

> å®é™…æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­ï¼Œä¸èƒ½æŠŠå‚æ•°åˆå§‹åŒ–ä¸ºå…¨1ï¼Œä¼šé€ æˆæ— æ³•è®­ç»ƒï¼Œå…·ä½“å¯å‚è€ƒ[10-å¤šå±‚æ„ŸçŸ¥æœº](10-å¤šå±‚æ„ŸçŸ¥æœº.md)QAç« èŠ‚ä¸­ç¬¬ä¸€ä¸ªé—®é¢˜

- ä½¿ç”¨Xavieréšæœºåˆå§‹åŒ–ï¼š`torch.nn.init.xavier_uniform(tensor, gain=1)`

```python
def xavier(m):
    if type(m) == nn.Linear:
        nn.init.xavier_uniform_(m.weight)
        #uniform distribution
```

- é’ˆå¯¹ä¸åŒå±‚ä½¿ç”¨ä¸åŒåˆå§‹åŒ–

```python
def init_42(m):
    if type(m) == nn.Linear:
        nn.init.constant_(m.weight, 42)
        #nn.initå‡½æ•°è®¾ç½®æ¨¡å—åˆå§‹å€¼

net[0].apply(xavier)
net[2].apply(init_42)
print(net[0].weight.data[0])
print(net[2].weight.data)
```

> è¿™é‡Œæ²ç¥è®²äº†**42â€”â€”å®‡å®™çš„ç­”æ¡ˆ**è¿™ä¸ªæ•°ã€Google Brainå›¢é˜Ÿ42å·å¤§æ¥¼çš„å…«å¦ğŸ˜„
> è¯¦ç»†å†…å®¹é€Ÿæ¥å›´è§‚æ²ç¥åœ¨çŸ¥ä¹ä¸Šå†™çš„ä¸“æ ğŸ‘‰[ã€Šåšå£«è¿™äº”å¹´-ææ²ã€‹](https://zhuanlan.zhihu.com/p/25099638)

### è‡ªå®šä¹‰åˆå§‹åŒ–

æœ‰æ—¶ï¼Œæ·±åº¦å­¦ä¹ æ¡†æ¶æ²¡æœ‰æä¾›æˆ‘ä»¬éœ€è¦çš„åˆå§‹åŒ–æ–¹æ³•ã€‚åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹çš„åˆ†å¸ƒä¸ºä»»æ„æƒé‡å‚æ•°$w$å®šä¹‰åˆå§‹åŒ–æ–¹æ³•ï¼š

$$
\begin{aligned}
    w \sim \begin{cases}
        U(5, 10) & \text{ å¯èƒ½æ€§ } \frac{1}{4} \\
            0    & \text{ å¯èƒ½æ€§ } \frac{1}{2} \\
        U(-10, -5) & \text{ å¯èƒ½æ€§ } \frac{1}{4}
    \end{cases}
\end{aligned}
$$

åŒæ ·ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ª`my_init`å‡½æ•°æ¥åº”ç”¨åˆ°`net`ï¼š

```python
def my_init(m):
    if type(m) == nn.Linear:
        print("Init", *[(name, param.shape)
                        for name, param in m.named_parameters()][0])
        nn.init.uniform_(m.weight, -10, 10)
        m.weight.data *= m.weight.data.abs() >= 5

net.apply(my_init)
net[0].weight[:2]
```

- ç®€å•ç²—æš´çš„ç›´æ¥èµ‹å€¼æ–¹å¼

```python
net[0].weight.data[:] += 1
net[0].weight.data[0, 0] = 42
net[0].weight.data[0] #é»˜è®¤å–è¡Œ
```

- å‚æ•°ç»‘å®šï¼ˆå…±äº«æƒé‡ï¼‰

```python
shared = nn.Linear(8, 8)
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared,
                   nn.ReLU(), nn.Linear(8, 1))
net(X)
print(net[2].weight.data[0] == net[4].weight.data[0])
net[2].weight.data[0, 0] == 100
# ä¼šåŒæ—¶ä¿®æ”¹ä¸¤ä¸ªshared, ç›¸å½“äºåŒä¸€ä¸ªå®ä¾‹çš„èµ‹å€¼
print(net[2].weight.data[0] == net[4].weight.data[0])
```

## è‡ªå®šä¹‰å±‚

æ·±åº¦å­¦ä¹ æˆåŠŸèƒŒåçš„ä¸€ä¸ªå› ç´ æ˜¯ç¥ç»ç½‘ç»œçš„çµæ´»æ€§ï¼š æˆ‘ä»¬å¯ä»¥ç”¨åˆ›é€ æ€§çš„æ–¹å¼ç»„åˆä¸åŒçš„å±‚ï¼Œä»è€Œè®¾è®¡å‡ºé€‚ç”¨äºå„ç§ä»»åŠ¡çš„æ¶æ„ã€‚ ä¾‹å¦‚ï¼Œç ”ç©¶äººå‘˜å‘æ˜äº†ä¸“é—¨ç”¨äºå¤„ç†å›¾åƒã€æ–‡æœ¬ã€åºåˆ—æ•°æ®å’Œæ‰§è¡ŒåŠ¨æ€è§„åˆ’çš„å±‚ã€‚ æœªæ¥ï¼Œä½ ä¼šé‡åˆ°æˆ–è¦è‡ªå·±å‘æ˜ä¸€ä¸ªç°åœ¨åœ¨æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­è¿˜ä¸å­˜åœ¨çš„å±‚ã€‚ åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œä½ å¿…é¡»æ„å»ºè‡ªå®šä¹‰å±‚ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å‘ä½ å±•ç¤ºå¦‚ä½•æ„å»ºã€‚

### ä¸å¸¦å‚æ•°çš„å±‚

```python
class CenteredLayer(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, X):
        return X - X.mean()

layer = CenteredLayer()
layer(torch.FloatTensor([1, 2, 3, 4, 5]))
# Out: tensor([-2., -1.,  0.,  1.,  2.])

net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())

Y = net(torch.rand(4, 8))
Y.mean()
```

### å¸¦å‚æ•°çš„å±‚

> nn.Parameter(tensor, required_grad=True) #æŠŠä¼ å…¥å¼ é‡å½“ä½œæ¨¡å—å‚æ•°ï¼Œå¯ä»¥å¯¹å…¶æ±‚å¯¼çš„

```python
# å®šä¹‰ä¸€ä¸ªçº¿æ€§å±‚
class MyLinear(nn.Module):
    def __init__(self, in_units, units):
        super().__init__()
        self.weight = nn.Parameter(torch.randn(in_units, units))
        self.bias = nn.Parameter(torch.randn(units,))
        #ç†è®ºä¸Štorch.randn(units,)ä¸torch.randn(units)æ²¡æœ‰åŒºåˆ«
        #é€—å·åçœç•¥è¡¨ç¤ºç»´åº¦åªæœ‰1
        #å¦‚æœæ˜¯randn(2, 1)ï¼Œå°±æ˜¯ä¸€ä¸ªäºŒç»´å¼ é‡äº†ã€‚

    def forward(self, X):
        linear = torch.matmul(X, self.weight.dataï¼‰ + self.bias.data
        return F.relu(linear)

dense = MyLinear(5, 3)
dense.weight
```

- ä½¿ç”¨è‡ªå®šä¹‰å±‚è¿›è¡Œæ­£å‘ä¼ æ’­è®¡ç®—

```python
linear(torch.rand(2, 5))
# Out: tensor([[0.0000, 0.3813, 1.3363],
#       [0.0000, 0.2262, 1.3676]])
```

- ä½¿ç”¨è‡ªå®šä¹‰å±‚æ„å»ºæ¨¡å‹

```python
net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))
net(torch.rand(2, 64))
# Out: tensor([[10.6365],
#       [17.6410]])
```

## è¯»å†™æ–‡ä»¶

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•å¤„ç†æ•°æ®ï¼Œä»¥åŠå¦‚ä½•æ„å»ºã€è®­ç»ƒå’Œæµ‹è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ç„¶è€Œï¼Œæœ‰æ—¶æˆ‘ä»¬å¸Œæœ›ä¿å­˜è®­ç»ƒçš„æ¨¡å‹ï¼Œä»¥å¤‡å°†æ¥åœ¨å„ç§ç¯å¢ƒä¸­ä½¿ç”¨ï¼ˆæ¯”å¦‚åœ¨éƒ¨ç½²ä¸­è¿›è¡Œé¢„æµ‹ï¼‰ã€‚æ­¤å¤–ï¼Œå½“è¿è¡Œä¸€ä¸ªè€—æ—¶è¾ƒé•¿çš„è®­ç»ƒè¿‡ç¨‹æ—¶ï¼Œæœ€ä½³çš„åšæ³•æ˜¯å®šæœŸä¿å­˜ä¸­é—´ç»“æœï¼Œä»¥ç¡®ä¿åœ¨æœåŠ¡å™¨ç”µæºè¢«ä¸å°å¿ƒæ–­æ‰æ—¶ï¼Œæˆ‘ä»¬ä¸ä¼šæŸå¤±å‡ å¤©çš„è®¡ç®—ç»“æœã€‚å› æ­¤ï¼Œç°åœ¨æ˜¯æ—¶å€™å­¦ä¹ å¦‚ä½•åŠ è½½å’Œå­˜å‚¨æƒé‡å‘é‡å’Œæ•´ä¸ªæ¨¡å‹äº†ã€‚

Pytorchå­˜å‚¨æœ¬è´¨ä¸Šä½¿ç”¨çš„æ˜¯Pythonå®ç°çš„ **Pickleåºåˆ—åŒ–ï¼ˆSerializationï¼‰** æ“ä½œï¼Œæœ‰å…³Pickelåºåˆ—åŒ–çš„å†…å®¹å¯ä»¥å‚è€ƒğŸ‘‰[è¿™é‡Œ](https://docs.python.org/zh-cn/3/library/pickle.html)

- å­˜å‚¨ã€è¯»å–çŸ©é˜µ

> torch.save(tensor, 'filename')
>
> torch.load('filename')

```python
#å­˜å‚¨ä¸€ä¸ªtensor
X = torch.arange(4)
torch.save(X, 'x-file')

X2 = torch.load('x-file')
X2
```

```python
#å­˜å‚¨é«˜ç»´åº¦
y = torch.zeros(4)
torch.save([X, y], 'x-files')
x2, y2 = torch.load('x-files')
(x2, y2)
```

```python
#å­˜å‚¨å­—å…¸
mydict = {'x': X, 'y': y}
torch.save(mydict, 'mydict')
mydict2 = torch.load('mydict')
mydict2
```

- å­˜å‚¨æ¨¡å‹å‚æ•°

> torch.save(net.state_dict(),'net.params')
>
> net.load_state_dict(torch.load('net.params'))

```python
class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.hidden = nn.Linear(20, 256)
        self.output = nn.Linear(256, 10)

    def forward(self, X):
        return self.output(F.relu(self.hidden(X)))

net = MLP()
X = torch.randn(size=(2, 20))
Y = net(X)

torch.save(net.state_dict(), 'mlp.params') #å­˜å‚¨çš„å®é™…æ˜¯æ¨¡å‹å‚æ•°è€Œéæ¨¡å‹æœ¬èº«

clone = MLP()
#å…ˆå…‹éš†åŸæ¨¡å‹æœ¬èº«
clone.load_state_dict(torch.load('mlp.params'))
#å†è½½å…¥å¹¶é‡å†™å…‹éš†çš„æ¨¡å‹
clone.eval()
#eval()è®¾ç½®ä¸€ä¸ªæ¨¡å‹å‚æ•°ä¸ºä¸å¯å¯¼ï¼Œç”¨äºé¢„æµ‹æ¨ç†
Y_clone = clone(X)
Y_clone == Y   
# Out: True
```

> å¦‚è¦å­˜å‚¨æ¨¡å‹ç»“æ„å®šä¹‰ï¼Œéœ€è¦é€šè¿‡**TorchScript**å­˜å‚¨ï¼Œè¯¦è§åº•éƒ¨å‚è€ƒæ–‡æ¡£ã€‚

## Pytorch æ¨¡å—å‚è€ƒæ–‡æ¡£

- `torch.nn.Module`Pytorch æ‰€æœ‰ç½‘ç»œçš„åŸºç±» Module ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#containers) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)
- `torch.nn..Parameter`Pytorch ç¥ç»ç½‘ç»œå‚æ•°ç±» ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#parameters) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter)
- `torch.nn.init`Pytorch ç¥ç»ç½‘ç»œå‚æ•°å„ç§åˆå§‹åŒ–æ–¹æ³• ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/nn_init/) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/nn.init.html)
- `torch.save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)`Pytorch å¯¹è±¡å­˜å‚¨å‡½æ•° ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch/) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/generated/torch.save.html#torch.save)
- `torch.nn.load`Pytorch å¯¹è±¡è½½å…¥å‡½æ•° ğŸ§[ä¸­æ–‡](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch/) | [å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load)
- `TorchScript` æ˜¯ PyTorch æ¨¡å‹(`nn.Module`çš„å­ç±»ï¼‰çš„ä¸­é—´è¡¨ç¤ºå½¢å¼ ğŸ§[å®˜æ–¹è‹±æ–‡](https://pytorch.org/docs/stable/jit.html)

---

## Q&AğŸ¤“

**Qï¼šPytorchå®šä¹‰å¥½æ¨¡å‹åï¼Œè‹¥ä¸æŒ‡å®šåˆå§‹åŒ–ï¼Œåˆ™é»˜è®¤ä»¥ä»€ä¹ˆè§„åˆ™è¿›è¡Œåˆå§‹åŒ–ï¼Ÿ**

**ğŸ™‹â€â™‚ï¸**ï¼šé€šè¿‡æŸ¥çœ‹Pytorchæºç ï¼Œå‘ç°ä¾‹å¦‚`nn.Linear`å’Œ`nn.ConvNd`æ˜¯ä½¿ç”¨çš„æ˜¯`init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')`åˆå§‹åŒ–ï¼Œä¸€ç§åœ¨è®ºæ–‡Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification - He, K. et al. (2015)æå‡ºçš„ç±»ä¼¼Xvairçš„åˆå§‹åŒ–æ–¹æ³•ã€‚

**Qï¼šå¦‚æœè‡ªå®šä¹‰æ¿€æ´»å‡½æ•°æ˜¯ä¸å¯å¯¼çš„ï¼ŒPytorchæ˜¯å¦å¯ä»¥è‡ªåŠ¨æ±‚å¯¼ï¼Œè¿˜æ˜¯è¯´è¦äº‹å…ˆå®šä¹‰å¯¼æ•°ï¼Ÿ**

**ğŸ™‹â€â™‚ï¸**ï¼šåœ¨æ•°å€¼è®¡ç®—é¢†åŸŸï¼Œå‡ ä¹ä¸å­˜åœ¨å¤„å¤„ä¸å¯å¯¼çš„å‡½æ•°ï¼Œå®é™…åº”ç”¨ä¸­ä¸ç”¨è€ƒè™‘æ­¤ç§æƒ…å†µï¼Œæ·±åº¦å­¦ä¹ æ¡†æ¶å‡å¯è§£å†³ã€‚

**ç•ªå¤–**ï¼šç›®å‰å·²çŸ¥çš„ä¸€ä¸ªâ€œå¤„å¤„è¿ç»­ã€å¤„å¤„ä¸å¯å¯¼â€çš„å¥‡æ€ªå‡½æ•°å«â€œ**é­å°”æ–¯ç‰¹æ‹‰æ–¯å‡½æ•°ï¼ˆWeierstrass functionï¼‰**â€ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š

$$
f(x)=\sum_{n=0}^\infty a^n cos(b^n\pi x) \qquad \text{where $0<a<1,bä¸ºå¥‡æ•°,ab>1+{3\over 2}\pi$}
$$

> ä¸‹å›¾ä¸ºé­å°”æ–¯ç‰¹æ‹‰æ–¯å‡½æ•°åœ¨åŒºé—´ [âˆ’2ï¼Œ 2] ä¸Šçš„å›¾ã€‚åƒå…¶ä»–åˆ†å½¢ä¸€æ ·ï¼Œè¿™ä¸ªå‡½æ•°è¡¨ç°å‡ºè‡ªç›¸ä¼¼æ€§ï¼šæ¯ä¸ªç¼©æ”¾ï¼ˆçº¢è‰²åœ†åœˆï¼‰éƒ½ä¸å…¨å±€å›¾ç›¸ä¼¼ã€‚

![WeierstrassFunction](Images/WeierstrassFunction.svg)

> ä¸‹å›¾å±•ç¤ºWeierstrass functionå½“bä»0.1å¢å¤§åˆ°5æ—¶å‡½æ•°çš„å›¾å½¢å˜åŒ–

![Weierstrass_Animation](Images/Weierstrass_Animation.gif)

è¿™ä¸ªç¥å¥‡çš„å‡½æ•°æ˜¯ç”±åä¹ä¸–çºªçš„å¾·å›½æ•°å­¦å®¶å¡å°”Â·é­å°”æ–½ç‰¹æ‹‰æ–¯ï¼ˆKarl Theodor Wilhelm Weierstrass ; 1815â€“1897ï¼‰æå‡ºçš„ã€‚

![Weierstrass](Images/Weierstrass.jpg)

è¿™åœ¨å½“æ—¶æ•°å­¦ç•Œå¼•èµ·ä¸å°çš„è½°åŠ¨ï¼ŒåŠ¨æ‘‡äº†å½“æ—¶â€œåªè¦æ˜¯è¿ç»­å‡½æ•°æ€»å¯å¯¼â€çš„è§‚ç‚¹ï¼Œä¹Ÿæ¨åŠ¨äº†æ•°å­¦çš„å‘å±•ã€‚æ ¹æ®ä¸Šå›¾å¯çœ‹å‡ºï¼ŒWeierstrass functionæ˜¯ä¸€ä¸ªâ€œåˆ†å½¢â€å‡½æ•°ï¼Œå®ƒä¹Ÿæ¨åŠ¨äº†åˆ†å½¢é¢†åŸŸçš„å‘å±•ã€‚
