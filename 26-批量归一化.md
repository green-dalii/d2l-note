# 26 - æ‰¹é‡å½’ä¸€åŒ–

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‡

[![Bilibil](https://i2.hdslb.com/bfs/archive/c52c4d88d8fe65f6d2ffac27b8ce6cb02dcdcacc.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1X44y1r77r)

## ç½‘ç»œè¶Šæ·±äº§ç”Ÿçš„é—®é¢˜

- åå‘ä¼ æ’­ï¼ŒæŸå¤±çš„æ¢¯åº¦ä»è¾“å‡ºå±‚å‘åä¼ ï¼Œé è¿‘è¾“å‡ºçš„å±‚è®­ç»ƒè¾ƒå¿«
  - æ¢¯åº¦è¶Šå¾€ä¸‹ä¼ é€’è¶Šå°ï¼ˆå°æ•°ç›¸ä¹˜ï¼‰
- æ•°æ®åœ¨æœ€åº•éƒ¨
  - é è¿‘æ•°æ®çš„åº•éƒ¨å±‚è®­ç»ƒè¾ƒæ…¢
  - åº•éƒ¨å±‚ä¸€å˜åŒ–ï¼Œæ‰€æœ‰éƒ½å¾—è·Ÿç€å˜ï¼Œç›¸å½“äºä½å±‚ç‰¹å¾æ”¹å˜ï¼Œä¸æ–­æŠ½è±¡å¾—åˆ°çš„é«˜å±‚ç‰¹å¾ä¹Ÿä¼šéšä¹‹æ”¹å˜
  - é¡¶éƒ¨çš„é‚£äº›å±‚éœ€è¦é‡æ–°å­¦ä¹ å¤šæ¬¡
  - å¯¼è‡´æ”¶æ•›å˜æ…¢

## å¦‚ä½•è§£å†³

å¯¹äºå…¸å‹çš„å¤šå±‚æ„ŸçŸ¥æœºæˆ–å·ç§¯ç¥ç»ç½‘ç»œã€‚å½“æˆ‘ä»¬è®­ç»ƒæ—¶ï¼Œä¸­é—´å±‚ä¸­çš„å˜é‡ï¼ˆä¾‹å¦‚ï¼Œå¤šå±‚æ„ŸçŸ¥æœºä¸­çš„ä»¿å°„å˜æ¢è¾“å‡ºï¼‰å¯èƒ½å…·æœ‰æ›´å¹¿çš„å˜åŒ–èŒƒå›´ï¼šä¸è®ºæ˜¯æ²¿ç€ä»è¾“å…¥åˆ°è¾“å‡ºçš„å±‚ï¼Œè·¨åŒä¸€å±‚ä¸­çš„å•å…ƒï¼Œæˆ–æ˜¯éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæ¨¡å‹å‚æ•°çš„éšç€è®­ç»ƒæ›´æ–°å˜å¹»è«æµ‹ã€‚ æ‰¹é‡è§„èŒƒåŒ–çš„å‘æ˜è€…éæ­£å¼åœ°å‡è®¾ï¼Œè¿™äº›å˜é‡åˆ†å¸ƒä¸­çš„è¿™ç§åç§»å¯èƒ½ä¼šé˜»ç¢ç½‘ç»œçš„æ”¶æ•›ã€‚ ç›´è§‚åœ°è¯´ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šçŒœæƒ³ï¼Œå¦‚æœä¸€ä¸ªå±‚çš„å¯å˜å€¼æ˜¯å¦ä¸€å±‚çš„ 100 å€ï¼Œè¿™å¯èƒ½éœ€è¦å¯¹å­¦ä¹ ç‡è¿›è¡Œè¡¥å¿è°ƒæ•´ã€‚

åŒæ—¶ï¼Œæ›´æ·±å±‚çš„ç½‘ç»œå¾ˆå¤æ‚ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆã€‚ è¿™æ„å‘³ç€æ­£åˆ™åŒ–å˜å¾—æ›´åŠ é‡è¦ã€‚

![bn](Images/Batch_Normalization.gif)

æ‰¹é‡è§„èŒƒåŒ–åº”ç”¨äºå•ä¸ªå¯é€‰å±‚ï¼ˆä¹Ÿå¯ä»¥åº”ç”¨åˆ°æ‰€æœ‰å±‚ï¼‰ï¼Œå…¶åŸç†å¦‚ä¸‹ï¼šåœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè§„èŒƒåŒ–è¾“å…¥ï¼Œå³é€šè¿‡å‡å»å…¶å‡å€¼å¹¶é™¤ä»¥å…¶æ ‡å‡†å·®ï¼Œå…¶ä¸­ä¸¤è€…å‡åŸºäºå½“å‰å°æ‰¹é‡å¤„ç†ã€‚ æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åº”ç”¨æ¯”ä¾‹ç³»æ•°å’Œæ¯”ä¾‹åç§»ã€‚ æ­£æ˜¯ç”±äºè¿™ä¸ªåŸºäºæ‰¹é‡ç»Ÿè®¡çš„æ ‡å‡†åŒ–ï¼Œæ‰æœ‰äº†æ‰¹é‡å½’ä¸€åŒ–çš„åç§°ã€‚

å›ºå®šå°æ‰¹é‡ï¼ˆåœ¨ä¸åŒå±‚è¾“å‡ºï¼‰é‡Œé¢çš„å‡å€¼å’Œæ–¹å·®ï¼š

$$
\mu_B={1 \over |B|} \sum_{i \in B} x_i \\

\sigma_B^2={1 \over |B|} \sum_{i \in B} (x_i-\mu_B)^2 + \epsilon
$$

> å…¶ä¸­$B$æŒ‡ä¸€ä¸ªæ‰¹é‡ Batchï¼Œ$\epsilon$ä¸ºä¸€ä¸ªå¾ˆå°çš„æ•°ï¼Œé˜²æ­¢æ–¹å·®ä¸ºé›¶ï¼Œåœ¨ä¸‹æ–‡æ— æ³•è¿›è¡Œé™¤é›¶è¿ç®—

![s](https://theaisummer.com/static/d42512016d9b99eabb69a61bb295cd50/2e9f9/normalization.png)

ç„¶åå†é€šè¿‡ä¸‹å¼å¯¹æ¯ä¸ªæ‰¹é‡åœ¨ä¸åŒå±‚çš„è¾“å‡ºå€¼æ•°æ®åšé¢å¤–çš„è°ƒæ•´ï¼Œå°†æ¯å±‚è¾“å‡ºå€¼å›ºå®šä¸ºå‡å€¼ä¸º${\beta}$ã€æ–¹å·®ä¸º${\gamma}$çš„åˆ†å¸ƒï¼š

$$
x_{i+1}=\gamma{x_i-\mu_B \over \sigma_B} + \beta
$$

- æ¯”ä¾‹${\gamma}$å’Œåç§»ç³»æ•°${\beta}$æ˜¯å­¦ä¹ å‡ºæ¥çš„
- æ‰¹é‡å½’ä¸€åŒ–æ˜¯ä¸€ä¸ªçº¿æ€§å˜æ¢
- ä½œç”¨ä½ç½®
  - å…¨è¿æ¥å±‚å’Œå·ç§¯å±‚è¾“å‡ºä¸Šï¼Œæ¿€æ´»å‡½æ•°ä¹‹å‰
    > å› ä¸ºä¸€èˆ¬æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ reluï¼‰ ä¼šå°†æ•°æ®æ˜ å°„ä¸ºæ­£æ•°ï¼Œæ‰€ä»¥ä¸èƒ½å†å¸¦å›æ­£è´Ÿå„å¼‚çš„çŠ¶æ€
  - å…¨è¿æ¥å±‚å’Œå·ç§¯å±‚è¾“å…¥ä¸Š
- å¯¹äºå…¨è¿æ¥å±‚ï¼Œä½œç”¨åœ¨**ç‰¹å¾ç»´**ï¼ˆç‹¬ç«‹æ”¹å˜æ¯ä¸ªç‰¹å¾çš„åˆ†å¸ƒï¼‰
- å¯¹äºå·ç§¯å±‚ï¼Œä½œç”¨äº**é€šé“ç»´**ï¼ˆå³ä¸€ä¸ªæ»‘åŠ¨çª—å£é‡Œåƒç´ çš„ç‰¹å¾ï¼‰
- åªæœ‰**æ‰¹é‡è¶³å¤Ÿå¤§**æ—¶æ‰¹é‡å½’ä¸€åŒ–æ•ˆæœæ‰èƒ½æœ‰æ•ˆä¸”ç¨³å®šï¼ˆæ¯”å¦‚æç«¯æƒ…å†µ batch_size=1 æ—¶ï¼Œnormalization åéšè—å±‚è¾“å‡ºå°†ä¸ºé›¶ï¼‰ï¼Œæ‰¹é‡å¤§å°è¶…å‚æ•°çš„é€‰æ‹©ç”šè‡³æ¯”æ²¡æœ‰æ‰¹é‡å½’ä¸€åŒ–æ›´é‡è¦

## æ‰¹é‡å½’ä¸€åŒ–çš„ä½œç”¨

- å¯ä»¥**åŠ é€Ÿæ”¶æ•›å¹¶è®©è®­ç»ƒæ›´ç¨³å®š**ï¼ˆå¯ä»¥ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡ï¼Œè€Œé˜²æ­¢å­¦ä¹ ç‡è¿‡å¤§é€ æˆçš„æ— æ³•æ”¶æ•›æŠ–åŠ¨æˆ–è€…é è¿‘è¾“å‡ºå±‚æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ï¼‰
- ä¸€èˆ¬ä¸æ”¹å˜æ¨¡å‹çš„ç²¾åº¦

![bn](Images/batch_norm3.jpg)

> ä¸Šå›¾ä»¥ä½¿ç”¨ VGG ç½‘ç»œä¸ºä¾‹å±•ç¤º BatchNorm çš„æ•ˆæœï¼Œæ©™è‰²ä»£è¡¨æ ‡å‡†ç»“æ„ï¼Œè“è‰²ä»£è¡¨å¢åŠ äº† BatchNorm çš„å¯¹æ¯”ç»“æ„ï¼Œå“çº¢è‰²ä»£è¡¨å¢åŠ äº†â€œNoisy BatchNormâ€çš„å¯¹æ¯”ç»“æ„ã€‚ä»å·¦ä¾§å›¾å¯çœ‹å‡ºåŠ å…¥ BatchNorm åï¼Œè®­ç»ƒç²¾è¯»æ”¶æ•›å¾—æ›´å¿«ï¼ŒåŒæ—¶æŠ–åŠ¨æ›´å°ï¼ˆä½†ä¸æ”¹å˜æœ€ç»ˆçš„ç²¾åº¦ï¼‰ï¼›ä»å³ä¾§å›¾å¯çœ‹å‡ºåŠ å…¥ BatchNorm åï¼Œå„å±‚è¾“å‡ºåˆ†å¸ƒæ›´åŠ â€œå‡è¡¡â€ã€‚

![bn2](Images/batch_norm.jpg)

> é€šè¿‡ä¸Šå›¾å¯¹æ¯”å®éªŒï¼Œå¯ä»¥çœ‹å‡ºä½¿ç”¨ BN åï¼ŒæŸå¤±ä¸‹é™æ›´å¿«æ›´å¹³ç¨³ï¼Œæ¢¯åº¦æŠ–åŠ¨æ›´ç¨³å®šã€‚

## æ‰¹é‡å½’ä¸€åŒ–ä½œç”¨çš„åŸç†

- æœ€åˆçš„è®ºæ–‡è¡¨ç¤ºå¯ä»¥å‡å°‘å†…éƒ¨åå˜é‡è½¬ç§»
- åç»­è®ºæ–‡æŒ‡å‡º batch normalization ç›¸å½“äºåœ¨å°æ‰¹é‡é‡Œ**å¢åŠ å™ªéŸ³**$\mu,\sigma$ï¼Œå¯¹æ•°æ®è¿›è¡Œäº†éšæœºåç§»å’Œç¼©æ”¾ï¼ˆç›®å‰è¿˜æ²¡æœ‰ä¸€ä¸ªç»Ÿä¸€çš„ç»“è®ºï¼‰
- **æ²¡å¿…è¦å’Œä¸¢å¼ƒæ³•æ··åˆä½¿ç”¨**ï¼ˆåœ¨[ç•ªå¤– 04-Kaggle ç«èµ›å®è·µç»éªŒ](ç•ªå¤–ç¯‡/ç•ªå¤–04-Kaggleç«èµ›å®è·µç»éªŒ.md)ä¸€ç¯‡ä¸­æœ‰ç›¸å…³å®è·µè¯æ˜ï¼‰

## BatchNormã€LayerNormã€InstanceNormã€GroupNorm åŒºåˆ«

ç›®å‰å¸¸ç”¨çš„æœ‰**BatchNormã€LayerNormã€InstanceNormã€GroupNorm**å››ç§å½’ä¸€åŒ–æ–¹æ³•ã€‚

![norm](Images/normalization.png)

> ä¸Šå›¾ä¸­æ¯ä¸ªç«‹æ–¹ä½“ä»£è¡¨ä¸€ä¸ª Batch çš„æ•°æ®ï¼Œå…¶ä¸­ C ä»£è¡¨ Channel é€šé“ç»´ï¼ŒN ä»£è¡¨ batch ç»´ï¼Œ(H,W)ä»£è¡¨ä¸€ä¸ªç©ºé—´ç»´ï¼ˆä¾‹å¦‚äºŒç»´å›¾åƒï¼‰

> è“è‰²ä»£è¡¨æ­£åˆ™åŒ–çš„ä½œç”¨èŒƒå›´ï¼ŒBatchNorm ä½œç”¨äºæ¯ä¸ª Channal ç»´ï¼›LayerNorm ä½œç”¨äºä¸€ä¸ª batch ä¸­ä¸€ä¸ªæ ·æœ¬ï¼ˆå¦‚ä¸€å¼ å›¾çš„æ‰€æœ‰é€šé“ï¼‰ï¼›InstanceNorm ä½œç”¨äºä¸€ä¸ªæ ·æœ¬çš„ä¸€ä¸ªé€šé“ï¼›GroupNorm ä½œç”¨äºä¸€ä¸ªæ ·æœ¬çš„å¤šä¸ªé€šé“

- **BatchNorm**ï¼š æ˜¯åœ¨ batch ä¸Šï¼Œå¤šç”¨äº CNNï¼Œå¯¹å° batchsize æ•ˆæœä¸å¥½ï¼›
- **LayerNorm**ï¼š åœ¨é€šé“æ–¹å‘ä¸Šï¼Œä¸»è¦å¯¹ RNN ä½œç”¨æ˜æ˜¾ï¼Œç°å¤šç”¨äº Transformerï¼Œå¯å‚è€ƒç¬”è®° ğŸ‘‰[56-Transformer](56-Transformer.md)ï¼›
- **InstanceNorm**ï¼š åœ¨å›¾åƒåƒç´ ä¸Šï¼Œå¤šç”¨åœ¨é£æ ¼åŒ–è¿ç§»ï¼›
- **GroupNorm**ï¼š å°† channel åˆ†ç»„ï¼Œç„¶åå†åšå½’ä¸€åŒ–, åœ¨ batchsize<16 çš„æ—¶å€™, å¯ä»¥ä½¿ç”¨è¿™ç§å½’ä¸€åŒ–ã€‚

![graph-normalization-methods](Images/graph-normalization-methods.png)

> ä¸Šå›¾å±•ç¤ºäº†å„ç§ Normalization çš„è®ºæ–‡ä½¿ç”¨ç‡ï¼Œå¯çœ‹å‡ºéšç€ Transformer åŠå…¶å˜ç§çš„å¹¿æ³›åº”ç”¨ï¼ŒLayerNorm ä½¿ç”¨ç‡é€å¹´å¢é«˜ï¼›ä¸»æµæ–¹æ³•è¿˜æ˜¯ BatchNorm ä¸ LayerNorm

![Results-normalization](Images/Results-normalization-imagenet-resnet50.png)

> ä¸Šå›¾å±•ç¤ºäº†åœ¨ç›¸åŒ ResNet-50 ç½‘ç»œæ¶æ„ä¸‹ï¼Œä¸åŒå½’ä¸€åŒ–æ–¹æ³•çš„éªŒè¯è¯¯å·®æ¯”è¾ƒå›¾ï¼ˆbatch size=64 imagesï¼‰

å…·ä½“å…³äºå››ç§å½’ä¸€åŒ–çš„ç»¼è¿°ï¼Œå¯ä»¥å‚è€ƒ AISummer è¿™ç¯‡æ–‡ç«  ğŸ‘‰[[1]](https://theaisummer.com/normalization/)å’Œè¿™ç¯‡[çŸ¥ä¹](https://zhuanlan.zhihu.com/p/395855181)

## å¡å°”æ›¼æ»¤æ³¢[[2]](https://wiwiki.kfd.me/wiki/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2)

åœ¨æµ‹è¯•çš„æ—¶å€™ï¼Œæ ·æœ¬ä¸€ä¸ªä¸€ä¸ªè¿›å…¥ç½‘ç»œï¼Œæ²¡æœ‰åŒºåŸŸå‡å€¼ã€æ–¹å·®å¯æ±‚ã€‚å¯ä»¥ç”¨æµ‹è¯•é›†å¾—åˆ°å‡å€¼ã€æ–¹å·®ä½œä¸ºåˆå€¼ã€‚

å…¨å±€æœŸæœ›çš„æ›´æ–°è¦å€ŸåŠ©**Karlman æ»¤æ³¢**ï¼Œå¯ç‚¹å‡»ä¸‹å›¾å‚è€ƒ Matlab å®˜æ–¹åˆ¶ä½œçš„ä¼˜ç§€ç§‘æ™®è§†é¢‘ ğŸ‘‡

[![karlman](https://i0.hdslb.com/bfs/archive/b16e54070ffd2768a763a768463311b085de66d3.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1V5411V72J)

å¯¹åŒä¸€ä¸ªç›®æ ‡ï¼Œå¤šæ¬¡æµ‹é‡å€¼$z_1,z_2,z_3,...,z_k$ï¼Œå…¶æœŸæœ›$x_1, x_2,...,x_k$

$$
\begin{aligned}
\hat x_k&={1\over k}(z_1+z_2+z_3+...+z_{k-1}+z_k)\\
&={1\over k}(z_1+z_2+z_3+...+z_{k-1})+{1\over k}z_k\\
&={1\over k}{k-1\over k-1}(z_1+z_2+z_3+...+z_{k-1})+{1\over k}z_k\\
&={k-1\over k}\hat x_{k-1}+{1\over k}z_k\\
&=\hat x_{k-1}-{1\over k}\hat x_{k-1}+{1\over k}z_k\\
&=\hat x_{k-1}+{1\over k}(z_k-\hat x_{k-1})
\end{aligned}
$$

éšç€$k$çš„å¢åŠ ï¼Œæµ‹é‡å€¼$z_k$å°±ä¸å†é‡è¦

$$\hat x_k=\hat x_{k-1}+k_k(z_k-\hat x_{k-1})$$

$k_k$: Karlman Gain

å½“å‰ä¼°è®¡å€¼=ä¸Šä¸€æ¬¡çš„ä¼°è®¡å€¼+ç³»æ•° Ã—(å½“å‰æµ‹é‡å€¼-ä¸Šä¸€æ¬¡çš„ä¼°è®¡å€¼)

- åªä¸ä¸Šä¸€æ¬¡çš„ä¼°è®¡å€¼æœ‰å…³ï¼Œé€’å½’ç®—æ³•ã€‚

$$k_k={e_e\over e_e+e_m}$$

> ä¼°è®¡è¯¯å·®ï¼š$e_e$ï¼Œæµ‹é‡è¯¯å·®ï¼š$e_m$

- $e_e\gt\gt e_m: k_k\rightarrow1\quad \hat x_k=\hat x_{k-1}+z_k-\hat x_{k-1}=z_k$ï¼Œå½“ä¼°è®¡è¯¯å·®è¿œå¤§äºæµ‹é‡è¯¯å·®æ—¶ï¼Œä»¥æµ‹é‡å€¼ä¸ºå‡†
- $e_e\lt\lt e_m: k_k\rightarrow0\quad \hat x_k=\hat x_{k-1}$å½“ä¼°è®¡è¯¯å·®è¿œå°äºæµ‹é‡è¯¯å·®æ—¶ï¼Œä»¥ä¼°è®¡å€¼ä¸ºå‡†

## ä»£ç å®ç°

- å®šä¹‰ batch_norm è¿ç®—

```python
import torch
from torch import nn
from d2l import torch as d2l

def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):
    # moving_mean/varå…¨å±€çš„æœŸæœ›å’Œæ–¹å·®ï¼Œè¿‘ä¼¼äºæ•´ä¸ªæ•°æ®é›†ä¸Š
    # epsï¼šå¾ˆå°çš„å›ºå®šå€¼ï¼Œé¿å…é™¤é›¶ï¼Œå¾ˆé‡è¦
    # momentumï¼šç”¨äºæ›´æ–°movingçš„åŠ¨é‡ï¼Œé€šå¸¸å–å›ºå®šå€¼
    if not torch.is_grad_enabled(): #åšinferenceè€Œétrainï¼Œæ‰€ä»¥ä¸æ±‚æ¢¯åº¦
        # ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†çš„å‡å€¼å’Œæ–¹å·®è®¡ç®—
        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)
    else:
        # X.shapeè¾“å…¥è¦ä¹ˆä¸º2ï¼ˆä»£è¡¨å…¨è¿æ¥å±‚ï¼‰è¦ä¹ˆä¸º4ï¼ˆ2Då·ç§¯å±‚ï¼Œ(batch_samples,channals,w,h)ï¼‰
        assert len(X.shape) in (2, 4)
        # å½“ä¸ºå…¨è¿æ¥å±‚æ—¶
        if len(X.shape) == 2:
        #æŒ‰ç‰¹å¾æ±‚å‡å€¼å’Œæ–¹å·®
            mean = X.mean(dim=0)    # æŒ‰è¡Œæ±‚å‡å€¼ï¼Œå°†ä¸åŒè¡Œæ±‚å‡å€¼åå‹ç¼©åˆ°ä¸€è¡Œï¼Œ
            var = ((X - mean)**2).mean(dim=0)
        # å½“ä¸º2Då·ç§¯å±‚æ—¶
        else:
            # å¯¹æ¯ä¸€ä¸ªé€šé“çš„å…¨éƒ¨å…ƒç´ æ±‚å‡å€¼æ–¹å·®ï¼Œå¾—åˆ°ä¸€ä¸ª(1,channal_num,1,1)çš„çŸ©é˜µ
            mean = X.mean(dim=(0, 2, 3), keepdim=True)
            var = ((X - mean)**2).mean(dim=(0, 2, 3), keepdim=True)

        # å¯¹Xæ¯ä¸ªå…ƒç´ è¿›è¡Œå½’ä¸€åŒ–
        X_hat = (X - mean) / torch.sqrt(var + eps)
        #
        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean
        moving_var = momentum * moving_var + (1.0 - momentum) * var
    Y = gamma * X_hat + beta
    return Y, moving_mean.data, moving_var.data
    #å¾—åˆ°normalizeè¿‡çš„Yå’Œæ›´æ–°è¿‡çš„moving
```

- å®šä¹‰ BatchNorm å—

```python
class BatchNorm(nn.Module):
    def __init__(self, num_features, num_dims):
        super().__init__()
        if num_dims == 2:   #å…¨è¿æ¥å±‚
            shape = (1, num_features)

        else:   #2Då·ç§¯å±‚
            shape = (1, num_features, 1, 1)
        self.gamma = nn.Parameter(torch.ones(shape))
        self.beta = nn.Parameter(torch.zeros(shape))
        #gammaå’Œbetaæ˜¯éœ€è¦å‚æ•°å­¦ä¹ çš„å‚æ•°ï¼Œä½¿ç”¨Parameterå­˜å‚¨æ¢¯åº¦
        self.moving_mean = torch.zeros(shape)
        self.moving_var = torch.ones(shape)

    def forward(self, X):
        # æ£€æµ‹moving_mean/varæ‰€åœ¨è®¾å¤‡
        if self.moving_mean.device != X.device:
            self.moving_mean = self.moving_mean.to(X.device)
            self.moving_var = self.moving_var.to(X.device)

        Y, self.moving_mean, self.moving_var = batch_norm(
            X, self.gamma, self.beta, self.moving_mean,
            self.moving_var, eps=1e-5, momentum=0.9)
        return Y
    # ç›¸å½“äºBatchnormå®šä¹‰äº†å¹¶åˆå§‹åŒ–ä¸¤ä¸ªè¶…å‚æ•°gammaå’Œbeta
    # åˆå§‹åŒ–äº†moving_mean & var

```

- åµŒå¥—è¿›ä¸€ä¸ª LeNet ç¥ç»ç½‘ç»œ

```python
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5), BatchNorm(6, num_dims=4),
    nn.Sigmoid(), nn.MaxPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), BatchNorm(16, num_dims=4),
    nn.Sigmoid(), nn.MaxPool2d(kernel_size=2, stride=2),
    nn.Flatten(), nn.Linear(16 * 4 * 4, 120),
    BatchNorm(120, num_dims=2), nn.Sigmoid(),
    nn.Linear(120, 84), BatchNorm(84, num_dims=2),
    nn.Sigmoid(), nn.Linear(84, 10))
#å¯¹çº¿æ€§å±‚åªæœ‰(256ï¼Œ16*4*4)çŸ©é˜µçš„norm
```

- è®­ç»ƒ

```python
lr, num_epochs, batch_size = 1.0, 10, 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```

```python
net[1].gamma.reshape((-1,)), net[1].beta.reshape((-1,))
#è‡ªåŠ¨è®¡ç®—è¡Œï¼Œæ‰€ä»¥é»˜è®¤å¡«å……æ‰€æœ‰åˆ—
```

- ç®€æ˜å®ç°

```python
#æ³¨æ„1dä¸2dçš„åŒºåˆ«ã€‚
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6),
    nn.Sigmoid(), nn.MaxPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16),
    nn.Sigmoid(), nn.MaxPool2d(kernel_size=2, stride=2),
    nn.Flatten(), nn.Linear(16 * 4 * 4, 120),
    nn.BatchNorm1d(120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.BatchNorm1d(84),
    nn.Sigmoid(), nn.Linear(84, 10))
```

```python
nn.Flatten()
#é»˜è®¤ä»ç¬¬1ä¸ªç»´åº¦ï¼ˆè€Œä¸æ˜¯ç¬¬0ç»´ï¼‰å¼€å§‹æ‹‰å¹³ç›´è‡³æœ€åä¸€ä¸ªç»´åº¦
#æ‰€ä»¥Flatten()ä¸€ä¸ªäºŒç»´çŸ©é˜µä¸å‘ç”Ÿä»»ä½•å½¢çŠ¶å˜åŒ–ã€‚
```

## å‚è€ƒèµ„æ–™

[1][in-layer normalization techniques for training very deep neural networks](https://theaisummer.com/normalization/)

[2][å¡å°”æ›¼æ»¤æ³¢-ç»´åŸºç™¾ç§‘](https://wiwiki.kfd.me/wiki/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2)
