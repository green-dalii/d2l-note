# 08 - çº¿æ€§å›å½’

---

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰[Bilibil](https://www.bilibili.com/video/BV1PX4y1g7KC)

## 1.å›å½’ï¼ˆRegressionï¼‰ 
åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸï¼Œå¤§è‡´å¯åˆ†ä¸º**å›å½’**ä¸**åˆ†ç±»**ä¸¤ç±»é—®é¢˜ã€‚

å›å½’æ˜¯æŒ‡ä¸€ç±»ä¸ºä¸€ä¸ªæˆ–å¤šä¸ªè‡ªå˜é‡ä¸å› å˜é‡ä¹‹é—´å…³ç³»å»ºæ¨¡çš„æ–¹æ³•ã€‚åœ¨è‡ªç„¶ç§‘å­¦å’Œç¤¾ä¼šç§‘å­¦é¢†åŸŸï¼Œå›å½’ç»å¸¸ç”¨æ¥è¡¨ç¤ºè¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„å…³ç³»ï¼›åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œå›å½’å¸¸ç”¨äºè§£å†³**é¢„æµ‹**é—®é¢˜ã€‚

**çº¿æ€§å›å½’**ï¼ˆLinear Regressionï¼‰æ˜¯æœ€ç®€å•çš„ä¸€ç§å›å½’æ¨¡å‹ï¼Œåœ¨å¯¹ç»“æœç²¾åº¦è¦æ±‚ä¸é«˜ã€ç°å®æƒ…å†µç›¸å¯¹ä¸å¤æ‚çš„æƒ…å†µï¼ˆå‡è®¾æ»¡è¶³çº¿æ€§å…³ç³»ï¼‰ï¼Œä½¿ç”¨çº¿æ€§å›å½’å¯ä»¥ç®€ä¾¿å¿«é€Ÿåœ°å¾—åˆ°å¯æ¥å—çš„ç»“æœã€‚

çº¿æ€§å›å½’æ¨¡å‹å¯ä»¥ç­‰ä»·çœ‹ä½œæ˜¯æ¿€æ´»å‡½æ•°ä¸ºçº¿æ€§å‡½æ•°$\sigma=wx$çš„**å•å±‚ç¥ç»ç½‘ç»œ**æ¨¡å‹ã€‚å…¶ä¸­è¾“å…¥å±‚**èŠ‚ç‚¹æ•°é‡**ç­‰äºæ•°æ®**ç‰¹å¾ä¸ªæ•°**ï¼š

![å•å±‚ç¥ç»ç½‘ç»œ](http://zh.d2l.ai/_images/singleneuron.svg)

**Ep: æˆ¿ä»·é¢„æµ‹**
- é¢„æµ‹æ¨¡å‹ï¼šè¾“å‡º = è¾“å…¥çš„åŠ æƒå’Œ + æ ‡é‡åå·®
$$
y = <{\bf{w},\bf{x}}>+b=
w_1x_1+w_2x_2+...+w_nx_n+b
$$
çº¿æ€§æ¨¡å‹å¯ä»¥çœ‹ä½œå•å±‚ç¥ç»ç½‘ç»œï¼Œè¯¥å±‚ç¥ç»å…ƒçš„æ¿€æ´»å‡½æ•°ä¸ºçº¿æ€§æ˜ å°„å‡½æ•°ã€‚
- è¡¡é‡é¢„ä¼°è´¨é‡â€”â€”é€šè¿‡æ¯”è¾ƒçœŸå®å€¼å’Œé¢„ä¼°å€¼ã€‚
å¸¸ç”¨å¹³æ–¹æŸå¤±ï¼š
$$
l(y,\hat{y})={1\over2}{(y-\hat{y})^2}
$$
ï¼ˆå…¶ä¸­ï¼Œå¼ä¸­çš„$1\over2$æ–¹ä¾¿æ±‚å¯¼ï¼‰
- è®­ç»ƒæ•°æ®â€”â€”æ”¶é›†ä¸€äº›æ•°æ®ç‚¹æ¥å†³å®šæ¨¡å‹å‚æ•°ï¼ˆæƒé‡ã€åå·®ï¼‰ï¼Œç§°ä¹‹ä¸ºè®­ç»ƒæ•°æ®ï¼Œå¤šå¤šç›Šå–„ï¼Œæ•°æ®è¿‡å°‘å®¹æ˜“é€ æˆæ¨¡å‹çš„æ¬ æ‹Ÿåˆæˆ–è¿‡æ‹Ÿåˆï¼Œå½±å“æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚

é€šå¸¸ä¸ºæ–¹ä¾¿è®¡ç®—æœºä½¿ç”¨å¹¶è¡ŒåŠ é€Ÿè¿ç®—èƒ½åŠ›ï¼Œä¼š**å‘é‡åŒ–**è®­ç»ƒæ•°æ®è¡¨ç¤ºä¸ºåˆ—å‘é‡ï¼Œç›¸å…³ç†è®ºå¯å‚è€ƒå´æ©è¾¾Deeplearningè¯¾ç¨‹ç¬¬17èŠ‚å†…å®¹ğŸ‘‰[Bilibili](https://www.bilibili.com/video/BV1FT4y1E74V?p=17)ï¼Œå½¢å¼ä¸ºï¼š
$$
{\bf{X}}=[{\bf{x_1}},{\bf{x_2}},{\bf{x_3}},...,{\bf{x_n}}]^T
$$
$$
{\bf{y}}=[y_1,y_2,y_3,...,y_n]^T
$$
- å‚æ•°å­¦ä¹ 

è®­ç»ƒæŸå¤±
$$
L({\bf{X}},{\bf{y}},{\bf{w}},b)={1\over2n}\sum_{i=1}^n(y_i-<{\bf{w}},{\bf{x_i}}>-b)^2={1\over2n}||{\bf{y}}-{\bf{X}}{\bf{w}}-b||^2
$$
æœ€å°åŒ–æŸå¤±æ¥å­¦ä¹ å‚æ•°
$$
{\bf{w}}^*,{\bf{b}}^*=arg\,\min_{{\bf{w}},b}L({\bf{X}},{\bf{y}},{\bf{w}},b)
$$
- æ˜¾å¼è§£ï¼šçº¿æ€§å›å½’é—®é¢˜å­˜åœ¨æœ€ä¼˜è§£æè§£
  
  é¦–å…ˆå°†åå·®åŠ å…¥æƒé‡ï¼Œä»¥ç®€åŒ–è¡¨ç¤ºï¼š
  $$
  {\bf{X}}\leftarrow[{\bf{X}},{\bf{1}}]
  $$
  $$
  {\bf{w}}\leftarrow\begin{bmatrix} {\bf{w}}\\ b\\ \end{bmatrix}
  $$
  $$
  l({\bf{X}},{\bf{y}},{\bf{w}})={1\over2n}||{\bf{y}}-{\bf{X}}{\bf{w}}||^2
  $$
  $$
  {\partial\over\partial{\bf{w}}}l({\bf{X}},{\bf{y}},{\bf{w}})={1\over n}({\bf{y}}-{\bf{X}}{\bf{w}})^T{\bf{X}}
  $$
  è¯¥æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°ï¼Œå…¶æœ€ä¼˜è§£æ»¡è¶³æ±‚å¯¹åº”å‚æ•°åå¯¼ä¸ºé›¶ï¼š
$$
{\partial\over\partial{\bf{w}}}l({\bf{X}},{\bf{y}},{\bf{w}})=0
$$
$$
{1\over n}({\bf{y}}-{\bf{X}}{\bf{w}})^T{\bf{X}}=0
$$
$$
{\bf{w}}^*=({\bf{X}}^T{\bf{X}})^{-1}{\bf{X}}{\bf{y}}
$$

## 2.ä¼˜åŒ–æ–¹æ³•
**1. æ¢¯åº¦ä¸‹é™**

å¦‚æœä¸€ä¸ªæ¨¡å‹æ²¡æœ‰æ˜¾å¼è§£ï¼Œå°±éœ€è¦å€ŸåŠ©æ•°å€¼æ–¹æ³•ã€‚
é¦–å…ˆå¯éšæœºåˆå§‹åŒ–ä¸€ä¸ªå‚æ•°å€¼${\bf{w_0}}$ï¼Œé‡å¤è¿­ä»£$t=1,2,3...$ï¼Œä»¤ï¼š
$${\bf{w_t}}={\bf{w_{t-1}}}-\eta{\partial\over\partial{\bf{w_{t-1}}}}l$$
å…¶ä¸­ï¼Œå­¦ä¹ ç‡ï¼ˆ$\eta$ï¼‰ï¼šæ­¥é•¿çš„è¶…å‚æ•°ï¼ˆhyperparameterï¼‰,ä¸èƒ½å¤ªå°ï¼ˆä¼šå¯¼è‡´æ”¶æ•›æ—¶é—´è¿‡æ…¢ï¼‰ä¹Ÿä¸èƒ½å¤ªå¤§ï¼ˆäº§ç”Ÿéœ‡è¡ï¼Œæ— æ³•æ”¶æ•›ï¼‰ã€‚
æ²¿**è´Ÿæ¢¯åº¦æ–¹å‘**ä¸æ–­å‡å°æŸå¤±å‡½æ•°å€¼ã€‚
1. å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™ **(SGD)**
åœ¨æ•´ä¸ªè®­ç»ƒé›†ä¸Šç®—æ¢¯åº¦å®åœ¨å¤ªè´µ
å¯ä»¥éšæœºé‡‡æ ·$b$ä¸ªæ ·æœ¬$i_1,i_2,...,i_b$æ¥è¿‘ä¼¼æŸå¤±
$${1\over b}\sum_{i\in I_b}^nl({\bf{x_i}},y_i,{\bf{w}})$$
$b$ä¸ºæ‰¹é‡å¤§å°ï¼Œå¦å¤–ä¸€ä¸ªé‡è¦çš„è¶…å‚æ•°ã€‚
æ¢¯åº¦ä¸‹é™å°±æ˜¯ä¸æ–­å»¶ç€è´Ÿæ¢¯åº¦æ–¹å‘æ›´æ–°æ±‚è§£ï¼Œä¸éœ€è¦æ±‚è§£æ˜¾å¼è§£çš„å½¢å¼ï¼Œåªè¦å¯å¯¼å³å¯ã€‚

## 3. çº¿æ€§å›å½’çš„ä»é›¶ä»£ç å®ç°
Egï¼šä»¥çº¿æ€§å™ªå£°ä¸ºä¾‹
- æ„é€ æ•°æ®é›†
å‡è®¾åˆå§‹ ${\bf{w}}=[2,-.3.4]^T$ï¼Œ$b=4.2$ï¼Œå®šä¹‰çº¿æ€§å›å½’å‡½æ•°ï¼š
$y={\bf{X}}{\bf{w}}+b+\epsilon$
ï¼Œå…¶ä¸­$\epsilon$ä¸ºæ ·æœ¬å™ªå£°
```
def synthetic_data(w, b, num_examples):
    x = torch.normal(0, 1, (num_examples, len(w)))
    ## ä»å¹³å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„æ­£æ€åˆ†å¸ƒéšæœºåˆ›é€ num_examplesä¸ªï¼ˆè¿™é‡Œæ˜¯1000ï¼‰å¼ é‡ï¼Œå…¶é•¿åº¦ä¸wç›¸åŒï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ª1000Ã—2çš„çŸ©é˜µã€‚
    y = torch.matmul(X, w) + b
    ## mutmul()æ˜¯çŸ©é˜µä¹˜æ³•ã€‚
    y += torch.normal(0, 0.01, y.shape)
    ## æ·»åŠ ä¸ªéšæœºæ‰°åŠ¨
    return X, y.reshape(-1, 1)

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)
## featuresç‰¹å¾ï¼Œè¡¨ç¤ºå·²æœ‰çš„æ•°æ®é›†ï¼Œlabelsæ˜¯çœŸå€¼ã€‚
```
- æ¯æ¬¡è¯»å–ä¸€ä¸ªå°æ‰¹é‡

```
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    ## å¾—åˆ°ä¸€ä¸ªä¸ç‰¹å¾ç­‰é•¿çš„åºåˆ—
    random.shuffle(indices)
    ## æ‰“ä¹±è¯¥åºåˆ—
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(indices[i:min(i + batch_size, num_examples])
        yield features[batch_indices], labels[batch_indices]
    ## ç¡®å®šæ‰¹æ¬¡é‡ä½œä¸ºæ­¥é•¿ï¼Œè¿™é‡Œå–10ï¼Œç”Ÿæˆå™¨æ¯è¿è¡Œä¸€æ¬¡ï¼Œå°±ä¼šåˆ›é€ å‡ºä¸€ä¸ªé•¿åº¦ä¸º10çš„å¼ é‡ã€‚

batch_size = 10

for X, y in data_iter(batch_size, features, labels):
    print(X, '\n', y)
    break
    ## break ç”¨äºä¸­æ–­ç”Ÿæˆå™¨ï¼Œè¦ä¹ˆå°±ä¼šç”Ÿæˆ100ç»„ã€‚
```

- å®šä¹‰æ¨¡å‹

```
w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)
## è®¾ç½®åˆå€¼ã€‚

def linreg(X, w, b):
    return torch.matmul(X, w) + b
## å®šä¹‰æ¨¡å‹
```

- å®šä¹‰å¹³æ–¹å·®æŸå¤±å‡½æ•°

```
def squared_loss(y_hat, y):
    return(y_hat - y.reshape(y_hat.shape)) ** 2 / 2
```

- å®šä¹‰SGDä¼˜åŒ–ç®—æ³•

```
def sgd(params, lr, batch_size):
    with torch.no_grad():
    ## æ±‚å¯¼ä¸åœ¨æ­¤å¤„ã€‚
         for param in params:
         ## ä¼ å…¥w, bçš„åˆ—è¡¨ã€‚
            param -= lr * param.grad / batch_size
            param.grad.zero_()
            ## pyTorchéœ€è¦æ‰‹åŠ¨æ¢¯åº¦æ¸…é›¶
    ## å¯¹äºåˆ—è¡¨å¯¹è±¡ï¼Œå‡½æ•°ä¸­æ”¹å˜å°±ä¼šæ”¹å˜å…¨å±€å˜é‡ï¼Œæ•…ä¸é¡»return
```

- è®­ç»ƒæ­¥éª¤
  
```
  lr = 0.03
  num_epochs = 3
  net = linreg
  loss = squared_loss
  ## å®šä¹‰è¶…å‚æ•°

  for epoch in range(num_epochs):
  ## æ‰“ä¹±ä¸€éï¼Œå‡º100ç»„ï¼Œä¸€å…±æ‰“ä¹±ä¸‰éã€‚
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)
        l.sum().backward()
        ## å‰é¢å®šä¹‰äº†b, wçš„grad_requires=True
        sgd([w, b], lr, batch_size)
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        ## æ˜¾ç¤ºæ¯éå†å®Œä¸€éåçš„æœ€ç»ˆæŸå¤±ã€‚
        print('output:')

```
## çº¿æ€§å›å½’çš„ç®€å•å®ç°

è¿™é‡Œä½¿ç”¨Pytorchå·²æœ‰çš„å¸¸ç”¨ç»„ä»¶
```
import numpy as np
import torch
from torch.utils import data
from d2l import torch as d2l

## åˆ›å»ºæ•°æ®é›†
true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = d2l.synthetic_data(true_w, true_b, 1000)

## åˆ›å»ºæ‰¹é‡
def load_array(data_arrays, batch_size, is_train=True):
    dataset = data.TensorDataset(*data_arrays)
    ## æŠŠX,yè¿æˆåˆ—è¡¨ä½œä¸ºæ•°æ®é›†
    return data.DataLoader(dataset, batch_size, shuffle=is_train)
    ## DataLoader()å‡½æ•°è¡¨ç¤ºæå–ä¸€ä¸ªæ‰¹æ¬¡ã€‚

batch_size = 10
data_iter = load_array((features, labels), batch_size)

next(iter(data_iter))


from torch import nn
net = nn.Sequential(nn.Linear(2, 1))
## Linear()çº¿æ€§å›å½’ï¼Œè¾“å…¥è¾“å‡ºçš„ç»´åº¦ã€‚Sequential()è¡¨ç¤ºList of Layers

net[0].weight.data.normal_(0, 0.01)
## è®¾ç½®æƒé‡å‚æ•°wçš„åˆå§‹å€¼ã€‚
net[0].bias.data.fill_(0)

## è°ƒå…¥æŸå¤±å‡½æ•°
loss = nn.MSELoss()

## è°ƒå…¥ä¼˜åŒ–æ–¹æ³•
trainer = torch.optim.SGD(net.parameters(), lr=0.03)
## parametersæ˜¯networké‡Œæ‰€æœ‰çš„å‚æ•°ï¼ŒåŒ…æ‹¬wå’Œbã€‚

## è®­ç»ƒ
num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X), y)
        trainer.zero_grad()
        l.backward()
        trainer.step()
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {1:f}')
```

**Q1**ï¼šæ€ä¹ˆæŠŠå›¾æ’å…¥ç¬”è®°ï¼Œå¦‚æœæ˜¯æœ¬åœ°å›¾ç‰‡æ˜¯å¦ä¼šè¢«è¿œç¨‹è°ƒç”¨ï¼Ÿ

**A**ï¼šæœ¬åœ°å›¾ç‰‡ä¹Ÿå¯ä»¥æ’å…¥ï¼Œä½†é¦–å…ˆè¦ä¿è¯å›¾ç‰‡å­˜å‚¨äºä»£ç ä»“åº“ä¸­ï¼Œå³ä¿è¯Markdownå¯ä»¥è®¿é—®å¾—åˆ°ï¼ŒMarkdownæ’å…¥å›¾ç‰‡è¯­æ³•ä¸ºï¼š

`![å›¾ç‰‡åç§°](å›¾ç‰‡èµ„æºURLåœ°å€)`

æˆ‘åœ¨ä»£ç ä»“åº“æ ¹ç›®å½•åˆ›å»ºäº†åä¸ºâ€œ**Images**â€çš„æ–‡ä»¶å¤¹ï¼ŒæŠŠéœ€è¦æ’å…¥çš„æœ¬åœ°å›¾ç‰‡å…ˆå¤åˆ¶åˆ°æ­¤æ–‡ä»¶å¤¹ä¸­ï¼Œå†åœ¨URLåœ°å€å¡«å†™ï¼š`Images/xxx.jpg`å³å¯ã€‚ä»¥ä¸‹å›¾ç‰‡ä¾¿æ˜¯å¼•ç”¨Imagesæ–‡ä»¶å¤¹ä¸­çš„`test_img.png`å›¾ç‰‡æ–‡ä»¶ğŸ‘‡

![](Images/test_img.png)
