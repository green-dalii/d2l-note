# 17 - 卷积神经网络

---

### 🎦 本节课程视频地址 👇

[![Bilibil](https://i1.hdslb.com/bfs/archive/7f53ce06c826938d646dfc7dbf010a741fa8c3cc.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1L64y1m7Nh)

## 为什么需要卷积

举个🌰，对于目前主流手机摄像头来说，至少拥有1200万像素，拍摄一张照片，大概能产生 36M 像素的图片（RGB三个通道），即使像之前章节介绍的使用一个有100个神经元的单隐藏层 MLP，输入 36M 特征，100 个神经元就有 $36M\times100=3.6B=14GB$ 参数，所以不适用。

有个游戏“Waldo 在哪里”，要求在一幅图片中找特定的对象。可以引申出两点：

- 平移不变性：分类器不因出现位置改变而改变识别标准。
- 局部性：只需要在局部寻找对象，而非要远处无关区域。

## 从全连接层到卷积

将输入和输出变形为矩阵（宽 × 高）：
将权重变形为 4-D 张量$(h, w)$到$(h', w')$

$$
h_{i,j}=\sum_{k,l}w_{i,j,k,l}x_{k,l}=\sum_{a,b}v_{i,j,a,b}x_{i+a,j+b}
$$

此处做按元素相乘的哈马达积。

$$k=i+a,\ l=j+b$$

$v$是$w$的重新索引$v_{i,j,a,b}=w_{i,j,i+a,j+b}$，也就是说把$\bf w$通过坐标变换映射到$\bf v$。

**平移不变性**

$x$的平移导致$h$的平移

$v$不应该依赖于$(i,j)$

解决方案：$v_{i,j,a,b}=v_{a,b}$

$$h_{i,j}=\sum_{a,b}v_{a,b}x_{i+a,b+j}$$

这就是 2 维$\sout{卷积}$交叉相关

**局部性**

当评估$h_{i,j}$时，我们不应该远离$x_{i,j}$的参数

解决方案：当$|a|,|b|\gt\Delta$时，使得$v_{a,b}=0$

$$h_{i,j}=\sum_{a=-\Delta}^\Delta\sum_{b=-\Delta}^\Delta v_{a,b}x_{i+a,j+b}$$

## 卷积层

![](\Images/conv-full-layer.gif)

### 二维卷积层

输入$\bf X$：$n_h\times n_w$
核$\bf W$：$k_n\times k_w$
偏差$b\in \mathbb R$
输出$\bf Y$：$(n_h-k_h+1)\times(n_w-k_w+1)$

$${\bf Y}={\bf X* \bf W}+b$$
$\bf W$和$b$是可学习的参数。

**交叉相关 vs 卷积**

二维交叉相关

$$y_{i,j}=\sum_{a=1}^h\sum_{b=1}^w w_{a,b}x_{i+a,j+b}$$

二维卷积

$$y_{i,j}=\sum_{a=1}^h\sum_{b=1}^w w_{-a,-b}x_{i+a,j+b}$$

由于对称性，在实际使用中没有区别。

**一维和三维交叉相关**

- 一维

$$y_i=\sum_{a=1}^hw_ax_{i+a}$$

文本、语言、时序序列

- 三维

$$y_{i,j,k}=\sum_{a=1}^h\sum_{b=1}^w \sum_{c=1}^dw_{a,b,c}x_{i+a,j+b,k+c}$$

视频、医学图像、气象地图

**总结**

卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出

核矩阵和偏移是可学习的参数

核矩阵的大小是超参数，就规避了输入越大权重越大的问题。

### 代码实现

**实现交叉运算**

```
import torch
from torch import nn
from d2l import torch as d2l

def corr2d(X, K):
    h, w = K.shape
    Y = torch.zeros((X.shape[0] - h +1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y
```

**自定义卷积模块**

```
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```

**借助 PyTorch 实现卷积**

```
conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)
#直接调用Conv2d,input channel=1,outputchannel=1

X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))
#增加两个维度，通道维度和批量大小维度

for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y)**2
    conv2d.zero_grad()
    l.sum().backward()
    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad
    #做梯度优化
    if (i + 1) % 2 == 0:
        print(f'batch {i+1}, loss {l.sum():.3f}')
```
