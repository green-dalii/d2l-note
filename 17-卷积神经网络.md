## 从连接到卷积

### 从问题开始

对于一张36M的图片，运用一个单隐藏层MLP，输入36M特征，100个神经元就有3.6B=14GB参数，所以不适用。

有个游戏“Waldo在哪里”，要求在一幅图片中找特定的对象。可以引申出两点：

- 平移不变性：分类器不因出现位置改变而改变识别标准。
- 局部性：只需要在局部寻找对象，而非要远处无关区域。

### 从全连接层到卷积

将输入和输出变形为矩阵（宽×高）：
将权重变形为4-D张量$(h, w)$到$(h', w')$

$$
h_{i,j}=\sum_{k,l}w_{i,j,k,l}x_{k,l}=\sum_{a,b}v_{i,j,a,b}x_{i+a,j+b}
$$

此处做按元素相乘的哈马达积。

$$k=i+a,\ l=j+b$$

$v$是$w$的重新索引$v_{i,j,a,b}=w_{i,j,i+a,j+b}$，也就是说把$\bf w$通过坐标变换映射到$\bf v$。

**平移不变性**

$x$的平移导致$h$的平移

$v$不应该依赖于$(i,j)$

解决方案：$v_{i,j,a,b}=v_{a,b}$

$$h_{i,j}=\sum_{a,b}v_{a,b}x_{i+a,b+j}$$

 这就是2维$\sout{卷积}$交叉相关

**局部性**

当评估$h_{i,j}$时，我们不应该远离$x_{i,j}$的参数

解决方案：当$|a|,|b|\gt\Delta$时，使得$v_{a,b}=0$

$$h_{i,j}=\sum_{a=-\Delta}^\Delta\sum_{b=-\Delta}^\Delta v_{a,b}x_{i+a,j+b}$$

## 卷积层

![](\Images/conv-full-layer.gif)

### 二维卷积层
输入$\bf X$：$n_h\times n_w$
核$\bf W$：$k_n\times k_w$
偏差$b\in \mathbb R$
输出$\bf Y$：$(n_h-k_h+1)\times(n_w-k_w+1)$

$${\bf Y}={\bf X* \bf W}+b$$
$\bf W$和$b$是可学习的参数。

**交叉相关vs卷积**  

二维交叉相关

$$y_{i,j}=\sum_{a=1}^h\sum_{b=1}^w w_{a,b}x_{i+a,j+b}$$

二维卷积

$$y_{i,j}=\sum_{a=1}^h\sum_{b=1}^w w_{-a,-b}x_{i+a,j+b}$$

由于对称性，在实际使用中没有区别。

**一维和三维交叉相关**

- 一维

$$y_i=\sum_{a=1}^hw_ax_{i+a}$$

文本、语言、时序序列

- 三维

$$y_{i,j,k}=\sum_{a=1}^h\sum_{b=1}^w \sum_{c=1}^dw_{a,b,c}x_{i+a,j+b,k+c}$$

视频、医学图像、气象地图

**总结**

卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出

核矩阵和偏移是可学习的参数

核矩阵的大小是超参数，就规避了输入越大权重越大的问题。

### 代码实现

**实现交叉运算**
```
import torch
from torch import nn
from d2l import torch as d2l

def corr2d(X, K):
    h, w = K.shape
    Y = torch.zeros((X.shape[0] - h +1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y
```
**自定义卷积模块**
```
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))
        
    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```

**借助PyTorch实现卷积**
```
conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)
#直接调用Conv2d,input channel=1,outputchannel=1

X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))
#增加两个维度，通道维度和批量大小维度

for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y)**2
    conv2d.zero_grad()
    l.sum().backward()
    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad
    #做梯度优化
    if (i + 1) % 2 == 0:
        print(f'batch {i+1}, loss {l.sum():.3f}')
```

