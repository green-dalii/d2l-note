# 30 - 模型微调Fine-tuning

### 🎦 本节课程视频地址 👉[![Bilibil](https://i2.hdslb.com/bfs/archive/5cf6b3c8606c1bdda979ea50bf8c3989912315c1.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1Sb4y1d7CR)
## 微调/迁移学习(Transfer learning)

<font color=red> 非常重要的技术 </font>

**标注一个数据集很贵**
MyImageNet: 50K 100类

**网络架构**

- 一个神经网络一般可以分成两块
  - 特征抽取将原始像素变成容易线性分割的特征(前面的Layers)
  - 线性分类器来做分类(最后一层的full-connected和softmax)

**微调**

如果在一个源数据集(ImageNet)上做好了特征提取，说明特征提取部分(Pre-trained Layers)很成功，所以希望能够将其运用在新的目标数据集(MyImageNet)上

![](\Images/1_1CxVzTNILTHgDs5yJO4W9A.png)

**微调中的权重初始化**

- Copy Pretrained Layers to new network

- Random initialization the output layer
  - 标号可能会变化

![](\Images/1_9GTEzcO8KxxrfutmtsPs3Q.png)

**训练**

- 是一个目标数据集上的正常训练任务，但是用更强的正则化
  - 使用更小的学习率
  - 使用更少的数据迭代
  - 假设源数据集远远复杂于目标数据集
  - 正则化使模型不做出过多的训练改变
- 源数据集远复杂于目标数据，通常微调效果更好

**重用分类器权重**

- 源数据集可能也有目标数据中的部分标号
- 可以使用预训练好模型分类器中对应标号对应的向量来做初始化

**固定一些层**

- 神经网络通常学习有层次的特征表示
  - 低层次的特征更加通用
  - 高层次的特征则跟数据集相关
- 可以固定底部一些层的参数，不参与更新
  - 更强的正则

![](\Images/The-lower-level-features-progressively-combine-to-form-higher-layer-features-in-deep_Q640.jpg)

**总结**

- 微调通过使用在大数据上集(bigger than Image Net)得到的预训练好的模型来初始化模型权重来完成精度提升；
- 预训练模型质量很重要；
- 微调通常速度更快、精度更高。

因此，深度学习可以通过方便地使用别处的先进经验实现作用于新的目标，所以在工业界得到了非常广泛地使用

### 代码实现
```
#下载数据集
d2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip', 'fba480ffa8aa7e0febbb511d181409f899b9baa5')

data_dir = d2l.download_extract('hotdog')

train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))
test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'))

hotdogs = [train_imgs[i][0] for i in range(8)]
not_hotdogs = [train_imgs[-i - 1][0] for i in range(8)]
#显示最后八张图片，写法可以参考
d2l.show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4)
```
```
#数据集图片调整到ImageNet的格式
normalize = torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
#把每个RGB通道的均值和方差拿出来，将tensor正则化
#在ImageNet训练的模型做过
train_augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomResizedCrop(224),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(), normalize
])
#resized(224)也是为了符合ImageNet的宽高
test_augs = torchvision.transforms.Compose([
    torchvision.transforms.Resize(256),
    torchvision.transforms.CenterCrop(224),
    torchvision.transforms.ToTensor(), normalize
])
#因为图像高宽比都不一样，所以先放大在从中截取
```
```
#提取训练模型&经验
pretrained_net = torchvision.models.resnet18(pretrained=True)
#.models.xxx()可以直接拿模型
#pretrained=True顺便拿训练经验
pretrained_net.fc
#fc:fully-connected表示最后的全连接层
```
```
#重定义
finetune_net = torchvision.models.resnet18(pretrained=True)
finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2)
#重定义全连接层，input_features不变，output_labels=2
nn.init.xavier_uniform_(finetune_net.fc.weight)
#均匀初始化最后一层权重
type(finetune_net.named_parameters())
type(next(finetune_net.named_parameters())[1])
```
```
#定义训练函数
def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, param_group=True):
    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'train'), transform=train_augs),
        batch_size=batch_size, shuffle=True)
    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'test'), transform=test_augs),
        batch_size=batch_size)
    ##把定义读文件和提取iterable合并了
    devices = d2l.try_all_gpus()
    loss = nn.CrossEntropyLoss(reduction="None")
    ##和从前有一样
    if param_group:
        params_1x = [param for name, param in net.named_parameters()
                   if name not in ["fc.weight", 'fc.bias']]
        #把非最后全连接层的参数提取出来
        trainer = torch.optim.SGD([{'params': params_1x},
                                  {'params': net.fc.parameters(), 
                                   'lr': learning_rate * 10}],
                                 lr=learning_rate, weight_decay=0.001)
        #全连接层十倍学习率
        #SGD传入的是字典，keys是参数名称。
        #所以第二个字典里，用了.parameters()而非named_parameters()
        # params: iterable of parameters to optimize or dicts defining parameter groups
    else:
        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)
    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)
## Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.
```
