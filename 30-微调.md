# 30 - æ¨¡å‹å¾®è°ƒFine-tuning

### ğŸ¦ æœ¬èŠ‚è¯¾ç¨‹è§†é¢‘åœ°å€ ğŸ‘‰[![Bilibil](https://i2.hdslb.com/bfs/archive/5cf6b3c8606c1bdda979ea50bf8c3989912315c1.jpg@640w_400h_100Q_1c.webp)](https://www.bilibili.com/video/BV1Sb4y1d7CR)
## å¾®è°ƒ/è¿ç§»å­¦ä¹ (Transfer learning)

<font color=red> éå¸¸é‡è¦çš„æŠ€æœ¯ </font>

**æ ‡æ³¨ä¸€ä¸ªæ•°æ®é›†å¾ˆè´µ**
MyImageNet: 50K 100ç±»

**ç½‘ç»œæ¶æ„**

- ä¸€ä¸ªç¥ç»ç½‘ç»œä¸€èˆ¬å¯ä»¥åˆ†æˆä¸¤å—
  - ç‰¹å¾æŠ½å–å°†åŸå§‹åƒç´ å˜æˆå®¹æ˜“çº¿æ€§åˆ†å‰²çš„ç‰¹å¾(å‰é¢çš„Layers)
  - çº¿æ€§åˆ†ç±»å™¨æ¥åšåˆ†ç±»(æœ€åä¸€å±‚çš„full-connectedå’Œsoftmax)

**å¾®è°ƒ**

å¦‚æœåœ¨ä¸€ä¸ªæºæ•°æ®é›†(ImageNet)ä¸Šåšå¥½äº†ç‰¹å¾æå–ï¼Œè¯´æ˜ç‰¹å¾æå–éƒ¨åˆ†(Pre-trained Layers)å¾ˆæˆåŠŸï¼Œæ‰€ä»¥å¸Œæœ›èƒ½å¤Ÿå°†å…¶è¿ç”¨åœ¨æ–°çš„ç›®æ ‡æ•°æ®é›†(MyImageNet)ä¸Š

![](\Images/1_1CxVzTNILTHgDs5yJO4W9A.png)

**å¾®è°ƒä¸­çš„æƒé‡åˆå§‹åŒ–**

- Copy Pretrained Layers to new network

- Random initialization the output layer
  - æ ‡å·å¯èƒ½ä¼šå˜åŒ–

![](\Images/1_9GTEzcO8KxxrfutmtsPs3Q.png)

**è®­ç»ƒ**

- æ˜¯ä¸€ä¸ªç›®æ ‡æ•°æ®é›†ä¸Šçš„æ­£å¸¸è®­ç»ƒä»»åŠ¡ï¼Œä½†æ˜¯ç”¨æ›´å¼ºçš„æ­£åˆ™åŒ–
  - ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡
  - ä½¿ç”¨æ›´å°‘çš„æ•°æ®è¿­ä»£
  - å‡è®¾æºæ•°æ®é›†è¿œè¿œå¤æ‚äºç›®æ ‡æ•°æ®é›†
  - æ­£åˆ™åŒ–ä½¿æ¨¡å‹ä¸åšå‡ºè¿‡å¤šçš„è®­ç»ƒæ”¹å˜
- æºæ•°æ®é›†è¿œå¤æ‚äºç›®æ ‡æ•°æ®ï¼Œé€šå¸¸å¾®è°ƒæ•ˆæœæ›´å¥½

**é‡ç”¨åˆ†ç±»å™¨æƒé‡**

- æºæ•°æ®é›†å¯èƒ½ä¹Ÿæœ‰ç›®æ ‡æ•°æ®ä¸­çš„éƒ¨åˆ†æ ‡å·
- å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒå¥½æ¨¡å‹åˆ†ç±»å™¨ä¸­å¯¹åº”æ ‡å·å¯¹åº”çš„å‘é‡æ¥åšåˆå§‹åŒ–

**å›ºå®šä¸€äº›å±‚**

- ç¥ç»ç½‘ç»œé€šå¸¸å­¦ä¹ æœ‰å±‚æ¬¡çš„ç‰¹å¾è¡¨ç¤º
  - ä½å±‚æ¬¡çš„ç‰¹å¾æ›´åŠ é€šç”¨
  - é«˜å±‚æ¬¡çš„ç‰¹å¾åˆ™è·Ÿæ•°æ®é›†ç›¸å…³
- å¯ä»¥å›ºå®šåº•éƒ¨ä¸€äº›å±‚çš„å‚æ•°ï¼Œä¸å‚ä¸æ›´æ–°
  - æ›´å¼ºçš„æ­£åˆ™

![](\Images/The-lower-level-features-progressively-combine-to-form-higher-layer-features-in-deep_Q640.jpg)

**æ€»ç»“**

- å¾®è°ƒé€šè¿‡ä½¿ç”¨åœ¨å¤§æ•°æ®ä¸Šé›†(bigger than Image Net)å¾—åˆ°çš„é¢„è®­ç»ƒå¥½çš„æ¨¡å‹æ¥åˆå§‹åŒ–æ¨¡å‹æƒé‡æ¥å®Œæˆç²¾åº¦æå‡ï¼›
- é¢„è®­ç»ƒæ¨¡å‹è´¨é‡å¾ˆé‡è¦ï¼›
- å¾®è°ƒé€šå¸¸é€Ÿåº¦æ›´å¿«ã€ç²¾åº¦æ›´é«˜ã€‚

å› æ­¤ï¼Œæ·±åº¦å­¦ä¹ å¯ä»¥é€šè¿‡æ–¹ä¾¿åœ°ä½¿ç”¨åˆ«å¤„çš„å…ˆè¿›ç»éªŒå®ç°ä½œç”¨äºæ–°çš„ç›®æ ‡ï¼Œæ‰€ä»¥åœ¨å·¥ä¸šç•Œå¾—åˆ°äº†éå¸¸å¹¿æ³›åœ°ä½¿ç”¨

### ä»£ç å®ç°
```
#ä¸‹è½½æ•°æ®é›†
d2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip', 'fba480ffa8aa7e0febbb511d181409f899b9baa5')

data_dir = d2l.download_extract('hotdog')

train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))
test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'))

hotdogs = [train_imgs[i][0] for i in range(8)]
not_hotdogs = [train_imgs[-i - 1][0] for i in range(8)]
#æ˜¾ç¤ºæœ€åå…«å¼ å›¾ç‰‡ï¼Œå†™æ³•å¯ä»¥å‚è€ƒ
d2l.show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4)
```
```
#æ•°æ®é›†å›¾ç‰‡è°ƒæ•´åˆ°ImageNetçš„æ ¼å¼
normalize = torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
#æŠŠæ¯ä¸ªRGBé€šé“çš„å‡å€¼å’Œæ–¹å·®æ‹¿å‡ºæ¥ï¼Œå°†tensoræ­£åˆ™åŒ–
#åœ¨ImageNetè®­ç»ƒçš„æ¨¡å‹åšè¿‡
train_augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomResizedCrop(224),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(), normalize
])
#resized(224)ä¹Ÿæ˜¯ä¸ºäº†ç¬¦åˆImageNetçš„å®½é«˜
test_augs = torchvision.transforms.Compose([
    torchvision.transforms.Resize(256),
    torchvision.transforms.CenterCrop(224),
    torchvision.transforms.ToTensor(), normalize
])
#å› ä¸ºå›¾åƒé«˜å®½æ¯”éƒ½ä¸ä¸€æ ·ï¼Œæ‰€ä»¥å…ˆæ”¾å¤§åœ¨ä»ä¸­æˆªå–
```
```
#æå–è®­ç»ƒæ¨¡å‹&ç»éªŒ
pretrained_net = torchvision.models.resnet18(pretrained=True)
#.models.xxx()å¯ä»¥ç›´æ¥æ‹¿æ¨¡å‹
#pretrained=Trueé¡ºä¾¿æ‹¿è®­ç»ƒç»éªŒ
pretrained_net.fc
#fc:fully-connectedè¡¨ç¤ºæœ€åçš„å…¨è¿æ¥å±‚
```
```
#é‡å®šä¹‰
finetune_net = torchvision.models.resnet18(pretrained=True)
finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2)
#é‡å®šä¹‰å…¨è¿æ¥å±‚ï¼Œinput_featuresä¸å˜ï¼Œoutput_labels=2
nn.init.xavier_uniform_(finetune_net.fc.weight)
#å‡åŒ€åˆå§‹åŒ–æœ€åä¸€å±‚æƒé‡
type(finetune_net.named_parameters())
type(next(finetune_net.named_parameters())[1])
```
```
#å®šä¹‰è®­ç»ƒå‡½æ•°
def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, param_group=True):
    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'train'), transform=train_augs),
        batch_size=batch_size, shuffle=True)
    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'test'), transform=test_augs),
        batch_size=batch_size)
    ##æŠŠå®šä¹‰è¯»æ–‡ä»¶å’Œæå–iterableåˆå¹¶äº†
    devices = d2l.try_all_gpus()
    loss = nn.CrossEntropyLoss(reduction="None")
    ##å’Œä»å‰æœ‰ä¸€æ ·
    if param_group:
        params_1x = [param for name, param in net.named_parameters()
                   if name not in ["fc.weight", 'fc.bias']]
        #æŠŠéæœ€åå…¨è¿æ¥å±‚çš„å‚æ•°æå–å‡ºæ¥
        trainer = torch.optim.SGD([{'params': params_1x},
                                  {'params': net.fc.parameters(), 
                                   'lr': learning_rate * 10}],
                                 lr=learning_rate, weight_decay=0.001)
        #å…¨è¿æ¥å±‚åå€å­¦ä¹ ç‡
        #SGDä¼ å…¥çš„æ˜¯å­—å…¸ï¼Œkeysæ˜¯å‚æ•°åç§°ã€‚
        #æ‰€ä»¥ç¬¬äºŒä¸ªå­—å…¸é‡Œï¼Œç”¨äº†.parameters()è€Œénamed_parameters()
        # params: iterable of parameters to optimize or dicts defining parameter groups
    else:
        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)
    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)
## Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.
```
